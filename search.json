[
  {
    "objectID": "pages/widgets_expanded.html",
    "href": "pages/widgets_expanded.html",
    "title": "Interactive Widgets in Jupyter",
    "section": "",
    "text": "Jupyter widgets (ipywidgets) allow you to build interactive GUIs for your notebooks. They’re perfect for:\n\nData Exploration: Interactive parameter tuning\nTeaching: Demonstrating concepts dynamically\nDashboards: Simple data apps without leaving Jupyter\nModel Tuning: Real-time hyperparameter adjustment\n\nThis tutorial covers everything from basic widgets to complex interactive applications."
  },
  {
    "objectID": "pages/widgets_expanded.html#introduction-to-jupyter-widgets",
    "href": "pages/widgets_expanded.html#introduction-to-jupyter-widgets",
    "title": "Interactive Widgets in Jupyter",
    "section": "",
    "text": "Jupyter widgets (ipywidgets) allow you to build interactive GUIs for your notebooks. They’re perfect for:\n\nData Exploration: Interactive parameter tuning\nTeaching: Demonstrating concepts dynamically\nDashboards: Simple data apps without leaving Jupyter\nModel Tuning: Real-time hyperparameter adjustment\n\nThis tutorial covers everything from basic widgets to complex interactive applications."
  },
  {
    "objectID": "pages/widgets_expanded.html#setup-and-installation",
    "href": "pages/widgets_expanded.html#setup-and-installation",
    "title": "Interactive Widgets in Jupyter",
    "section": "Setup and Installation",
    "text": "Setup and Installation\n\n# Install if needed (uncomment)\n# !pip install ipywidgets\n# !jupyter nbextension enable --py widgetsnbextension\n\n# Import libraries\nimport ipywidgets as widgets\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nfrom IPython.display import display, clear_output, HTML\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\n\n# Setup\nset_matplotlib_formats('retina')\nsns.set_theme(style='whitegrid')\nplt.rcParams['figure.figsize'] = (8, 5)\n\nprint(\"Widgets ready!\")"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-1-basic-widgets",
    "href": "pages/widgets_expanded.html#part-1-basic-widgets",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 1: Basic Widgets",
    "text": "Part 1: Basic Widgets\n\nSimple Input Widgets\n\n# Text input\ntext = widgets.Text(\n    value='Hello World',\n    placeholder='Type something',\n    description='String:',\n    disabled=False\n)\ndisplay(text)\n\n\n# Numeric input\nint_slider = widgets.IntSlider(\n    value=7,\n    min=0,\n    max=10,\n    step=1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='d'\n)\ndisplay(int_slider)\n\n\n# Float slider with style\nfloat_slider = widgets.FloatSlider(\n    value=5.5,\n    min=0,\n    max=10.0,\n    step=0.1,\n    description='Float:',\n    style={'description_width': 'initial'},\n    layout=widgets.Layout(width='50%')\n)\ndisplay(float_slider)\n\n\n\nSelection Widgets\n\n# Dropdown\ndropdown = widgets.Dropdown(\n    options=['Option 1', 'Option 2', 'Option 3'],\n    value='Option 2',\n    description='Choose:',\n    disabled=False,\n)\n\n# Radio buttons\nradio = widgets.RadioButtons(\n    options=['Small', 'Medium', 'Large'],\n    value='Medium',\n    description='Size:',\n    disabled=False\n)\n\n# Checkbox\ncheckbox = widgets.Checkbox(\n    value=False,\n    description='Check me',\n    disabled=False,\n    indent=False\n)\n\n# Display all\ndisplay(dropdown, radio, checkbox)\n\n\n\nButton and Output Widgets\n\n# Button with callback\nbutton = widgets.Button(\n    description='Click me!',\n    disabled=False,\n    button_style='success',  # 'success', 'info', 'warning', 'danger' or ''\n    tooltip='Click to see magic',\n    icon='check'  # FontAwesome icon\n)\n\noutput = widgets.Output()\n\ndef on_button_click(b):\n    with output:\n        clear_output()\n        print(f\"Button clicked! Value from slider: {int_slider.value}\")\n\nbutton.on_click(on_button_click)\ndisplay(button, output)"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-2-the-interact-function",
    "href": "pages/widgets_expanded.html#part-2-the-interact-function",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 2: The interact Function",
    "text": "Part 2: The interact Function\nThe easiest way to create interactive widgets!\n\n# Simple interact\n@interact(x=(0, 10), y=(0, 10))\ndef add(x, y):\n    return f\"{x} + {y} = {x + y}\"\n\n\n# Interact with plot\n@interact(freq=(1, 10, 0.5), amplitude=(0.1, 2, 0.1), phase=(0, 2*np.pi, 0.1))\ndef plot_sine(freq=2, amplitude=1, phase=0):\n    x = np.linspace(0, 2*np.pi, 1000)\n    y = amplitude * np.sin(freq * x + phase)\n    \n    plt.figure(figsize=(10, 4))\n    plt.plot(x, y, 'b-', linewidth=2)\n    plt.ylim(-2.5, 2.5)\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title(f'y = {amplitude:.1f} * sin({freq:.1f}x + {phase:.1f})')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\n\nAutomatic Widget Generation\n\n# Interact automatically creates appropriate widgets\n@interact\ndef auto_widgets(\n    text=\"Hello\",                    # Creates Text widget\n    number=5,                        # Creates IntSlider\n    float_num=5.5,                   # Creates FloatSlider\n    boolean=True,                    # Creates Checkbox\n    options=['A', 'B', 'C'],        # Creates Dropdown\n    date=(1, 100, 10)               # Creates IntSlider with range\n):\n    print(f\"Text: {text}\")\n    print(f\"Number: {number}\")\n    print(f\"Float: {float_num}\")\n    print(f\"Boolean: {boolean}\")\n    print(f\"Option: {options}\")\n    print(f\"Date: {date}\")"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-3-interactive-data-exploration",
    "href": "pages/widgets_expanded.html#part-3-interactive-data-exploration",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 3: Interactive Data Exploration",
    "text": "Part 3: Interactive Data Exploration\n\n# Load sample data\npenguins = sns.load_dataset('penguins')\npenguins_clean = penguins.dropna()\n\n# Interactive data explorer\n@interact(\n    x_col=list(penguins_clean.select_dtypes(include=[np.number]).columns),\n    y_col=list(penguins_clean.select_dtypes(include=[np.number]).columns),\n    hue_col=['None'] + list(penguins_clean.columns),\n    plot_type=['scatter', 'line', 'hex']\n)\ndef explore_data(x_col='bill_length_mm', y_col='bill_depth_mm', \n                 hue_col='species', plot_type='scatter'):\n    \n    plt.figure(figsize=(10, 6))\n    \n    if hue_col == 'None':\n        hue_data = None\n    else:\n        hue_data = penguins_clean[hue_col]\n    \n    if plot_type == 'scatter':\n        sns.scatterplot(data=penguins_clean, x=x_col, y=y_col, hue=hue_data, s=100)\n    elif plot_type == 'line':\n        if hue_data is not None:\n            for val in penguins_clean[hue_col].unique():\n                data = penguins_clean[penguins_clean[hue_col] == val]\n                plt.plot(data[x_col], data[y_col], 'o-', label=val, alpha=0.7)\n            plt.legend()\n        else:\n            plt.plot(penguins_clean[x_col], penguins_clean[y_col], 'o-')\n    elif plot_type == 'hex':\n        plt.hexbin(penguins_clean[x_col], penguins_clean[y_col], gridsize=20, cmap='YlOrRd')\n        plt.colorbar(label='Count')\n    \n    plt.xlabel(x_col)\n    plt.ylabel(y_col)\n    plt.title(f'{plot_type.capitalize()} Plot: {x_col} vs {y_col}')\n    plt.tight_layout()\n    plt.show()\n    \n    # Show statistics\n    print(f\"\\nCorrelation: {penguins_clean[x_col].corr(penguins_clean[y_col]):.3f}\")\n    print(f\"Data points: {len(penguins_clean)}\")"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-4-layout-and-styling",
    "href": "pages/widgets_expanded.html#part-4-layout-and-styling",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 4: Layout and Styling",
    "text": "Part 4: Layout and Styling\n\nContainer Widgets\n\n# HBox - Horizontal layout\nslider1 = widgets.IntSlider(description='A')\nslider2 = widgets.IntSlider(description='B')\nslider3 = widgets.IntSlider(description='C')\n\nhbox = widgets.HBox([slider1, slider2, slider3])\ndisplay(hbox)\n\n\n# VBox - Vertical layout\nvbox = widgets.VBox([\n    widgets.Label('Vertical Stack:'),\n    widgets.IntSlider(description='Value 1'),\n    widgets.IntSlider(description='Value 2'),\n    widgets.IntSlider(description='Value 3')\n])\ndisplay(vbox)\n\n\n# Tabs\ntab1 = widgets.VBox([widgets.HTML('&lt;h3&gt;Settings&lt;/h3&gt;'),\n                     widgets.IntSlider(description='Speed'),\n                     widgets.FloatSlider(description='Quality')])\n\ntab2 = widgets.VBox([widgets.HTML('&lt;h3&gt;Advanced&lt;/h3&gt;'),\n                     widgets.Checkbox(description='Enable feature'),\n                     widgets.Dropdown(options=['Mode 1', 'Mode 2'])])\n\ntabs = widgets.Tab(children=[tab1, tab2])\ntabs.set_title(0, 'Basic')\ntabs.set_title(1, 'Advanced')\ndisplay(tabs)\n\n\n# Accordion\naccordion = widgets.Accordion(children=[\n    widgets.IntSlider(description='Setting 1'),\n    widgets.Text(description='Setting 2'),\n    widgets.Dropdown(options=['A', 'B', 'C'], description='Setting 3')\n])\naccordion.set_title(0, 'Numeric Settings')\naccordion.set_title(1, 'Text Settings')\naccordion.set_title(2, 'Choice Settings')\ndisplay(accordion)\n\n\n\nCustom Styling\n\n# Styled widgets\nstyled_slider = widgets.IntSlider(\n    value=50,\n    min=0,\n    max=100,\n    description='Styled:',\n    style={\n        'description_width': '100px',\n        'handle_color': 'lightblue'\n    },\n    layout=widgets.Layout(\n        width='80%',\n        height='50px',\n        border='2px solid blue',\n        padding='10px',\n        margin='10px'\n    )\n)\n\nstyled_button = widgets.Button(\n    description='Styled Button',\n    button_style='info',\n    layout=widgets.Layout(\n        width='200px',\n        height='50px'\n    )\n)\n\ndisplay(styled_slider, styled_button)"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-5-advanced-interactive-applications",
    "href": "pages/widgets_expanded.html#part-5-advanced-interactive-applications",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 5: Advanced Interactive Applications",
    "text": "Part 5: Advanced Interactive Applications\n\nInteractive Machine Learning Model\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Generate sample data\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n                          n_redundant=5, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Interactive model training\n@interact(\n    n_estimators=(10, 200, 10),\n    max_depth=(1, 20),\n    min_samples_split=(2, 20),\n    criterion=['gini', 'entropy']\n)\ndef train_model(n_estimators=100, max_depth=10, min_samples_split=2, criterion='gini'):\n    # Train model\n    clf = RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        criterion=criterion,\n        random_state=42\n    )\n    clf.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    # Visualization\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n    ax1.set_title(f'Confusion Matrix\\nAccuracy: {accuracy:.3f}')\n    ax1.set_xlabel('Predicted')\n    ax1.set_ylabel('Actual')\n    \n    # Feature importance\n    importance = clf.feature_importances_\n    indices = np.argsort(importance)[::-1][:10]\n    ax2.bar(range(10), importance[indices])\n    ax2.set_title('Top 10 Feature Importances')\n    ax2.set_xlabel('Feature Index')\n    ax2.set_ylabel('Importance')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nModel Performance:\")\n    print(f\"Training samples: {len(X_train)}\")\n    print(f\"Test samples: {len(X_test)}\")\n    print(f\"Accuracy: {accuracy:.3f}\")\n\n\n\nInteractive Image Processing\n\nfrom scipy import ndimage\nfrom skimage import data\n\n# Load sample image\nimage = data.camera()\n\n@interact(\n    blur=(0, 10, 0.5),\n    rotation=(-180, 180, 10),\n    brightness=(-100, 100, 10),\n    contrast=(0.5, 2, 0.1)\n)\ndef process_image(blur=0, rotation=0, brightness=0, contrast=1):\n    # Process image\n    processed = image.copy().astype(float)\n    \n    # Apply blur\n    if blur &gt; 0:\n        processed = ndimage.gaussian_filter(processed, blur)\n    \n    # Apply rotation\n    if rotation != 0:\n        processed = ndimage.rotate(processed, rotation, reshape=False)\n    \n    # Adjust brightness and contrast\n    processed = (processed - 128) * contrast + 128 + brightness\n    processed = np.clip(processed, 0, 255)\n    \n    # Display\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    \n    ax1.imshow(image, cmap='gray')\n    ax1.set_title('Original')\n    ax1.axis('off')\n    \n    ax2.imshow(processed, cmap='gray', vmin=0, vmax=255)\n    ax2.set_title('Processed')\n    ax2.axis('off')\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-6-building-a-complete-dashboard",
    "href": "pages/widgets_expanded.html#part-6-building-a-complete-dashboard",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 6: Building a Complete Dashboard",
    "text": "Part 6: Building a Complete Dashboard\n\n# Complete interactive dashboard\nclass DataDashboard:\n    def __init__(self, data):\n        self.data = data\n        self.setup_widgets()\n        self.setup_layout()\n        \n    def setup_widgets(self):\n        # Data selection\n        self.column_x = widgets.Dropdown(\n            options=self.data.select_dtypes(include=[np.number]).columns,\n            description='X axis:'\n        )\n        self.column_y = widgets.Dropdown(\n            options=self.data.select_dtypes(include=[np.number]).columns,\n            description='Y axis:'\n        )\n        self.color_by = widgets.Dropdown(\n            options=['None'] + list(self.data.columns),\n            description='Color by:'\n        )\n        \n        # Plot type\n        self.plot_type = widgets.RadioButtons(\n            options=['Scatter', 'Box', 'Histogram', 'Correlation'],\n            description='Plot Type:'\n        )\n        \n        # Update button\n        self.update_button = widgets.Button(\n            description='Update Plot',\n            button_style='success'\n        )\n        self.update_button.on_click(self.update_plot)\n        \n        # Output area\n        self.output = widgets.Output()\n        \n        # Statistics text\n        self.stats_output = widgets.Output()\n        \n    def setup_layout(self):\n        # Control panel\n        controls = widgets.VBox([\n            widgets.HTML('&lt;h3&gt;Data Selection&lt;/h3&gt;'),\n            self.column_x,\n            self.column_y,\n            self.color_by,\n            widgets.HTML('&lt;h3&gt;Visualization&lt;/h3&gt;'),\n            self.plot_type,\n            self.update_button\n        ])\n        \n        # Main layout\n        self.dashboard = widgets.HBox([\n            controls,\n            widgets.VBox([\n                self.output,\n                self.stats_output\n            ])\n        ])\n        \n    def update_plot(self, button):\n        with self.output:\n            clear_output(wait=True)\n            \n            fig, ax = plt.subplots(figsize=(10, 6))\n            \n            if self.plot_type.value == 'Scatter':\n                hue = None if self.color_by.value == 'None' else self.data[self.color_by.value]\n                sns.scatterplot(data=self.data, \n                              x=self.column_x.value, \n                              y=self.column_y.value,\n                              hue=hue, ax=ax)\n                \n            elif self.plot_type.value == 'Box':\n                self.data.boxplot(column=self.column_y.value, ax=ax)\n                \n            elif self.plot_type.value == 'Histogram':\n                ax.hist(self.data[self.column_x.value].dropna(), bins=30, edgecolor='black')\n                ax.set_xlabel(self.column_x.value)\n                \n            elif self.plot_type.value == 'Correlation':\n                corr_matrix = self.data.select_dtypes(include=[np.number]).corr()\n                sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)\n            \n            plt.tight_layout()\n            plt.show()\n        \n        # Update statistics\n        with self.stats_output:\n            clear_output(wait=True)\n            if self.plot_type.value == 'Scatter':\n                corr = self.data[self.column_x.value].corr(self.data[self.column_y.value])\n                print(f\"Correlation: {corr:.3f}\")\n                print(f\"Data points: {len(self.data.dropna())}\")\n    \n    def display(self):\n        display(self.dashboard)\n        self.update_plot(None)  # Initial plot\n\n# Create and display dashboard\ndashboard = DataDashboard(penguins)\ndashboard.display()"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-7-linking-widgets",
    "href": "pages/widgets_expanded.html#part-7-linking-widgets",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 7: Linking Widgets",
    "text": "Part 7: Linking Widgets\n\n# Linked widgets example\na = widgets.FloatSlider(description='a', min=-10, max=10, value=1)\nb = widgets.FloatSlider(description='b', min=-10, max=10, value=0)\nc = widgets.FloatSlider(description='c', min=-10, max=10, value=0)\n\ndef update_equation(change):\n    with equation_output:\n        clear_output(wait=True)\n        \n        x = np.linspace(-10, 10, 1000)\n        y = a.value * x**2 + b.value * x + c.value\n        \n        plt.figure(figsize=(10, 6))\n        plt.plot(x, y, 'b-', linewidth=2)\n        plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n        plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n        plt.grid(True, alpha=0.3)\n        plt.xlim(-10, 10)\n        plt.ylim(-50, 50)\n        plt.title(f'y = {a.value:.1f}x² + {b.value:.1f}x + {c.value:.1f}')\n        plt.xlabel('x')\n        plt.ylabel('y')\n        plt.show()\n\n# Link widgets to function\na.observe(update_equation, names='value')\nb.observe(update_equation, names='value')\nc.observe(update_equation, names='value')\n\nequation_output = widgets.Output()\n\n# Display\ndisplay(widgets.VBox([a, b, c, equation_output]))\nupdate_equation(None)  # Initial plot"
  },
  {
    "objectID": "pages/widgets_expanded.html#part-8-file-upload-widget",
    "href": "pages/widgets_expanded.html#part-8-file-upload-widget",
    "title": "Interactive Widgets in Jupyter",
    "section": "Part 8: File Upload Widget",
    "text": "Part 8: File Upload Widget\n\n# File upload widget\nupload = widgets.FileUpload(\n    accept='.csv',  # Accept CSV files\n    multiple=False  # Single file\n)\n\noutput = widgets.Output()\n\ndef handle_upload(change):\n    with output:\n        clear_output()\n        if upload.value:\n            # Get uploaded file\n            uploaded_file = list(upload.value.values())[0]\n            content = uploaded_file['content']\n            \n            # Read CSV\n            import io\n            df = pd.read_csv(io.BytesIO(content))\n            \n            print(f\"File uploaded: {uploaded_file['metadata']['name']}\")\n            print(f\"Shape: {df.shape}\")\n            print(\"\\nFirst 5 rows:\")\n            display(df.head())\n            \n            # Simple plot\n            if len(df.select_dtypes(include=[np.number]).columns) &gt;= 2:\n                fig, ax = plt.subplots(figsize=(10, 6))\n                df.plot(kind='scatter', \n                       x=df.columns[0], \n                       y=df.columns[1], \n                       ax=ax)\n                plt.show()\n\nupload.observe(handle_upload, names='value')\n\ndisplay(widgets.VBox([\n    widgets.HTML('&lt;h3&gt;Upload CSV File&lt;/h3&gt;'),\n    upload,\n    output\n]))"
  },
  {
    "objectID": "pages/widgets_expanded.html#best-practices-and-tips",
    "href": "pages/widgets_expanded.html#best-practices-and-tips",
    "title": "Interactive Widgets in Jupyter",
    "section": "Best Practices and Tips",
    "text": "Best Practices and Tips\n\n1. Performance Optimization\n\nUse continuous_update=False for sliders to avoid excessive updates\nCache expensive computations\nUse interact_manual for heavy computations\nLimit data size for real-time interactions\n\n\n\n2. User Experience\n\nProvide clear labels and descriptions\nUse appropriate widget types for data\nGroup related controls\nAdd loading indicators for slow operations\n\n\n\n3. Layout Guidelines\n\nUse VBox/HBox for simple layouts\nUse Grid for complex arrangements\nKeep controls organized and intuitive\nProvide visual feedback for actions"
  },
  {
    "objectID": "pages/widgets_expanded.html#troubleshooting",
    "href": "pages/widgets_expanded.html#troubleshooting",
    "title": "Interactive Widgets in Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nCommon Issues\n\nWidgets not displaying:\n\nEnsure ipywidgets is installed\nEnable notebook extension: jupyter nbextension enable --py widgetsnbextension\n\nUpdates not working:\n\nCheck callback function signatures\nUse .observe() for custom widgets\nVerify widget value types\n\nPerformance issues:\n\nReduce update frequency\nOptimize computation code\nUse caching where possible"
  },
  {
    "objectID": "pages/widgets_expanded.html#advanced-topics",
    "href": "pages/widgets_expanded.html#advanced-topics",
    "title": "Interactive Widgets in Jupyter",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nCustom Widget Classes\n\n# Create custom widget\nclass ColorPicker(widgets.HBox):\n    def __init__(self):\n        super().__init__()\n        \n        self.r = widgets.IntSlider(min=0, max=255, description='R')\n        self.g = widgets.IntSlider(min=0, max=255, description='G')\n        self.b = widgets.IntSlider(min=0, max=255, description='B')\n        self.preview = widgets.HTML(\n            value='&lt;div style=\"width:100px;height:100px;background:rgb(0,0,0)\"&gt;&lt;/div&gt;'\n        )\n        \n        self.r.observe(self.update_color, 'value')\n        self.g.observe(self.update_color, 'value')\n        self.b.observe(self.update_color, 'value')\n        \n        self.children = [self.r, self.g, self.b, self.preview]\n    \n    def update_color(self, change):\n        color = f'rgb({self.r.value},{self.g.value},{self.b.value})'\n        self.preview.value = f'&lt;div style=\"width:100px;height:100px;background:{color}\"&gt;&lt;/div&gt;'\n    \n    @property\n    def value(self):\n        return (self.r.value, self.g.value, self.b.value)\n\n# Use custom widget\ncolor_picker = ColorPicker()\ndisplay(color_picker)"
  },
  {
    "objectID": "pages/widgets_expanded.html#resources-and-further-learning",
    "href": "pages/widgets_expanded.html#resources-and-further-learning",
    "title": "Interactive Widgets in Jupyter",
    "section": "Resources and Further Learning",
    "text": "Resources and Further Learning\n\nDocumentation\n\nipywidgets Documentation\nWidget List\nLayout and Styling\n\n\n\nAdvanced Libraries\n\nVoilà: Turn notebooks into standalone web apps\nPanel: More advanced dashboarding\nDash: Production-ready dashboards\nStreamlit: Rapid app development\n\n\n\nExamples\n\nipywidgets Gallery\nInteractive Visualizations"
  },
  {
    "objectID": "pages/widgets_expanded.html#summary",
    "href": "pages/widgets_expanded.html#summary",
    "title": "Interactive Widgets in Jupyter",
    "section": "Summary",
    "text": "Summary\nYou’ve learned: - Basic Widgets: Input, selection, and display widgets - Interact: Quick interactive functions - Layouts: Organizing widgets effectively - Linking: Creating responsive interfaces - Dashboards: Building complete applications\nJupyter widgets transform static notebooks into interactive applications, perfect for: - Data exploration - Teaching and demonstrations - Prototype development - Model tuning\nKeep experimenting and building!"
  },
  {
    "objectID": "pages/test_simple.html",
    "href": "pages/test_simple.html",
    "title": "Simple Test",
    "section": "",
    "text": "Basic notebook"
  },
  {
    "objectID": "pages/plotting_expanded.html",
    "href": "pages/plotting_expanded.html",
    "title": "Data Visualization with Python",
    "section": "",
    "text": "Data visualization is essential for: - Exploring data patterns and relationships - Communicating findings effectively - Debugging data processing pipelines - Presenting results to stakeholders\nThis tutorial covers Python’s main visualization libraries with practical examples."
  },
  {
    "objectID": "pages/plotting_expanded.html#introduction-to-data-visualization",
    "href": "pages/plotting_expanded.html#introduction-to-data-visualization",
    "title": "Data Visualization with Python",
    "section": "",
    "text": "Data visualization is essential for: - Exploring data patterns and relationships - Communicating findings effectively - Debugging data processing pipelines - Presenting results to stakeholders\nThis tutorial covers Python’s main visualization libraries with practical examples."
  },
  {
    "objectID": "pages/plotting_expanded.html#setup-and-imports",
    "href": "pages/plotting_expanded.html#setup-and-imports",
    "title": "Data Visualization with Python",
    "section": "Setup and Imports",
    "text": "Setup and Imports\n\n# Core visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import plotly.express as px\n# import plotly.graph_objects as go\n\n# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Display settings\nsns.set_theme(style=\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 12\n\n# High-resolution displays\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nset_matplotlib_formats('retina', 'png')\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries loaded successfully!\")\n\nLibraries loaded successfully!"
  },
  {
    "objectID": "pages/plotting_expanded.html#load-sample-data",
    "href": "pages/plotting_expanded.html#load-sample-data",
    "title": "Data Visualization with Python",
    "section": "Load Sample Data",
    "text": "Load Sample Data\nWe’ll use several datasets to demonstrate different visualization techniques:\n\n# Load built-in datasets\npenguins = sns.load_dataset(\"penguins\")\ntips = sns.load_dataset(\"tips\")\niris = sns.load_dataset(\"iris\")\n\n# Create synthetic time series data\ndates = pd.date_range('2023-01-01', periods=365, freq='D')\nts_data = pd.DataFrame({\n    'date': dates,\n    'value': np.cumsum(np.random.randn(365)) + 100,\n    'volume': np.random.poisson(1000, 365)\n})\n\nprint(f\"Penguins dataset: {penguins.shape}\")\nprint(f\"Tips dataset: {tips.shape}\")\nprint(f\"Time series: {ts_data.shape}\")\npenguins.head()\n\nPenguins dataset: (344, 7)\nTips dataset: (244, 7)\nTime series: (365, 3)\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-1-matplotlib-fundamentals",
    "href": "pages/plotting_expanded.html#part-1-matplotlib-fundamentals",
    "title": "Data Visualization with Python",
    "section": "Part 1: Matplotlib Fundamentals",
    "text": "Part 1: Matplotlib Fundamentals\nMatplotlib is the foundation of Python visualization. Most other libraries build on top of it.\n\nBasic Plot Types\n\n# Create a figure with subplots\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# 1. Line plot\nx = np.linspace(0, 10, 100)\naxes[0, 0].plot(x, np.sin(x), 'b-', label='sin(x)')\naxes[0, 0].plot(x, np.cos(x), 'r--', label='cos(x)')\naxes[0, 0].set_title('Line Plot')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. Scatter plot\naxes[0, 1].scatter(penguins['bill_length_mm'], \n                   penguins['flipper_length_mm'],\n                   alpha=0.6, s=50)\naxes[0, 1].set_title('Scatter Plot')\naxes[0, 1].set_xlabel('Bill Length (mm)')\naxes[0, 1].set_ylabel('Flipper Length (mm)')\n\n# 3. Histogram\naxes[0, 2].hist(penguins['body_mass_g'].dropna(), \n                bins=30, edgecolor='black', alpha=0.7)\naxes[0, 2].set_title('Histogram')\naxes[0, 2].set_xlabel('Body Mass (g)')\naxes[0, 2].set_ylabel('Frequency')\n\n# 4. Bar plot\nspecies_counts = penguins['species'].value_counts()\naxes[1, 0].bar(species_counts.index, species_counts.values, \n               color=['#1f77b4', '#ff7f0e', '#2ca02c'])\naxes[1, 0].set_title('Bar Plot')\naxes[1, 0].set_ylabel('Count')\n\n# 5. Box plot\ndata_to_plot = [penguins[penguins['species'] == s]['body_mass_g'].dropna() \n                for s in penguins['species'].unique()]\naxes[1, 1].boxplot(data_to_plot, labels=penguins['species'].unique())\naxes[1, 1].set_title('Box Plot')\naxes[1, 1].set_ylabel('Body Mass (g)')\n\n# 6. Pie chart\naxes[1, 2].pie(species_counts.values, labels=species_counts.index, \n               autopct='%1.1f%%', startangle=90)\naxes[1, 2].set_title('Pie Chart')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCustomizing Plots\n\n# Create a customized plot\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot data with custom styling\nfor species in penguins['species'].unique():\n    data = penguins[penguins['species'] == species]\n    ax.scatter(data['bill_length_mm'], \n               data['bill_depth_mm'],\n               label=species,\n               s=100,\n               alpha=0.7,\n               edgecolor='black',\n               linewidth=0.5)\n\n# Customize appearance\nax.set_xlabel('Bill Length (mm)', fontsize=14, fontweight='bold')\nax.set_ylabel('Bill Depth (mm)', fontsize=14, fontweight='bold')\nax.set_title('Palmer Penguins: Bill Dimensions by Species', \n             fontsize=16, fontweight='bold', pad=20)\n\n# Add grid\nax.grid(True, alpha=0.3, linestyle='--')\n\n# Customize legend\nax.legend(title='Species', loc='upper right', \n          frameon=True, fancybox=True, shadow=True)\n\n# Add text annotation\nax.annotate('Gentoo penguins\\nhave longer bills', \n            xy=(55, 16), xytext=(52, 20),\n            arrowprops=dict(arrowstyle='-&gt;', color='red', lw=2),\n            fontsize=12, ha='center',\n            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.5))\n\n# Set axis limits\nax.set_xlim(30, 60)\nax.set_ylim(13, 22)\n\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-2-seaborn---statistical-visualization",
    "href": "pages/plotting_expanded.html#part-2-seaborn---statistical-visualization",
    "title": "Data Visualization with Python",
    "section": "Part 2: Seaborn - Statistical Visualization",
    "text": "Part 2: Seaborn - Statistical Visualization\nSeaborn provides high-level interface for statistical graphics.\n\nDistribution Plots\n\n# Create distribution plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# 1. Histogram with KDE\nsns.histplot(data=penguins, x='body_mass_g', hue='species', \n             kde=True, ax=axes[0, 0])\naxes[0, 0].set_title('Histogram with KDE')\n\n# 2. Violin plot\nsns.violinplot(data=penguins, x='species', y='body_mass_g', \n               ax=axes[0, 1])\naxes[0, 1].set_title('Violin Plot')\n\n# 3. Joint plot (requires separate figure)\naxes[1, 0].text(0.5, 0.5, 'See separate joint plot below', \n                ha='center', va='center', fontsize=12)\naxes[1, 0].set_title('Joint Plot')\n\n# 4. Strip plot with swarm\nsns.stripplot(data=penguins, x='species', y='bill_length_mm', \n              alpha=0.3, ax=axes[1, 1])\nsns.swarmplot(data=penguins, x='species', y='bill_length_mm', \n              size=3, ax=axes[1, 1])\naxes[1, 1].set_title('Strip + Swarm Plot')\n\nplt.tight_layout()\nplt.show()\n\n# Create joint plot separately\ng = sns.jointplot(data=penguins, x='bill_length_mm', y='bill_depth_mm', \n                  hue='species', kind='scatter', height=8)\ng.fig.suptitle('Joint Distribution Plot', y=1.02)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorical Plots\n\n# Categorical plot examples\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# 1. Box plot\nsns.boxplot(data=tips, x='day', y='total_bill', hue='sex', ax=axes[0, 0])\naxes[0, 0].set_title('Box Plot by Day and Sex')\n\n# 2. Bar plot with error bars\nsns.barplot(data=tips, x='day', y='total_bill', hue='time', \n            errorbar='sd', ax=axes[0, 1])\naxes[0, 1].set_title('Bar Plot with Error Bars')\n\n# 3. Count plot\nsns.countplot(data=tips, x='day', hue='time', ax=axes[0, 2])\naxes[0, 2].set_title('Count Plot')\n\n# 4. Point plot\nsns.pointplot(data=tips, x='day', y='total_bill', hue='sex', \n              ax=axes[1, 0])\naxes[1, 0].set_title('Point Plot with Confidence Intervals')\n\n# 5. Categorical scatter\nsns.catplot(data=tips, x='day', y='total_bill', \n            col='time', kind='swarm', height=4)\naxes[1, 1].text(0.5, 0.5, 'See separate catplot', \n                ha='center', va='center')\naxes[1, 1].set_title('Catplot')\n\n# 6. Box-and-whisker with points\nsns.boxplot(data=tips, x='time', y='tip', ax=axes[1, 2])\nsns.stripplot(data=tips, x='time', y='tip', \n              color='black', alpha=0.3, ax=axes[1, 2])\naxes[1, 2].set_title('Box Plot with Points')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression and Relationships\n\n# Regression plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# 1. Simple regression\nsns.regplot(data=penguins, x='bill_length_mm', y='bill_depth_mm', \n            ax=axes[0, 0])\naxes[0, 0].set_title('Simple Linear Regression')\n\n# 2. Regression by groups\nsns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g', \n                hue='species', ax=axes[0, 1])\nfor species in penguins['species'].unique():\n    data = penguins[penguins['species'] == species]\n    sns.regplot(data=data, x='flipper_length_mm', y='body_mass_g', \n                scatter=False, ax=axes[0, 1])\naxes[0, 1].set_title('Regression by Species')\n\n# 3. Residual plot\nsns.residplot(data=penguins, x='bill_length_mm', y='body_mass_g', \n              ax=axes[1, 0])\naxes[1, 0].set_title('Residual Plot')\naxes[1, 0].axhline(y=0, color='red', linestyle='--')\n\n# 4. Polynomial regression\nsns.regplot(data=penguins, x='bill_length_mm', y='body_mass_g', \n            order=2, ax=axes[1, 1])\naxes[1, 1].set_title('Polynomial Regression (order=2)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nHeatmaps and Correlation\n\n# Correlation analysis\nnumeric_cols = penguins.select_dtypes(include=[np.number]).columns\ncorrelation_matrix = penguins[numeric_cols].corr()\n\n# Create heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, \n            annot=True,  # Show values\n            fmt='.2f',   # Format to 2 decimal places\n            cmap='coolwarm',  # Color scheme\n            center=0,    # Center colormap at 0\n            square=True, # Square cells\n            linewidths=1,  # Grid lines\n            cbar_kws={\"shrink\": 0.8})\n\nplt.title('Correlation Heatmap - Palmer Penguins', fontsize=16, pad=20)\nplt.show()\n\n# Clustermap for hierarchical clustering\ng = sns.clustermap(correlation_matrix, \n                   cmap='coolwarm', \n                   annot=True, \n                   fmt='.2f',\n                   figsize=(10, 10))\ng.fig.suptitle('Hierarchical Clustering of Features', y=1.02)\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-3-multi-panel-figures",
    "href": "pages/plotting_expanded.html#part-3-multi-panel-figures",
    "title": "Data Visualization with Python",
    "section": "Part 3: Multi-Panel Figures",
    "text": "Part 3: Multi-Panel Figures\nCreating complex layouts and faceted plots.\n\n# FacetGrid for exploring relationships\ng = sns.FacetGrid(penguins, col='island', row='sex', \n                  hue='species', height=3, aspect=1.2)\ng.map(sns.scatterplot, 'bill_length_mm', 'bill_depth_mm', alpha=0.7)\ng.add_legend()\ng.fig.suptitle('Bill Dimensions by Island and Sex', y=1.02)\nplt.show()\n\n# PairGrid for comprehensive comparisons\ng = sns.PairGrid(penguins, hue='species', \n                 vars=['bill_length_mm', 'bill_depth_mm', \n                       'flipper_length_mm', 'body_mass_g'])\ng.map_diag(sns.histplot)\ng.map_upper(sns.scatterplot, alpha=0.7)\ng.map_lower(sns.kdeplot)\ng.add_legend()\ng.fig.suptitle('Comprehensive Feature Comparison', y=1.02)\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-4-time-series-visualization",
    "href": "pages/plotting_expanded.html#part-4-time-series-visualization",
    "title": "Data Visualization with Python",
    "section": "Part 4: Time Series Visualization",
    "text": "Part 4: Time Series Visualization\n\n# Time series plots\nfig, axes = plt.subplots(3, 1, figsize=(14, 10))\n\n# 1. Basic time series\naxes[0].plot(ts_data['date'], ts_data['value'], linewidth=1)\naxes[0].set_title('Stock Price Over Time')\naxes[0].set_ylabel('Price ($)')\naxes[0].grid(True, alpha=0.3)\n\n# 2. Moving averages\nts_data['MA7'] = ts_data['value'].rolling(window=7).mean()\nts_data['MA30'] = ts_data['value'].rolling(window=30).mean()\n\naxes[1].plot(ts_data['date'], ts_data['value'], \n             label='Daily', alpha=0.5, linewidth=0.5)\naxes[1].plot(ts_data['date'], ts_data['MA7'], \n             label='7-day MA', linewidth=2)\naxes[1].plot(ts_data['date'], ts_data['MA30'], \n             label='30-day MA', linewidth=2)\naxes[1].set_title('Price with Moving Averages')\naxes[1].set_ylabel('Price ($)')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n# 3. Volume bars\naxes[2].bar(ts_data['date'], ts_data['volume'], width=1, alpha=0.7)\naxes[2].set_title('Daily Trading Volume')\naxes[2].set_ylabel('Volume')\naxes[2].set_xlabel('Date')\n\n# Format x-axis\nfor ax in axes:\n    ax.xaxis.set_major_locator(plt.MaxNLocator(6))\n    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-5-interactive-visualizations-with-plotly",
    "href": "pages/plotting_expanded.html#part-5-interactive-visualizations-with-plotly",
    "title": "Data Visualization with Python",
    "section": "Part 5: Interactive Visualizations with Plotly",
    "text": "Part 5: Interactive Visualizations with Plotly\n\n# Interactive scatter plot\nfig = px.scatter(penguins, \n                 x='bill_length_mm', \n                 y='bill_depth_mm',\n                 color='species',\n                 size='body_mass_g',\n                 hover_data=['island', 'sex'],\n                 title='Interactive Penguin Data Explorer',\n                 labels={'bill_length_mm': 'Bill Length (mm)',\n                        'bill_depth_mm': 'Bill Depth (mm)'})\n\nfig.update_layout(height=600)\nfig.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 2\n      1 # Interactive scatter plot\n----&gt; 2 fig = px.scatter(penguins, \n      3                  x='bill_length_mm', \n      4                  y='bill_depth_mm',\n      5                  color='species',\n      6                  size='body_mass_g',\n      7                  hover_data=['island', 'sex'],\n      8                  title='Interactive Penguin Data Explorer',\n      9                  labels={'bill_length_mm': 'Bill Length (mm)',\n     10                         'bill_depth_mm': 'Bill Depth (mm)'})\n     12 fig.update_layout(height=600)\n     13 fig.show()\n\nNameError: name 'px' is not defined\n\n\n\n\n# 3D scatter plot\nfig = px.scatter_3d(penguins,\n                    x='bill_length_mm',\n                    y='bill_depth_mm',\n                    z='flipper_length_mm',\n                    color='species',\n                    size='body_mass_g',\n                    hover_name='species',\n                    title='3D Penguin Measurements')\n\nfig.update_layout(height=700)\nfig.show()\n\n\n# Interactive time series\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=ts_data['date'], y=ts_data['value'],\n                         mode='lines',\n                         name='Price',\n                         line=dict(width=1)))\n\nfig.add_trace(go.Scatter(x=ts_data['date'], y=ts_data['MA7'],\n                         mode='lines',\n                         name='7-day MA',\n                         line=dict(width=2)))\n\nfig.add_trace(go.Scatter(x=ts_data['date'], y=ts_data['MA30'],\n                         mode='lines',\n                         name='30-day MA',\n                         line=dict(width=2)))\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.update_layout(title='Interactive Time Series with Range Slider',\n                  height=600)\nfig.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-6-advanced-customization",
    "href": "pages/plotting_expanded.html#part-6-advanced-customization",
    "title": "Data Visualization with Python",
    "section": "Part 6: Advanced Customization",
    "text": "Part 6: Advanced Customization\n\nCustom Color Palettes\n\n# Define custom colors\ncustom_palette = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n\n# Apply custom palette\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: Default colors\nplt.subplot(1, 2, 1)\nsns.barplot(data=tips.groupby('day')['total_bill'].mean().reset_index(),\n            x='day', y='total_bill')\nplt.title('Default Colors')\n\n# Subplot 2: Custom colors\nplt.subplot(1, 2, 2)\nsns.barplot(data=tips.groupby('day')['total_bill'].mean().reset_index(),\n            x='day', y='total_bill',\n            palette=custom_palette[:4])\nplt.title('Custom Colors')\n\nplt.tight_layout()\nplt.show()\n\n# Show available color palettes\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\npalettes = ['deep', 'pastel', 'dark', 'colorblind', 'husl', 'Set2']\n\nfor ax, palette in zip(axes.flat, palettes):\n    sns.barplot(data=tips.groupby('day')['total_bill'].mean().reset_index(),\n                x='day', y='total_bill',\n                palette=palette, ax=ax)\n    ax.set_title(f'Palette: {palette}')\n\nplt.tight_layout()\nplt.show()\n\n\n\nAnnotations and Text\n\n# Advanced annotations\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Create base plot\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\nax.plot(x, y1, 'b-', linewidth=2, label='sin(x)')\nax.plot(x, y2, 'r-', linewidth=2, label='cos(x)')\n\n# Add various annotations\n# 1. Simple text\nax.text(5, 0.5, 'Trigonometric Functions', \n        fontsize=14, ha='center',\n        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# 2. Arrow annotation\nax.annotate('Maximum', xy=(np.pi/2, 1), xytext=(np.pi/2 + 1, 0.8),\n            arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=0.3'),\n            fontsize=12)\n\n# 3. Highlight region\nax.axvspan(3, 5, alpha=0.2, color='yellow', label='Region of Interest')\n\n# 4. Mathematical expression\nax.text(8, -0.5, r'$\\int_{0}^{\\pi} \\sin(x)dx = 2$', \n        fontsize=14, color='green')\n\n# 5. Add value labels\nfor i in range(0, 11, 2):\n    ax.plot(i, np.sin(i), 'bo', markersize=8)\n    ax.text(i, np.sin(i) + 0.1, f'{np.sin(i):.2f}', \n            ha='center', fontsize=10)\n\nax.set_xlabel('x', fontsize=12)\nax.set_ylabel('y', fontsize=12)\nax.set_title('Advanced Annotations Example', fontsize=16, fontweight='bold')\nax.legend(loc='upper right')\nax.grid(True, alpha=0.3)\n\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#part-7-saving-and-exporting-plots",
    "href": "pages/plotting_expanded.html#part-7-saving-and-exporting-plots",
    "title": "Data Visualization with Python",
    "section": "Part 7: Saving and Exporting Plots",
    "text": "Part 7: Saving and Exporting Plots\n\n# Create a publication-quality figure\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot data\nsns.scatterplot(data=penguins, x='bill_length_mm', y='bill_depth_mm',\n                hue='species', style='sex', s=100, ax=ax)\n\n# Customize for publication\nax.set_xlabel('Bill Length (mm)', fontsize=12)\nax.set_ylabel('Bill Depth (mm)', fontsize=12)\nax.set_title('Palmer Penguins Bill Morphology', fontsize=14, fontweight='bold')\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Save in multiple formats\n# High-resolution PNG\nplt.savefig('penguin_plot.png', dpi=300, bbox_inches='tight')\n\n# Vector format for publications\nplt.savefig('penguin_plot.pdf', bbox_inches='tight')\n\n# SVG for web\nplt.savefig('penguin_plot.svg', bbox_inches='tight')\n\nprint(\"Plots saved as:\")\nprint(\"- penguin_plot.png (300 DPI)\")\nprint(\"- penguin_plot.pdf (vector)\")\nprint(\"- penguin_plot.svg (web)\")\n\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#best-practices-and-tips",
    "href": "pages/plotting_expanded.html#best-practices-and-tips",
    "title": "Data Visualization with Python",
    "section": "Best Practices and Tips",
    "text": "Best Practices and Tips\n\n1. Choose the Right Plot Type\n\n\n\nData Type\nRecommended Plots\n\n\n\n\nDistributions\nHistogram, KDE, Box plot, Violin plot\n\n\nRelationships\nScatter plot, Line plot, Regression plot\n\n\nComparisons\nBar plot, Grouped bar, Heatmap\n\n\nProportions\nPie chart, Stacked bar, Treemap\n\n\nTime Series\nLine plot, Area plot, Candlestick\n\n\nMultivariate\nPair plot, Parallel coordinates, PCA plot\n\n\n\n\n\n2. Color Guidelines\n\nUse colorblind-friendly palettes\nLimit to 5-7 distinct colors\nUse color meaningfully (not just decoratively)\nConsider grayscale printing\n\n\n\n3. Text and Labels\n\nAlways label axes with units\nUse descriptive titles\nKeep text readable (min 8pt font)\nAvoid overlapping labels\n\n\n\n4. Performance Tips\n\nFor large datasets (&gt;10k points), consider:\n\nSampling or aggregation\nRasterization for scatter plots\nInteractive tools like Plotly or Bokeh\nDatashader for millions of points"
  },
  {
    "objectID": "pages/plotting_expanded.html#exercises",
    "href": "pages/plotting_expanded.html#exercises",
    "title": "Data Visualization with Python",
    "section": "Exercises",
    "text": "Exercises\nTry these exercises to practice your visualization skills:\n\nBasic: Create a figure with 4 subplots showing different aspects of the tips dataset\nIntermediate: Build an interactive dashboard with Plotly showing penguin data\nAdvanced: Create a custom visualization function that automatically chooses the best plot type based on data types\n\n\nExercise 1 Solution Starter\n\n# Exercise 1: Your code here\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Add your plots here\n# Hint: Try different plot types for different relationships in the tips data\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "pages/plotting_expanded.html#resources-and-further-learning",
    "href": "pages/plotting_expanded.html#resources-and-further-learning",
    "title": "Data Visualization with Python",
    "section": "Resources and Further Learning",
    "text": "Resources and Further Learning\n\nDocumentation\n\nMatplotlib Documentation\nSeaborn Tutorial\nPlotly Python\n\n\n\nGalleries and Examples\n\nMatplotlib Gallery\nSeaborn Gallery\nPython Graph Gallery\n\n\n\nBooks and Courses\n\n“Fundamentals of Data Visualization” by Claus O. Wilke\n“Storytelling with Data” by Cole Nussbaumer Knaflic\n\n\n\nColor Resources\n\nColorBrewer\nCoolors\nAdobe Color"
  },
  {
    "objectID": "pages/plotting_expanded.html#summary",
    "href": "pages/plotting_expanded.html#summary",
    "title": "Data Visualization with Python",
    "section": "Summary",
    "text": "Summary\nYou’ve learned: - Matplotlib: Low-level control for custom plots - Seaborn: Statistical visualizations with less code - Plotly: Interactive and 3D visualizations - Best Practices: How to create effective, beautiful visualizations\nRemember: Good visualization is about clarity, not complexity. Start simple, then add complexity only when it adds value!"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html",
    "href": "pages/numpy_pandas_comprehensive.html",
    "title": "NumPy and Pandas Mastery",
    "section": "",
    "text": "NumPy and Pandas are the foundation of data science in Python:\n\nNumPy: Efficient numerical computing with arrays\nPandas: Data manipulation and analysis with DataFrames\n\nThis comprehensive tutorial will take you from basics to advanced techniques.\n\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Display settings\npd.set_option('display.max_columns', 10)\npd.set_option('display.max_rows', 10)\npd.set_option('display.precision', 3)\nsns.set_theme(style='whitegrid')\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#introduction",
    "href": "pages/numpy_pandas_comprehensive.html#introduction",
    "title": "NumPy and Pandas Mastery",
    "section": "",
    "text": "NumPy and Pandas are the foundation of data science in Python:\n\nNumPy: Efficient numerical computing with arrays\nPandas: Data manipulation and analysis with DataFrames\n\nThis comprehensive tutorial will take you from basics to advanced techniques.\n\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Display settings\npd.set_option('display.max_columns', 10)\npd.set_option('display.max_rows', 10)\npd.set_option('display.precision', 3)\nsns.set_theme(style='whitegrid')\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#why-numpy",
    "href": "pages/numpy_pandas_comprehensive.html#why-numpy",
    "title": "NumPy and Pandas Mastery",
    "section": "Why NumPy?",
    "text": "Why NumPy?\nNumPy provides: - Fast operations on arrays (10-100x faster than lists) - Broadcasting for element-wise operations - Mathematical functions - Linear algebra operations - Random number generation"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#creating-arrays",
    "href": "pages/numpy_pandas_comprehensive.html#creating-arrays",
    "title": "NumPy and Pandas Mastery",
    "section": "Creating Arrays",
    "text": "Creating Arrays\n\n# From lists\narr1 = np.array([1, 2, 3, 4, 5])\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\n\nprint(\"1D array:\", arr1)\nprint(\"2D array:\\n\", arr2)\nprint(f\"Shape: {arr2.shape}, Dimensions: {arr2.ndim}, Size: {arr2.size}\")\n\n\n# Special arrays\nzeros = np.zeros((3, 4))           # 3x4 matrix of zeros\nones = np.ones((2, 3, 4))          # 2x3x4 tensor of ones\nidentity = np.eye(4)               # 4x4 identity matrix\nrandom = np.random.rand(3, 3)      # 3x3 random values [0,1)\n\n# Sequences\nsequence = np.arange(0, 10, 2)     # [0, 2, 4, 6, 8]\nlinspace = np.linspace(0, 1, 5)    # 5 points from 0 to 1\n\nprint(\"Zeros:\\n\", zeros)\nprint(\"\\nIdentity:\\n\", identity)\nprint(\"\\nSequence:\", sequence)\nprint(\"Linspace:\", linspace)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#array-operations",
    "href": "pages/numpy_pandas_comprehensive.html#array-operations",
    "title": "NumPy and Pandas Mastery",
    "section": "Array Operations",
    "text": "Array Operations\n\n# Element-wise operations\na = np.array([1, 2, 3, 4])\nb = np.array([5, 6, 7, 8])\n\nprint(\"Addition:\", a + b)\nprint(\"Multiplication:\", a * b)\nprint(\"Power:\", a ** 2)\nprint(\"Boolean:\", a &gt; 2)\n\n# Mathematical functions\nprint(\"\\nSqrt:\", np.sqrt(a))\nprint(\"Exp:\", np.exp(a))\nprint(\"Log:\", np.log(a + 1))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#broadcasting",
    "href": "pages/numpy_pandas_comprehensive.html#broadcasting",
    "title": "NumPy and Pandas Mastery",
    "section": "Broadcasting",
    "text": "Broadcasting\nNumPy’s powerful feature for operations on arrays of different shapes:\n\n# Broadcasting examples\nmatrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Add scalar to matrix\nprint(\"Matrix + 10:\")\nprint(matrix + 10)\n\n# Add vector to each row\nrow_vector = np.array([1, 0, -1])\nprint(\"\\nMatrix + row vector:\")\nprint(matrix + row_vector)\n\n# Add vector to each column\ncol_vector = np.array([[10], [20], [30]])\nprint(\"\\nMatrix + column vector:\")\nprint(matrix + col_vector)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#indexing-and-slicing",
    "href": "pages/numpy_pandas_comprehensive.html#indexing-and-slicing",
    "title": "NumPy and Pandas Mastery",
    "section": "Indexing and Slicing",
    "text": "Indexing and Slicing\n\n# 2D array indexing\narr = np.array([[1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]])\n\nprint(\"Original array:\")\nprint(arr)\n\n# Access elements\nprint(\"\\nElement [1,2]:\", arr[1, 2])  # Row 1, Column 2\nprint(\"First row:\", arr[0, :])         # or arr[0]\nprint(\"Last column:\", arr[:, -1])\n\n# Slicing\nprint(\"\\nSubmatrix [0:2, 1:3]:\")\nprint(arr[0:2, 1:3])\n\n# Boolean indexing\nmask = arr &gt; 5\nprint(\"\\nElements &gt; 5:\", arr[mask])"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#array-manipulation",
    "href": "pages/numpy_pandas_comprehensive.html#array-manipulation",
    "title": "NumPy and Pandas Mastery",
    "section": "Array Manipulation",
    "text": "Array Manipulation\n\n# Reshaping\na = np.arange(12)\nprint(\"Original:\", a)\nprint(\"Reshaped to 3x4:\")\nprint(a.reshape(3, 4))\nprint(\"Reshaped to 2x2x3:\")\nprint(a.reshape(2, 2, 3))\n\n# Stacking\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\nprint(\"\\nVertical stack:\")\nprint(np.vstack([a, b]))\nprint(\"Horizontal stack:\")\nprint(np.hstack([a, b]))\n\n# Splitting\narr = np.arange(9).reshape(3, 3)\nprint(\"\\nOriginal:\")\nprint(arr)\nprint(\"Split horizontally:\", np.hsplit(arr, 3))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#statistical-operations",
    "href": "pages/numpy_pandas_comprehensive.html#statistical-operations",
    "title": "NumPy and Pandas Mastery",
    "section": "Statistical Operations",
    "text": "Statistical Operations\n\n# Generate sample data\ndata = np.random.randn(1000)  # Normal distribution\n\nprint(f\"Mean: {np.mean(data):.3f}\")\nprint(f\"Median: {np.median(data):.3f}\")\nprint(f\"Std Dev: {np.std(data):.3f}\")\nprint(f\"Variance: {np.var(data):.3f}\")\nprint(f\"Min: {np.min(data):.3f}\")\nprint(f\"Max: {np.max(data):.3f}\")\nprint(f\"25th percentile: {np.percentile(data, 25):.3f}\")\nprint(f\"75th percentile: {np.percentile(data, 75):.3f}\")\n\n# Axis operations\nmatrix = np.random.randn(3, 4)\nprint(\"\\nMatrix:\")\nprint(matrix)\nprint(\"Column means:\", np.mean(matrix, axis=0))\nprint(\"Row means:\", np.mean(matrix, axis=1))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#linear-algebra",
    "href": "pages/numpy_pandas_comprehensive.html#linear-algebra",
    "title": "NumPy and Pandas Mastery",
    "section": "Linear Algebra",
    "text": "Linear Algebra\n\n# Matrix operations\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[5, 6], [7, 8]])\n\nprint(\"Matrix A:\")\nprint(A)\nprint(\"\\nMatrix B:\")\nprint(B)\n\n# Matrix multiplication\nprint(\"\\nA @ B (matrix product):\")\nprint(A @ B)  # or np.dot(A, B)\n\n# Other operations\nprint(\"\\nTranspose of A:\")\nprint(A.T)\nprint(\"\\nDeterminant of A:\", np.linalg.det(A))\nprint(\"\\nInverse of A:\")\nprint(np.linalg.inv(A))\n\n# Eigenvalues and eigenvectors\neigenvalues, eigenvectors = np.linalg.eig(A)\nprint(\"\\nEigenvalues:\", eigenvalues)\nprint(\"Eigenvectors:\")\nprint(eigenvectors)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#why-pandas",
    "href": "pages/numpy_pandas_comprehensive.html#why-pandas",
    "title": "NumPy and Pandas Mastery",
    "section": "Why Pandas?",
    "text": "Why Pandas?\nPandas provides: - DataFrames for tabular data - Missing data handling - Data alignment and merging - Time series functionality - Input/Output tools for various formats"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#creating-dataframes",
    "href": "pages/numpy_pandas_comprehensive.html#creating-dataframes",
    "title": "NumPy and Pandas Mastery",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames\n\n# From dictionary\ndf1 = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 28],\n    'city': ['NYC', 'LA', 'Chicago', 'Houston'],\n    'salary': [70000, 80000, 75000, 65000]\n})\n\n# From lists\ndf2 = pd.DataFrame(\n    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n    columns=['A', 'B', 'C'],\n    index=['row1', 'row2', 'row3']\n)\n\n# From NumPy array\ndf3 = pd.DataFrame(\n    np.random.randn(5, 3),\n    columns=['X', 'Y', 'Z']\n)\n\nprint(\"DataFrame from dictionary:\")\nprint(df1)\nprint(\"\\nDataFrame with custom index:\")\nprint(df2)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#data-exploration",
    "href": "pages/numpy_pandas_comprehensive.html#data-exploration",
    "title": "NumPy and Pandas Mastery",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n# Load sample data\ntips = sns.load_dataset('tips')\n\n# Basic information\nprint(\"Shape:\", tips.shape)\nprint(\"\\nFirst 5 rows:\")\nprint(tips.head())\nprint(\"\\nData types:\")\nprint(tips.dtypes)\nprint(\"\\nBasic statistics:\")\nprint(tips.describe())\nprint(\"\\nInfo:\")\ntips.info()"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#selecting-and-filtering-data",
    "href": "pages/numpy_pandas_comprehensive.html#selecting-and-filtering-data",
    "title": "NumPy and Pandas Mastery",
    "section": "Selecting and Filtering Data",
    "text": "Selecting and Filtering Data\n\n# Column selection\nprint(\"Single column (Series):\")\nprint(tips['total_bill'].head())\n\nprint(\"\\nMultiple columns (DataFrame):\")\nprint(tips[['total_bill', 'tip', 'day']].head())\n\n# Row selection with loc (label-based)\nprint(\"\\nRows 10-12, specific columns:\")\nprint(tips.loc[10:12, ['total_bill', 'tip', 'day']])\n\n# Row selection with iloc (position-based)\nprint(\"\\nRows 0-2, columns 0-2:\")\nprint(tips.iloc[0:3, 0:3])\n\n\n# Boolean filtering\n# Simple condition\nhigh_bills = tips[tips['total_bill'] &gt; 30]\nprint(f\"High bills (&gt;30): {len(high_bills)} rows\")\nprint(high_bills.head())\n\n# Multiple conditions\ndinner_high_tip = tips[(tips['time'] == 'Dinner') & (tips['tip'] &gt; 5)]\nprint(f\"\\nDinner with high tip: {len(dinner_high_tip)} rows\")\n\n# Using isin\nweekend = tips[tips['day'].isin(['Sat', 'Sun'])]\nprint(f\"\\nWeekend data: {len(weekend)} rows\")\n\n# Using query\nresult = tips.query('total_bill &gt; 30 and tip &gt; 5')\nprint(f\"\\nQuery result: {len(result)} rows\")"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#data-manipulation",
    "href": "pages/numpy_pandas_comprehensive.html#data-manipulation",
    "title": "NumPy and Pandas Mastery",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n\n# Adding columns\ntips_copy = tips.copy()\ntips_copy['tip_percentage'] = tips_copy['tip'] / tips_copy['total_bill'] * 100\ntips_copy['bill_per_person'] = tips_copy['total_bill'] / tips_copy['size']\n\nprint(\"New columns added:\")\nprint(tips_copy[['total_bill', 'tip', 'tip_percentage', 'bill_per_person']].head())\n\n# Modifying columns\ntips_copy['day_type'] = tips_copy['day'].apply(\n    lambda x: 'Weekend' if x in ['Sat', 'Sun'] else 'Weekday'\n)\n\n# Dropping columns\ntips_copy = tips_copy.drop(['bill_per_person'], axis=1)\n\n# Renaming columns\ntips_copy = tips_copy.rename(columns={'size': 'party_size'})\n\nprint(\"\\nModified DataFrame:\")\nprint(tips_copy.head())"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#handling-missing-data",
    "href": "pages/numpy_pandas_comprehensive.html#handling-missing-data",
    "title": "NumPy and Pandas Mastery",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\n\n# Create data with missing values\ndf_missing = pd.DataFrame({\n    'A': [1, 2, np.nan, 4, 5],\n    'B': [np.nan, 2, 3, np.nan, 5],\n    'C': [1, 2, 3, 4, 5],\n    'D': [np.nan, np.nan, np.nan, np.nan, 5]\n})\n\nprint(\"Data with missing values:\")\nprint(df_missing)\n\n# Check for missing values\nprint(\"\\nMissing values per column:\")\nprint(df_missing.isnull().sum())\n\n# Drop missing values\nprint(\"\\nDrop rows with any NaN:\")\nprint(df_missing.dropna())\n\nprint(\"\\nDrop columns with any NaN:\")\nprint(df_missing.dropna(axis=1))\n\n# Fill missing values\nprint(\"\\nFill with constant:\")\nprint(df_missing.fillna(0))\n\nprint(\"\\nForward fill:\")\nprint(df_missing.fillna(method='ffill'))\n\nprint(\"\\nFill with mean:\")\nprint(df_missing.fillna(df_missing.mean()))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#groupby-operations",
    "href": "pages/numpy_pandas_comprehensive.html#groupby-operations",
    "title": "NumPy and Pandas Mastery",
    "section": "GroupBy Operations",
    "text": "GroupBy Operations\n\n# Simple groupby\ngrouped = tips.groupby('day')\nprint(\"Mean by day:\")\nprint(grouped[['total_bill', 'tip']].mean())\n\n# Multiple grouping\nprint(\"\\nMean by day and time:\")\nprint(tips.groupby(['day', 'time'])['total_bill'].mean().unstack())\n\n# Multiple aggregations\nprint(\"\\nMultiple statistics:\")\nagg_result = tips.groupby('day').agg({\n    'total_bill': ['mean', 'std', 'count'],\n    'tip': ['mean', 'max']\n})\nprint(agg_result)\n\n\n# Transform - returns same-sized result\ntips['bill_zscore'] = tips.groupby('day')['total_bill'].transform(\n    lambda x: (x - x.mean()) / x.std()\n)\n\nprint(\"Z-scores by day:\")\nprint(tips[['day', 'total_bill', 'bill_zscore']].head(10))\n\n# Apply - flexible operation\ndef top_tips(df, n=3):\n    return df.nlargest(n, 'tip')[['total_bill', 'tip']]\n\nprint(\"\\nTop 3 tips per day:\")\nprint(tips.groupby('day').apply(top_tips))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#merging-and-joining",
    "href": "pages/numpy_pandas_comprehensive.html#merging-and-joining",
    "title": "NumPy and Pandas Mastery",
    "section": "Merging and Joining",
    "text": "Merging and Joining\n\n# Create sample DataFrames\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'city': ['NYC', 'LA', 'Chicago', 'Houston']\n})\n\norders = pd.DataFrame({\n    'order_id': [101, 102, 103, 104, 105],\n    'customer_id': [1, 2, 1, 3, 5],\n    'amount': [250, 150, 300, 200, 175]\n})\n\nprint(\"Customers:\")\nprint(customers)\nprint(\"\\nOrders:\")\nprint(orders)\n\n# Different join types\nprint(\"\\nInner join:\")\nprint(pd.merge(customers, orders, on='customer_id', how='inner'))\n\nprint(\"\\nLeft join:\")\nprint(pd.merge(customers, orders, on='customer_id', how='left'))\n\nprint(\"\\nOuter join:\")\nprint(pd.merge(customers, orders, on='customer_id', how='outer'))"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#pivot-tables-and-reshaping",
    "href": "pages/numpy_pandas_comprehensive.html#pivot-tables-and-reshaping",
    "title": "NumPy and Pandas Mastery",
    "section": "Pivot Tables and Reshaping",
    "text": "Pivot Tables and Reshaping\n\n# Pivot table\npivot = tips.pivot_table(\n    values='total_bill',\n    index='day',\n    columns='time',\n    aggfunc='mean'\n)\nprint(\"Pivot table - mean bill by day and time:\")\nprint(pivot)\n\n# Melt (unpivot)\nmelted = pivot.reset_index().melt(\n    id_vars='day',\n    var_name='time',\n    value_name='avg_bill'\n)\nprint(\"\\nMelted data:\")\nprint(melted)\n\n# Stack and unstack\nstacked = tips.groupby(['day', 'time'])['total_bill'].mean()\nprint(\"\\nStacked:\")\nprint(stacked)\nprint(\"\\nUnstacked:\")\nprint(stacked.unstack())"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#time-series",
    "href": "pages/numpy_pandas_comprehensive.html#time-series",
    "title": "NumPy and Pandas Mastery",
    "section": "Time Series",
    "text": "Time Series\n\n# Create time series data\ndates = pd.date_range('2023-01-01', periods=365, freq='D')\nts = pd.Series(np.random.randn(365).cumsum() + 100, index=dates)\n\nprint(\"Time series data:\")\nprint(ts.head())\n\n# Resampling\nmonthly = ts.resample('M').mean()\nprint(\"\\nMonthly average:\")\nprint(monthly)\n\n# Rolling operations\nrolling_mean = ts.rolling(window=30).mean()\nrolling_std = ts.rolling(window=30).std()\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 6))\nts.plot(ax=ax, label='Daily', alpha=0.5)\nrolling_mean.plot(ax=ax, label='30-day MA', linewidth=2)\nax.fill_between(rolling_mean.index, \n                rolling_mean - 2*rolling_std,\n                rolling_mean + 2*rolling_std,\n                alpha=0.2, label='±2 STD')\nax.legend()\nax.set_title('Time Series with Moving Average')\nplt.show()"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#string-operations",
    "href": "pages/numpy_pandas_comprehensive.html#string-operations",
    "title": "NumPy and Pandas Mastery",
    "section": "String Operations",
    "text": "String Operations\n\n# String data\ndf = pd.DataFrame({\n    'name': ['John Smith', 'jane doe', 'Bob JONES', 'alice wonderland'],\n    'email': ['john@email.com', 'JANE@GMAIL.COM', 'bob@yahoo.com', 'alice@outlook.com']\n})\n\nprint(\"Original:\")\nprint(df)\n\n# String methods\ndf['name_upper'] = df['name'].str.upper()\ndf['name_title'] = df['name'].str.title()\ndf['first_name'] = df['name'].str.split().str[0]\ndf['email_domain'] = df['email'].str.split('@').str[1].str.lower()\ndf['name_length'] = df['name'].str.len()\n\nprint(\"\\nProcessed:\")\nprint(df)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#categorical-data",
    "href": "pages/numpy_pandas_comprehensive.html#categorical-data",
    "title": "NumPy and Pandas Mastery",
    "section": "Categorical Data",
    "text": "Categorical Data\n\n# Create categorical data\ndf = pd.DataFrame({\n    'grade': ['A', 'B', 'A', 'C', 'B', 'A', 'D', 'C'],\n    'score': [95, 85, 92, 75, 88, 96, 65, 78]\n})\n\n# Convert to categorical\ndf['grade'] = pd.Categorical(\n    df['grade'],\n    categories=['D', 'C', 'B', 'A'],\n    ordered=True\n)\n\nprint(\"Categorical data:\")\nprint(df)\nprint(\"\\nCategories:\", df['grade'].cat.categories)\nprint(\"Ordered:\", df['grade'].cat.ordered)\n\n# Sort by categorical order\nprint(\"\\nSorted by grade:\")\nprint(df.sort_values('grade'))\n\n# Filter using categorical order\nprint(\"\\nGrades better than C:\")\nprint(df[df['grade'] &gt; 'C'])"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#example-1-data-cleaning-pipeline",
    "href": "pages/numpy_pandas_comprehensive.html#example-1-data-cleaning-pipeline",
    "title": "NumPy and Pandas Mastery",
    "section": "Example 1: Data Cleaning Pipeline",
    "text": "Example 1: Data Cleaning Pipeline\n\n# Create messy data\nmessy_data = pd.DataFrame({\n    'Date': ['2023-01-01', '2023-01-02', '2023/01/03', '01-04-2023', None],\n    'Amount': ['$1,234.56', '2345.67', '$3,456.78', 'N/A', '4567.89'],\n    'Category': ['Food', 'food', 'FOOD', 'Transport', None],\n    'Status': ['Complete', 'complete', 'PENDING', 'pending', 'Complete']\n})\n\nprint(\"Messy data:\")\nprint(messy_data)\n\ndef clean_data(df):\n    \"\"\"Clean and standardize the data\"\"\"\n    df = df.copy()\n    \n    # Clean dates\n    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n    \n    # Clean amounts\n    df['Amount'] = (df['Amount']\n                   .str.replace('$', '', regex=False)\n                   .str.replace(',', '', regex=False)\n                   .replace('N/A', np.nan))\n    df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n    \n    # Standardize categories\n    df['Category'] = df['Category'].str.title()\n    df['Category'] = df['Category'].fillna('Unknown')\n    \n    # Standardize status\n    df['Status'] = df['Status'].str.title()\n    \n    # Remove rows with critical missing data\n    df = df.dropna(subset=['Date', 'Amount'])\n    \n    return df\n\nclean = clean_data(messy_data)\nprint(\"\\nCleaned data:\")\nprint(clean)\nprint(\"\\nData types:\")\nprint(clean.dtypes)"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#example-2-sales-analysis",
    "href": "pages/numpy_pandas_comprehensive.html#example-2-sales-analysis",
    "title": "NumPy and Pandas Mastery",
    "section": "Example 2: Sales Analysis",
    "text": "Example 2: Sales Analysis\n\n# Generate sales data\nnp.random.seed(42)\nn_records = 1000\n\nsales = pd.DataFrame({\n    'date': pd.date_range('2023-01-01', periods=n_records, freq='H'),\n    'product': np.random.choice(['A', 'B', 'C', 'D'], n_records),\n    'quantity': np.random.poisson(10, n_records),\n    'price': np.random.uniform(10, 100, n_records),\n    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records)\n})\n\nsales['revenue'] = sales['quantity'] * sales['price']\n\n# Analysis\nprint(\"Sales Summary:\")\nprint(sales.describe())\n\n# Daily aggregation\ndaily_sales = sales.set_index('date').resample('D').agg({\n    'quantity': 'sum',\n    'revenue': 'sum',\n    'price': 'mean'\n})\n\nprint(\"\\nDaily sales (first week):\")\nprint(daily_sales.head(7))\n\n# Product performance\nproduct_performance = sales.groupby('product').agg({\n    'quantity': 'sum',\n    'revenue': ['sum', 'mean'],\n    'price': 'mean'\n}).round(2)\n\nprint(\"\\nProduct Performance:\")\nprint(product_performance)\n\n# Regional analysis\nregional = sales.pivot_table(\n    values='revenue',\n    index='product',\n    columns='region',\n    aggfunc='sum'\n).round(2)\n\nprint(\"\\nRevenue by Product and Region:\")\nprint(regional)\n\n# Visualization\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Daily revenue trend\ndaily_sales['revenue'].plot(ax=axes[0, 0])\naxes[0, 0].set_title('Daily Revenue Trend')\naxes[0, 0].set_ylabel('Revenue ($)')\n\n# Product distribution\nsales.groupby('product')['revenue'].sum().plot(kind='bar', ax=axes[0, 1])\naxes[0, 1].set_title('Total Revenue by Product')\naxes[0, 1].set_ylabel('Revenue ($)')\n\n# Regional distribution\nsales.groupby('region')['revenue'].sum().plot(kind='pie', ax=axes[1, 0], autopct='%1.1f%%')\naxes[1, 0].set_title('Revenue Distribution by Region')\n\n# Heatmap\nsns.heatmap(regional, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1, 1])\naxes[1, 1].set_title('Revenue Heatmap')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#performance-tips",
    "href": "pages/numpy_pandas_comprehensive.html#performance-tips",
    "title": "NumPy and Pandas Mastery",
    "section": "Performance Tips",
    "text": "Performance Tips\n\nNumPy Performance\n\nimport time\n\n# Vectorization vs loops\nsize = 1000000\na = np.random.randn(size)\nb = np.random.randn(size)\n\n# Loop method\nstart = time.time()\nresult_loop = []\nfor i in range(size):\n    result_loop.append(a[i] + b[i])\nloop_time = time.time() - start\n\n# Vectorized method\nstart = time.time()\nresult_vector = a + b\nvector_time = time.time() - start\n\nprint(f\"Loop time: {loop_time:.4f} seconds\")\nprint(f\"Vectorized time: {vector_time:.4f} seconds\")\nprint(f\"Speedup: {loop_time/vector_time:.1f}x\")\n\n\n\nPandas Performance\n\n# Efficient data types\ndf = pd.DataFrame({\n    'int_col': np.random.randint(0, 100, 10000),\n    'float_col': np.random.randn(10000),\n    'category_col': np.random.choice(['A', 'B', 'C'], 10000)\n})\n\nprint(\"Original memory usage:\")\nprint(df.memory_usage(deep=True))\n\n# Optimize data types\ndf['int_col'] = df['int_col'].astype('int8')  # Smaller int\ndf['float_col'] = df['float_col'].astype('float32')  # Smaller float\ndf['category_col'] = df['category_col'].astype('category')  # Categorical\n\nprint(\"\\nOptimized memory usage:\")\nprint(df.memory_usage(deep=True))\n\n# Use vectorized string operations\n# Bad: df['new'] = df['category_col'].apply(lambda x: x.lower())\n# Good: df['new'] = df['category_col'].str.lower()"
  },
  {
    "objectID": "pages/numpy_pandas_comprehensive.html#summary-and-best-practices-numpy-best-practices1.-use-vectorization-instead-of-loops2.-preallocate-arrays-when-size-is-known3.-use-appropriate-data-types-float32-vs-float644.-leverage-broadcasting-for-operations5.-use-views-instead-of-copies-when-possible-pandas-best-practices1.-use-vectorized-operations-.str-.dt-methods2.-optimize-data-types-categories-smaller-ints3.-use-.loc.iloc-for-explicit-indexing4.-chain-operations-for-readability5.-profile-memory-usage-for-large-datasets-when-to-use-what--numpy-numerical-computations-linear-algebra-image-processing--pandas-tabular-data-time-series-data-cleaning-analysis-resources--numpy-documentation--pandas-documentation--numpy-tutorial--pandas-tutorialmaster-these-libraries-and-youll-be-equipped-for-any-data-analysis-task",
    "href": "pages/numpy_pandas_comprehensive.html#summary-and-best-practices-numpy-best-practices1.-use-vectorization-instead-of-loops2.-preallocate-arrays-when-size-is-known3.-use-appropriate-data-types-float32-vs-float644.-leverage-broadcasting-for-operations5.-use-views-instead-of-copies-when-possible-pandas-best-practices1.-use-vectorized-operations-.str-.dt-methods2.-optimize-data-types-categories-smaller-ints3.-use-.loc.iloc-for-explicit-indexing4.-chain-operations-for-readability5.-profile-memory-usage-for-large-datasets-when-to-use-what--numpy-numerical-computations-linear-algebra-image-processing--pandas-tabular-data-time-series-data-cleaning-analysis-resources--numpy-documentation--pandas-documentation--numpy-tutorial--pandas-tutorialmaster-these-libraries-and-youll-be-equipped-for-any-data-analysis-task",
    "title": "NumPy and Pandas Mastery",
    "section": "Summary and Best Practices### NumPy Best Practices1. Use vectorization instead of loops2. Preallocate arrays when size is known3. Use appropriate data types (float32 vs float64)4. Leverage broadcasting for operations5. Use views instead of copies when possible### Pandas Best Practices1. Use vectorized operations (.str, .dt methods)2. Optimize data types (categories, smaller ints)3. Use .loc/.iloc for explicit indexing4. Chain operations for readability5. Profile memory usage for large datasets### When to Use What?- NumPy: Numerical computations, linear algebra, image processing- Pandas: Tabular data, time series, data cleaning, analysis### Resources- NumPy Documentation- Pandas Documentation- NumPy Tutorial- Pandas TutorialMaster these libraries and you’ll be equipped for any data analysis task!",
    "text": "Summary and Best Practices### NumPy Best Practices1. Use vectorization instead of loops2. Preallocate arrays when size is known3. Use appropriate data types (float32 vs float64)4. Leverage broadcasting for operations5. Use views instead of copies when possible### Pandas Best Practices1. Use vectorized operations (.str, .dt methods)2. Optimize data types (categories, smaller ints)3. Use .loc/.iloc for explicit indexing4. Chain operations for readability5. Profile memory usage for large datasets### When to Use What?- NumPy: Numerical computations, linear algebra, image processing- Pandas: Tabular data, time series, data cleaning, analysis### Resources- NumPy Documentation- Pandas Documentation- NumPy Tutorial- Pandas TutorialMaster these libraries and you’ll be equipped for any data analysis task!"
  },
  {
    "objectID": "pages/jupyterlab_complete.html",
    "href": "pages/jupyterlab_complete.html",
    "title": "JupyterLab Short Guide",
    "section": "",
    "text": "Menu Bar: File, Edit, View, Run, Kernel, Tabs, Settings, Help\nLeft Sidebar: File browser, running terminals/kernels, command palette, notebook tools\nMain Work Area: Where notebooks, terminals, and other documents open\nStatus Bar: Information about current activity and keyboard mode",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#the-jupyterlab-interface",
    "href": "pages/jupyterlab_complete.html#the-jupyterlab-interface",
    "title": "JupyterLab Short Guide",
    "section": "",
    "text": "Menu Bar: File, Edit, View, Run, Kernel, Tabs, Settings, Help\nLeft Sidebar: File browser, running terminals/kernels, command palette, notebook tools\nMain Work Area: Where notebooks, terminals, and other documents open\nStatus Bar: Information about current activity and keyboard mode",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#working-with-notebooks",
    "href": "pages/jupyterlab_complete.html#working-with-notebooks",
    "title": "JupyterLab Short Guide",
    "section": "Working with Notebooks",
    "text": "Working with Notebooks\n\nCreating a New Notebook\n\nClick the + button in the file browser\nSelect Python 3 (or another kernel)\nOr use File → New → Notebook",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#cell-types",
    "href": "pages/jupyterlab_complete.html#cell-types",
    "title": "JupyterLab Short Guide",
    "section": "Cell Types",
    "text": "Cell Types\nJupyter notebooks have three main cell types:\n\n1. Markdown Cells\nMarkdown cells contain formatted text, like this one. They support:\n\nHeaders at Different Levels\nBold and italic text. Inline code and links.\n\nLists\nof\nstuff\n\n\nNumbered\nones\ntoo\n\nAn empty line separates a one paragraph of text.\nFrom another paragraph of text.\nTwo spaces at the end makes the line break:\nQuestion 1: some text\nQuestion 2: some text\nQuestion 3: some text\n# Displayed code with syntax highlighting\ndef hello():\n    return \"Hello, World!\"\n\n\n\nsmall\ntable\n\n\n\n\nfoo\n2\n\n\nbar\n3\n\n\n\nHTML to include image with defined width or height:\n\nFormulas inline \\(E = mc^2\\) or displayed:\n\\[\\sum_{i=0}^n i\\]\n\n\n\n2. Raw Cells\nRaw cells contain unformatted text that won’t be executed. Useful for including literal text or code that shouldn’t run.\n\n\n3. Code Cells\nCode cells contain executable code:\n\n# This is a code cell\nprint(\"Hello, JupyterLab!\")\n\n# Variables are preserved between cells\nx = 42\nprint(f\"Result: {x}\")\n\nHello, JupyterLab!\nResult: 42\n\n\nBeginning a line with an exclamation mark (!) lets you to run shell commands directly from a code cell, displaying the output.\n\n! pwd\n\n/Users/kmt/franklin-ecosystem/franklin/docs/pages",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#best-practices",
    "href": "pages/jupyterlab_complete.html#best-practices",
    "title": "JupyterLab Short Guide",
    "section": "Best Practices",
    "text": "Best Practices\n\n1. Cell Organization\n\nKeep cells focused on one concept\nUse markdown cells for documentation\nGroup related code logically\n\n\n\n2. Reproducibility\n\nRun cells in order\nDon’t rely on execution order\nUse “Restart & Run All” to verify",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#essential-keyboard-shortcuts",
    "href": "pages/jupyterlab_complete.html#essential-keyboard-shortcuts",
    "title": "JupyterLab Short Guide",
    "section": "Essential Keyboard Shortcuts",
    "text": "Essential Keyboard Shortcuts\nJupyterLab has two modes: - Command Mode (blue cell border): Navigate and manipulate cells - Edit Mode (green cell border): Edit cell contents\n\nCommand Mode Shortcuts\n\n\n\nShortcut\nAction\n\n\n\n\nEnter\nEnter edit mode\n\n\nA\nInsert cell above\n\n\nB\nInsert cell below\n\n\nD, D\nDelete cell\n\n\nY\nChange to code cell\n\n\nM\nChange to markdown cell\n\n\nC\nCopy cell\n\n\nV\nPaste cell below\n\n\nShift + V\nPaste cell above\n\n\nZ\nUndo cell deletion\n\n\nShift + M\nMerge selected cells\n\n\n\n\n\nEdit Mode Shortcuts\n\n\n\nShortcut\nAction\n\n\n\n\nEsc\nEnter command mode\n\n\nCtrl + Enter\nRun cell\n\n\nShift + Enter\nRun cell, select below\n\n\nAlt + Enter\nRun cell, insert below\n\n\nTab\nCode completion/indent\n\n\nShift + Tab\nTooltip/dedent\n\n\nCtrl + ]\nIndent\n\n\nCtrl + [\nDedent\n\n\nCtrl + A\nSelect all\n\n\nCtrl + Z\nUndo",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#two-kinds-of-undo",
    "href": "pages/jupyterlab_complete.html#two-kinds-of-undo",
    "title": "JupyterLab Short Guide",
    "section": "Two kinds of “Undo”",
    "text": "Two kinds of “Undo”\n\nEdit/Undo to undo stuff in the current cell\nEdit/Undo Cell Operation to undo deleting, moving, merging cells",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#moving-and-copypaste-cells",
    "href": "pages/jupyterlab_complete.html#moving-and-copypaste-cells",
    "title": "JupyterLab Short Guide",
    "section": "Moving and copy/paste cells",
    "text": "Moving and copy/paste cells\nYou can drag cells, or use C and V in command mode to copy and paste cells. You can also use the Edit menu if it feels safer.\n\nprint(\"Move this cell somewhere\")\n\nMove this cell somewhere",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#spitting-ane-merging-cells",
    "href": "pages/jupyterlab_complete.html#spitting-ane-merging-cells",
    "title": "JupyterLab Short Guide",
    "section": "Spitting ane merging cells",
    "text": "Spitting ane merging cells\nYou do this using shortcuts or the menus. Try to split this cell into one containing only this.\nAnd one containing only this.\nThen merge them back together.",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#working-with-multiple-files",
    "href": "pages/jupyterlab_complete.html#working-with-multiple-files",
    "title": "JupyterLab Short Guide",
    "section": "Working with Multiple Files",
    "text": "Working with Multiple Files\n\nSplit View\n\nRight-click on a notebook tab\nSelect “New View for Notebook”\nDrag the new tab to create split view\n\n\n\nSide-by-Side Editing\n\nDrag tabs to arrange them horizontally or vertically\nUseful for comparing code or referencing documentation",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#managing-kernels",
    "href": "pages/jupyterlab_complete.html#managing-kernels",
    "title": "JupyterLab Short Guide",
    "section": "Managing Kernels",
    "text": "Managing Kernels\n\nKernel Operations\n\nRestart: Clear all variables and start fresh\nRestart & Run All: Restart and execute all cells\nInterrupt: Stop currently executing code\nShutdown: Close the kernel completely\n\nAccess via Kernel menu or keyboard shortcuts.",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#exporting-notebooks",
    "href": "pages/jupyterlab_complete.html#exporting-notebooks",
    "title": "JupyterLab Short Guide",
    "section": "Exporting Notebooks",
    "text": "Exporting Notebooks\n\nExport Formats\nJupyterLab can export notebooks to:\n\nHTML: Static web page\nPDF: Via LaTeX (requires LaTeX installation)\nMarkdown: Text format\nPython: Pure Python script\nLaTeX: For academic papers\n\nUse File → Export Notebook As...",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#running-code-cells",
    "href": "pages/jupyterlab_complete.html#running-code-cells",
    "title": "JupyterLab Short Guide",
    "section": "Running Code Cells",
    "text": "Running Code Cells\n\nBasic Execution\n\n# Run with Shift+Enter or Ctrl+Enter\ndef square(x):\n    return x ** 2\n\n# Last expression is displayed\nsquare(5)\n\n25\n\n\n\n\nVariables Persist Between Cells\n\n# Define variable in one cell\nmy_list = [1, 2, 3, 4, 5]\n\n\n# Use in another cell\nprint(f\"Sum: {sum(my_list)}\")\nprint(f\"Squared: {[square(x) for x in my_list]}\")\n\nSum: 15\nSquared: [1, 4, 9, 16, 25]\n\n\n\n\nMagic Commands\nJupyterLab supports IPython magic commands (with a % prefix) for enhanced functionality. E.g. list all variable names or a a table including types and values:\n\n%who\n\nmatplotlib   my_list     process_data    square  x   \n\n\n\n%whos\n\nVariable       Type        Data/Info\n------------------------------------\nmatplotlib     module      &lt;module 'matplotlib' from&lt;...&gt;/matplotlib/__init__.py'&gt;\nmy_list        list        n=5\nprocess_data   function    &lt;function process_data at 0x12e8dfa60&gt;\nsquare         function    &lt;function square at 0x12e91e480&gt;\nx              int         42",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "pages/jupyterlab_complete.html#rich-output-display",
    "href": "pages/jupyterlab_complete.html#rich-output-display",
    "title": "JupyterLab Short Guide",
    "section": "Rich Output Display",
    "text": "Rich Output Display\n\nDisplaying Data\n\nimport pandas as pd\n\n# DataFrames display as nice tables\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'City': ['New York', 'Paris', 'London']\n})\ndf\n\n\n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nParis\n\n\n2\nCharlie\n35\nLondon\n\n\n\n\n\n\n\n\n\nInline Plots and Visualizations\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create sample data\nx = np.linspace(0, 2*np.pi, 100)\ny_sin = np.sin(x)\ny_cos = np.cos(x)\n\n# Create an axis for each subplot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\n# Plot sine wave\nax1.plot(x, y_sin, 'b-', label='sin(x)')\nax1.set_title('Sine Wave')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\nax1.legend()\n\n# Plot cosine wave\nax2.plot(x, y_cos, 'r-', label='cos(x)')\nax2.set_title('Cosine Wave')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.legend()\n\nplt.tight_layout()",
    "crumbs": [
      "Tutorials",
      "JupyterLab Short Guide"
    ]
  },
  {
    "objectID": "notebooks/pdb.html",
    "href": "notebooks/pdb.html",
    "title": "franklin",
    "section": "",
    "text": "# PDB Protein Structure Analysis for Molecular Biology Education\n# A comprehensive notebook showcasing data science approaches to protein structures\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nimport requests\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# For protein structure visualization\nimport py3Dmol\nfrom IPython.display import display, HTML\n\n# For structural analysis\nfrom Bio import PDB\nfrom Bio.PDB import PDBParser, DSSP, MMCIFParser\nfrom Bio.PDB.Polypeptide import PPBuilder\nimport biotite.structure as struc\nimport biotite.structure.io as strucio\n\n\n\nprint(\"🧬 Welcome to Protein Structure Data Science!\")\nprint(\"This notebook demonstrates how to use the PDB database for teaching molecular biology\")\n\n# =============================================================================\n# SECTION 1: EXPLORING THE PDB DATABASE\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 1: EXPLORING THE PDB DATABASE\")\nprint(\"=\"*60)\n\n# Function to query PDB REST API\ndef query_pdb_summary():\n    \"\"\"Get summary statistics from PDB\"\"\"\n    url = \"https://data.rcsb.org/rest/v1/holdings\"\n    response = requests.get(url)\n    if response.status_code == 200:\n        return response.json()\n    return None\n\n# Get PDB summary stats\npdb_stats = query_pdb_summary()\nif pdb_stats:\n    print(f\"📊 Current PDB Statistics:\")\n    print(f\"Total structures: {pdb_stats.get('total_count', 'N/A'):,}\")\n    print(f\"Experimental methods available: {len(pdb_stats.get('experimental_method_counts', []))}\")\n\n# Query specific protein families for teaching examples\ndef search_pdb_advanced(query_terms, max_results=100):\n    \"\"\"Advanced PDB search using REST API\"\"\"\n    url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n    \n    query = {\n        \"query\": {\n            \"type\": \"group\",\n            \"logical_operator\": \"and\",\n            \"nodes\": [\n                {\n                    \"type\": \"terminal\",\n                    \"service\": \"text\",\n                    \"parameters\": {\n                        \"attribute\": \"rcsb_struct_symmetry.symbol\",\n                        \"operator\": \"exists\"\n                    }\n                }\n            ]\n        },\n        \"return_type\": \"entry\",\n        \"request_options\": {\n            \"return_all_hits\": False,\n            \"results_verbosity\": \"compact\",\n            \"sort\": [{\"sort_by\": \"score\", \"direction\": \"desc\"}]\n        }\n    }\n    \n    response = requests.post(url, json=query)\n    if response.status_code == 200:\n        return response.json()\n    return None\n\n# Create a curated dataset of interesting proteins for teaching\nteaching_proteins = {\n    'hemoglobin': ['1HHO', '2HHB', '1A3N'],  # Oxygen transport, quaternary structure\n    'lysozyme': ['1LYZ', '193L', '1LYS'],    # Classic enzyme, well-studied\n    'insulin': ['1MSO', '4INS', '1ZNI'],     # Hormone, medical relevance\n    'myoglobin': ['1MBO', '1A6M', '3RGK'],   # Oxygen storage, comparison with hemoglobin\n    'catalase': ['1DGH', '1GWE', '7CAT'],    # Antioxidant enzyme\n    'dna_polymerase': ['1KLN', '3EYI', '1TAU'] # DNA replication\n}\n\nprint(f\"\\n🎯 Teaching Dataset: {sum(len(v) for v in teaching_proteins.values())} curated structures\")\nprint(\"Categories:\", list(teaching_proteins.keys()))\n\n🧬 Welcome to Protein Structure Data Science!\nThis notebook demonstrates how to use the PDB database for teaching molecular biology\n\n============================================================\nSECTION 1: EXPLORING THE PDB DATABASE\n============================================================\n\n🎯 Teaching Dataset: 18 curated structures\nCategories: ['hemoglobin', 'lysozyme', 'insulin', 'myoglobin', 'catalase', 'dna_polymerase']\n\n\n\n\n# =============================================================================\n# SECTION 2: STRUCTURE VISUALIZATION WITH PY3DMOL\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 2: INTERACTIVE 3D STRUCTURE VISUALIZATION\")\nprint(\"=\"*60)\n\ndef create_protein_viewer(pdb_id, style='cartoon', color='spectrum', width=600, height=400):\n    \"\"\"Create an interactive 3D protein viewer\"\"\"\n    view = py3Dmol.view(query=f'pdb:{pdb_id}', width=width, height=height)\n    view.setStyle({style: {'color': color}})\n    view.zoomTo()\n    view.spin(True)\n    return view\n\n# Example 1: Basic protein visualization\nprint(\"🔬 Example 1: Hemoglobin (1HHO) - Oxygen Transport Protein\")\nhemo_viewer = create_protein_viewer('1HHO')\ndisplay(hemo_viewer)\n\n# Example 2: Comparing different visualization styles\ndef compare_visualization_styles(pdb_id):\n    \"\"\"Show the same protein in different visualization styles\"\"\"\n    styles = [\n        ('cartoon', 'spectrum', 'Cartoon representation'),\n        ('stick', 'element', 'Stick representation'),\n        ('sphere', 'hydrophobicity', 'Space-filling model'),\n        ('surface', 'white', 'Surface representation')\n    ]\n    \n    print(f\"🎨 Visualization Styles for {pdb_id}:\")\n    for style, color, description in styles:\n        print(f\"\\n{description}:\")\n        view = py3Dmol.view(query=f'pdb:{pdb_id}', width=400, height=300)\n        view.setStyle({style: {'color': color}})\n        view.zoomTo()\n        display(view)\n\n# Uncomment to see different styles (commented to avoid too many visualizations)\n# compare_visualization_styles('1LYZ')\n\n# Example 3: Highlighting specific regions\ndef highlight_active_site(pdb_id, residues):\n    \"\"\"Highlight specific residues (like active sites) in a protein\"\"\"\n    view = py3Dmol.view(query=f'pdb:{pdb_id}', width=600, height=400)\n    \n    # Main protein structure\n    view.setStyle({'cartoon': {'color': 'lightgray'}})\n    \n    # Highlight specific residues\n    for residue in residues:\n        view.addStyle({'resi': residue}, {'stick': {'color': 'red', 'radius': 0.3}})\n    \n    view.zoomTo()\n    return view\n\nprint(\"\\n🎯 Example 3: Lysozyme Active Site (highlighted in red)\")\nlysozyme_active_site = highlight_active_site('1LYZ', [35, 52, 62, 63, 101, 108])\ndisplay(lysozyme_active_site)\n\n\n============================================================\nSECTION 2: INTERACTIVE 3D STRUCTURE VISUALIZATION\n============================================================\n🔬 Example 1: Hemoglobin (1HHO) - Oxygen Transport Protein\n\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.\n        \n\n\n\n&lt;py3Dmol.view at 0x11793cb60&gt;\n\n\n\n🎯 Example 3: Lysozyme Active Site (highlighted in red)\n\n\n\n        3Dmol.js failed to load for some reason.  Please check your browser console for error messages.\n        \n\n\n\n&lt;py3Dmol.view at 0x162dcfe60&gt;\n\n\n\n\n# =============================================================================\n# SECTION 3: STRUCTURAL ANALYSIS WITH BIOPYTHON\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 3: QUANTITATIVE STRUCTURAL ANALYSIS\")\nprint(\"=\"*60)\n\ndef download_and_analyze_structure(pdb_id):\n    \"\"\"Download and perform basic analysis of a protein structure\"\"\"\n    # Download PDB file\n    url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n    response = requests.get(url)\n    \n    if response.status_code != 200:\n        return None\n    \n    # Parse structure\n    parser = PDBParser(QUIET=True)\n    structure = parser.get_structure(pdb_id, StringIO(response.text))\n    \n    # Basic analysis\n    analysis = {\n        'pdb_id': pdb_id,\n        'num_models': len(list(structure.get_models())),\n        'num_chains': len(list(structure.get_chains())),\n        'num_residues': len(list(structure.get_residues())),\n        'num_atoms': len(list(structure.get_atoms())),\n        'amino_acids': []\n    }\n    \n    # Get amino acid composition\n    pp_builder = PPBuilder()\n    for pp in pp_builder.build_peptides(structure):\n        analysis['amino_acids'].extend(list(str(pp.get_sequence())))\n    \n    return analysis, structure\n\n# Analyze our teaching proteins\nprint(\"📊 Analyzing Teaching Dataset...\")\nanalysis_results = []\n\nfor category, pdb_ids in list(teaching_proteins.items())[:3]:  # Analyze first 3 categories\n    print(f\"\\n{category.upper()}:\")\n    for pdb_id in pdb_ids[:2]:  # First 2 structures per category\n        result, structure = download_and_analyze_structure(pdb_id)\n        if result:\n            analysis_results.append(result)\n            print(f\"  {pdb_id}: {result['num_residues']} residues, {result['num_chains']} chains\")\n\n# Create DataFrame for analysis\ndf_analysis = pd.DataFrame(analysis_results)\nprint(f\"\\n📈 Dataset Summary:\")\nprint(df_analysis[['pdb_id', 'num_chains', 'num_residues', 'num_atoms']].to_string(index=False))\n\n\n============================================================\nSECTION 3: QUANTITATIVE STRUCTURAL ANALYSIS\n============================================================\n📊 Analyzing Teaching Dataset...\n\nHEMOGLOBIN:\n  1HHO: 401 residues, 2 chains\n  2HHB: 801 residues, 4 chains\n\nLYSOZYME:\n  1LYZ: 230 residues, 1 chains\n  193L: 273 residues, 1 chains\n\nINSULIN:\n  1MSO: 330 residues, 4 chains\n  4INS: 454 residues, 4 chains\n\n📈 Dataset Summary:\npdb_id  num_chains  num_residues  num_atoms\n  1HHO           2           401       2396\n  2HHB           4           801       4779\n  1LYZ           1           230       1102\n  193L           1           273       1145\n  1MSO           4           330       1791\n  4INS           4           454       1158\n\n\n\n\n# =============================================================================\n# SECTION 4: AMINO ACID COMPOSITION ANALYSIS\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 4: AMINO ACID COMPOSITION ANALYSIS\")\nprint(\"=\"*60)\n\ndef analyze_amino_acid_composition(analysis_results):\n    \"\"\"Analyze amino acid composition across proteins\"\"\"\n    \n    # Standard amino acids\n    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n                   'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n    \n    composition_data = []\n    \n    for result in analysis_results:\n        if result['amino_acids']:\n            aa_counts = {aa: result['amino_acids'].count(aa) for aa in amino_acids}\n            total_aa = sum(aa_counts.values())\n            \n            if total_aa &gt; 0:\n                composition = {\n                    'pdb_id': result['pdb_id'],\n                    'total_residues': total_aa\n                }\n                for aa in amino_acids:\n                    composition[f'{aa}_percent'] = (aa_counts[aa] / total_aa) * 100\n                \n                composition_data.append(composition)\n    \n    return pd.DataFrame(composition_data)\n\n# Analyze amino acid composition\ncomp_df = analyze_amino_acid_composition(analysis_results)\n\nif not comp_df.empty:\n    # Plot amino acid composition\n    plt.figure(figsize=(15, 8))\n    \n    # Get amino acid percentage columns\n    aa_cols = [col for col in comp_df.columns if col.endswith('_percent')]\n    aa_names = [col[:-8] for col in aa_cols]\n    \n    # Calculate mean composition across all proteins\n    mean_composition = comp_df[aa_cols].mean()\n    \n    plt.subplot(2, 2, 1)\n    bars = plt.bar(aa_names, mean_composition.values)\n    plt.title('Average Amino Acid Composition\\nAcross Teaching Dataset')\n    plt.xlabel('Amino Acid')\n    plt.ylabel('Percentage (%)')\n    plt.xticks(rotation=45)\n    \n    # Color bars by amino acid properties\n    hydrophobic = ['A', 'I', 'L', 'M', 'F', 'W', 'Y', 'V']\n    polar = ['N', 'Q', 'S', 'T']\n    charged = ['R', 'K', 'D', 'E']\n    special = ['C', 'G', 'P', 'H']\n    \n    for i, aa in enumerate(aa_names):\n        if aa in hydrophobic:\n            bars[i].set_color('lightblue')\n        elif aa in polar:\n            bars[i].set_color('lightgreen')\n        elif aa in charged:\n            bars[i].set_color('lightcoral')\n        else:\n            bars[i].set_color('lightyellow')\n    \n    # Protein size comparison\n    plt.subplot(2, 2, 2)\n    plt.bar(comp_df['pdb_id'], comp_df['total_residues'])\n    plt.title('Protein Sizes in Teaching Dataset')\n    plt.xlabel('PDB ID')\n    plt.ylabel('Number of Residues')\n    plt.xticks(rotation=45)\n    \n    # Hydrophobicity analysis\n    plt.subplot(2, 2, 3)\n    hydrophobic_cols = [f'{aa}_percent' for aa in hydrophobic]\n    hydrophobic_percent = comp_df[hydrophobic_cols].sum(axis=1)\n    \n    plt.scatter(comp_df['total_residues'], hydrophobic_percent, alpha=0.7, s=100)\n    plt.title('Protein Size vs Hydrophobicity')\n    plt.xlabel('Number of Residues')\n    plt.ylabel('Hydrophobic Residues (%)')\n    \n    for i, pdb_id in enumerate(comp_df['pdb_id']):\n        plt.annotate(pdb_id, (comp_df['total_residues'].iloc[i], hydrophobic_percent.iloc[i]),\n                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n    \n    # Secondary structure prediction visualization placeholder\n    plt.subplot(2, 2, 4)\n    plt.text(0.5, 0.5, 'Secondary Structure\\nAnalysis\\n(Advanced Topic)', \n             ha='center', va='center', transform=plt.gca().transAxes,\n             fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n    plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n\n============================================================\nSECTION 4: AMINO ACID COMPOSITION ANALYSIS\n============================================================\n\n\n\n\n\n\n\n\n\n\n\n# =============================================================================\n# SECTION 5: COMPARATIVE ANALYSIS EXERCISES\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 5: STUDENT EXERCISES AND ASSIGNMENTS\")\nprint(\"=\"*60)\n\ndef create_student_exercises():\n    \"\"\"Generate student exercises using the PDB dataset\"\"\"\n    \n    exercises = {\n        \"Beginner Level\": [\n            {\n                \"title\": \"Protein Size Investigation\",\n                \"task\": \"Compare protein sizes across different organisms\",\n                \"datasets\": [\"1HHO (human)\", \"1MBO (sperm whale)\", \"1LYZ (chicken)\"],\n                \"questions\": [\n                    \"Which protein has the most amino acids?\",\n                    \"How does organism complexity relate to protein size?\",\n                    \"What might explain size differences?\"\n                ]\n            },\n            {\n                \"title\": \"Visualization Mastery\",\n                \"task\": \"Create different views of the same protein\",\n                \"proteins\": [\"1LYZ\"],\n                \"requirements\": [\n                    \"Cartoon representation showing secondary structure\",\n                    \"Surface view showing protein shape\",\n                    \"Stick model of active site residues\"\n                ]\n            }\n        ],\n        \n        \"Intermediate Level\": [\n            {\n                \"title\": \"Structure-Function Relationships\",\n                \"task\": \"Compare oxygen-binding proteins\",\n                \"proteins\": [\"1HHO (hemoglobin)\", \"1MBO (myoglobin)\"],\n                \"analysis\": [\n                    \"Identify heme groups in both structures\",\n                    \"Compare quaternary structures\",\n                    \"Relate structural differences to functional differences\"\n                ]\n            },\n            {\n                \"title\": \"Amino Acid Composition Analysis\",\n                \"task\": \"Analyze chemical properties across protein families\",\n                \"approach\": \"Statistical analysis of amino acid frequencies\",\n                \"coding_required\": True\n            }\n        ],\n        \n        \"Advanced Level\": [\n            {\n                \"title\": \"Evolutionary Analysis\",\n                \"task\": \"Compare homologous proteins across species\",\n                \"proteins\": [\"Multiple lysozyme structures\"],\n                \"methods\": [\"Structural alignment\", \"Conservation analysis\"],\n                \"tools\": [\"BioPython\", \"PyMOL scripting\"]\n            },\n            {\n                \"title\": \"Drug Design Project\",\n                \"task\": \"Identify potential drug binding sites\",\n                \"approach\": \"Cavity detection and analysis\",\n                \"real_world_application\": \"Pharmaceutical research\"\n            }\n        ]\n    }\n    \n    return exercises\n\nexercises = create_student_exercises()\n\nprint(\"🎓 STUDENT EXERCISE FRAMEWORK\")\nprint(\"=\"*40)\n\nfor level, exercise_list in exercises.items():\n    print(f\"\\n{level.upper()}:\")\n    for i, exercise in enumerate(exercise_list, 1):\n        print(f\"  {i}. {exercise['title']}\")\n        print(f\"     Task: {exercise['task']}\")\n        if 'proteins' in exercise:\n            print(f\"     Proteins: {', '.join(exercise['proteins'])}\")\n        if 'coding_required' in exercise:\n            print(f\"     💻 Coding Required: Yes\")\n\n\n============================================================\nSECTION 5: STUDENT EXERCISES AND ASSIGNMENTS\n============================================================\n🎓 STUDENT EXERCISE FRAMEWORK\n========================================\n\nBEGINNER LEVEL:\n  1. Protein Size Investigation\n     Task: Compare protein sizes across different organisms\n  2. Visualization Mastery\n     Task: Create different views of the same protein\n     Proteins: 1LYZ\n\nINTERMEDIATE LEVEL:\n  1. Structure-Function Relationships\n     Task: Compare oxygen-binding proteins\n     Proteins: 1HHO (hemoglobin), 1MBO (myoglobin)\n  2. Amino Acid Composition Analysis\n     Task: Analyze chemical properties across protein families\n     💻 Coding Required: Yes\n\nADVANCED LEVEL:\n  1. Evolutionary Analysis\n     Task: Compare homologous proteins across species\n     Proteins: Multiple lysozyme structures\n  2. Drug Design Project\n     Task: Identify potential drug binding sites\n\n\n\n\n# =============================================================================\n# SECTION 6: ASSESSMENT AND LEARNING OUTCOMES\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 6: LEARNING OUTCOMES & ASSESSMENT\")\nprint(\"=\"*60)\n\nlearning_outcomes = {\n    \"Technical Skills\": [\n        \"Database querying and API usage\",\n        \"3D structure visualization\",\n        \"Statistical analysis of biological data\",\n        \"Python programming for bioinformatics\",\n        \"Data interpretation and presentation\"\n    ],\n    \n    \"Biological Concepts\": [\n        \"Protein structure hierarchy (primary to quaternary)\",\n        \"Structure-function relationships\",\n        \"Evolutionary conservation\",\n        \"Enzyme mechanisms and active sites\",\n        \"Protein families and classification\"\n    ],\n    \n    \"Scientific Thinking\": [\n        \"Hypothesis formation and testing\",\n        \"Critical evaluation of data\",\n        \"Integration of multiple data sources\",\n        \"Scientific communication\",\n        \"Research methodology\"\n    ]\n}\n\nassessment_methods = {\n    \"Formative Assessment\": [\n        \"Interactive notebook completion\",\n        \"Peer review of visualizations\",\n        \"Discussion forum participation\",\n        \"Mini-quizzes on protein properties\"\n    ],\n    \n    \"Summative Assessment\": [\n        \"Research project: Novel protein analysis\",\n        \"Group presentation: Protein family comparison\",\n        \"Written report: Structure-function analysis\",\n        \"Code portfolio: Analysis scripts\"\n    ]\n}\n\nprint(\"🎯 LEARNING OUTCOMES:\")\nfor category, outcomes in learning_outcomes.items():\n    print(f\"\\n{category}:\")\n    for outcome in outcomes:\n        print(f\"  • {outcome}\")\n\nprint(f\"\\n📋 ASSESSMENT METHODS:\")\nfor category, methods in assessment_methods.items():\n    print(f\"\\n{category}:\")\n    for method in methods:\n        print(f\"  • {method}\")\n\n\n============================================================\nSECTION 6: LEARNING OUTCOMES & ASSESSMENT\n============================================================\n🎯 LEARNING OUTCOMES:\n\nTechnical Skills:\n  • Database querying and API usage\n  • 3D structure visualization\n  • Statistical analysis of biological data\n  • Python programming for bioinformatics\n  • Data interpretation and presentation\n\nBiological Concepts:\n  • Protein structure hierarchy (primary to quaternary)\n  • Structure-function relationships\n  • Evolutionary conservation\n  • Enzyme mechanisms and active sites\n  • Protein families and classification\n\nScientific Thinking:\n  • Hypothesis formation and testing\n  • Critical evaluation of data\n  • Integration of multiple data sources\n  • Scientific communication\n  • Research methodology\n\n📋 ASSESSMENT METHODS:\n\nFormative Assessment:\n  • Interactive notebook completion\n  • Peer review of visualizations\n  • Discussion forum participation\n  • Mini-quizzes on protein properties\n\nSummative Assessment:\n  • Research project: Novel protein analysis\n  • Group presentation: Protein family comparison\n  • Written report: Structure-function analysis\n  • Code portfolio: Analysis scripts\n\n\n\n\n# =============================================================================\n# SECTION 7: RESOURCES AND NEXT STEPS\n# =============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SECTION 7: RESOURCES AND NEXT STEPS\")\nprint(\"=\"*60)\n\nresources = {\n    \"Essential Tools\": [\n        \"py3Dmol: Interactive 3D visualization\",\n        \"BioPython: Python tools for bioinformatics\",\n        \"pandas: Data analysis and manipulation\",\n        \"matplotlib/seaborn: Data visualization\",\n        \"Jupyter notebooks: Interactive development\"\n    ],\n    \n    \"Advanced Tools\": [\n        \"PyMOL: Professional molecular visualization\",\n        \"ChimeraX: Advanced structural analysis\",\n        \"VMD: Molecular dynamics visualization\",\n        \"Biotite: High-performance structural biology\",\n        \"MDAnalysis: Trajectory analysis\"\n    ],\n    \n    \"Databases\": [\n        \"RCSB PDB: Protein structures\",\n        \"UniProt: Protein sequences and annotations\",\n        \"Pfam: Protein families\",\n        \"SCOP: Structural classification\",\n        \"CATH: Protein structure classification\"\n    ],\n    \n    \"Learning Resources\": [\n        \"PDB-101: Educational materials from RCSB\",\n        \"PyMOL Wiki: Tutorials and scripts\",\n        \"BioPython Tutorial: Comprehensive guide\",\n        \"Coursera/edX: Bioinformatics courses\",\n        \"Nature Structural Biology: Research articles\"\n    ]\n}\n\nprint(\"📚 RECOMMENDED RESOURCES:\")\nfor category, items in resources.items():\n    print(f\"\\n{category}:\")\n    for item in items:\n        print(f\"  • {item}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎉 CONGRATULATIONS!\")\nprint(\"You've completed the PDB protein structure analysis tutorial!\")\nprint(\"This notebook provides a foundation for teaching molecular biology\")\nprint(\"through hands-on data science approaches.\")\nprint(\"=\"*60)\n\n# Final interactive example\nprint(\"\\n🔬 Try this: Modify the code above to explore your own protein of interest!\")\nprint(\"Simply replace PDB IDs in the teaching_proteins dictionary.\")\n\n# Create a simple interactive widget concept\ndef explore_protein(pdb_id):\n    \"\"\"Template function for students to explore any protein\"\"\"\n    print(f\"🧬 Exploring protein: {pdb_id}\")\n    \n    # Download and analyze\n    analysis, structure = download_and_analyze_structure(pdb_id)\n    \n    if analysis:\n        print(f\"📊 Basic Properties:\")\n        print(f\"  Chains: {analysis['num_chains']}\")\n        print(f\"  Residues: {analysis['num_residues']}\")\n        print(f\"  Atoms: {analysis['num_atoms']}\")\n        \n        # Create viewer\n        print(f\"\\n🔍 3D Structure:\")\n        viewer = create_protein_viewer(pdb_id)\n        display(viewer)\n        \n        return analysis\n    else:\n        print(\"❌ Could not retrieve protein data\")\n        return None\n\n# Example usage (uncomment to try):\n# explore_protein('1BRD')  # DNA-binding protein\n\nprint(\"\\n💡 Next Steps for Instructors:\")\nprint(\"1. Customize the teaching_proteins dictionary for your course\")\nprint(\"2. Add specific exercises relevant to your learning objectives\") \nprint(\"3. Integrate with your LMS for student submissions\")\nprint(\"4. Develop rubrics for assessment\")\nprint(\"5. Create video tutorials for complex concepts\")\n\n\n============================================================\nSECTION 7: RESOURCES AND NEXT STEPS\n============================================================\n📚 RECOMMENDED RESOURCES:\n\nEssential Tools:\n  • py3Dmol: Interactive 3D visualization\n  • BioPython: Python tools for bioinformatics\n  • pandas: Data analysis and manipulation\n  • matplotlib/seaborn: Data visualization\n  • Jupyter notebooks: Interactive development\n\nAdvanced Tools:\n  • PyMOL: Professional molecular visualization\n  • ChimeraX: Advanced structural analysis\n  • VMD: Molecular dynamics visualization\n  • Biotite: High-performance structural biology\n  • MDAnalysis: Trajectory analysis\n\nDatabases:\n  • RCSB PDB: Protein structures\n  • UniProt: Protein sequences and annotations\n  • Pfam: Protein families\n  • SCOP: Structural classification\n  • CATH: Protein structure classification\n\nLearning Resources:\n  • PDB-101: Educational materials from RCSB\n  • PyMOL Wiki: Tutorials and scripts\n  • BioPython Tutorial: Comprehensive guide\n  • Coursera/edX: Bioinformatics courses\n  • Nature Structural Biology: Research articles\n\n============================================================\n🎉 CONGRATULATIONS!\nYou've completed the PDB protein structure analysis tutorial!\nThis notebook provides a foundation for teaching molecular biology\nthrough hands-on data science approaches.\n============================================================\n\n🔬 Try this: Modify the code above to explore your own protein of interest!\nSimply replace PDB IDs in the teaching_proteins dictionary.\n\n💡 Next Steps for Instructors:\n1. Customize the teaching_proteins dictionary for your course\n2. Add specific exercises relevant to your learning objectives\n3. Integrate with your LMS for student submissions\n4. Develop rubrics for assessment\n5. Create video tutorials for complex concepts"
  },
  {
    "objectID": "pages/troubleshooting.html",
    "href": "pages/troubleshooting.html",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Before troubleshooting specific issues, run Franklin’s diagnostic tool:\nfranklin doctor\nThis checks: - Python installation - Docker status - Network connectivity - GitLab access - File permissions - Available disk space",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#diagnostic-tools",
    "href": "pages/troubleshooting.html#diagnostic-tools",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Before troubleshooting specific issues, run Franklin’s diagnostic tool:\nfranklin doctor\nThis checks: - Python installation - Docker status - Network connectivity - GitLab access - File permissions - Available disk space",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#installation-issues",
    "href": "pages/troubleshooting.html#installation-issues",
    "title": "Troubleshooting Guide",
    "section": "Installation Issues",
    "text": "Installation Issues\n\n“Command not found” Error\n\nWindowsMac/Linux\n\n\nProblem: Terminal shows 'franklin' is not recognized as an internal or external command\nSolutions:\n\nVerify Miniforge Installation:\n# Check if conda is installed\nconda --version\nIf not found, reinstall Miniforge from conda-forge.org\nCheck PATH:\n# Add Miniforge to PATH\n$env:Path += \";C:\\Users\\YOUR_USERNAME\\miniforge3\\Scripts\"\nReinstall Franklin:\nconda install -c conda-forge -c munch-group franklin --force-reinstall\nUse Miniforge Prompt:\n\nDon’t use Command Prompt or PowerShell\nUse “Miniforge Prompt” from Start Menu\n\n\n\n\nProblem: Terminal shows franklin: command not found\nSolutions:\n\nCheck Installation:\nwhich franklin\nconda list franklin\nActivate Conda:\n# Initialize conda for your shell\nconda init bash  # or zsh for Mac\nsource ~/.bashrc  # or ~/.zshrc for Mac\nReinstall:\nconda remove franklin\nconda install -c conda-forge -c munch-group franklin\nCheck Shell Configuration:\n# Ensure conda is in PATH\necho $PATH | grep conda\n\n\n\n\n\n\nInstallation Hangs or Fails\nProblem: Installation process freezes or shows errors\nSolutions:\n\nClear Conda Cache:\nconda clean --all\nUse Mamba (faster solver):\nconda install mamba -c conda-forge\nmamba install -c conda-forge -c munch-group franklin\nNetwork Issues:\n# Use different mirror\nconda config --add channels conda-forge\nconda config --set channel_priority strict\nCreate Fresh Environment:\nconda create -n franklin-env python=3.11\nconda activate franklin-env\nconda install -c munch-group franklin",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#docker-issues",
    "href": "pages/troubleshooting.html#docker-issues",
    "title": "Troubleshooting Guide",
    "section": "Docker Issues",
    "text": "Docker Issues\n\nDocker Not Running\nProblem: “Docker is not running” error\n\n\nWindowsMacLinux\n\n\n\nStart Docker Desktop:\n\nOpen Docker Desktop from Start Menu\nWait for “Docker Desktop is running” in system tray\n\nCheck Service:\n# Check Docker service\nGet-Service docker\n\n# Start if needed\nStart-Service docker\nEnable WSL2:\n\nSettings → General → Use WSL 2 based engine\nRestart Docker Desktop\n\n\n\n\n\nStart Docker Desktop:\n\nOpen Docker from Applications\nLook for whale icon in menu bar\n\nReset Docker:\n\nDocker Desktop → Preferences → Reset\n“Reset to factory defaults”\n\nCheck Resources:\n\nDocker Desktop → Preferences → Resources\nIncrease memory to at least 4GB\n\n\n\n\n\nStart Docker Service:\nsudo systemctl start docker\nsudo systemctl enable docker\nAdd User to Docker Group:\nsudo usermod -aG docker $USER\nnewgrp docker\nCheck Status:\nsudo systemctl status docker\ndocker ps\n\n\n\n\n\n\nContainer Startup Failures\nProblem: Container fails to start or immediately exits\nSolutions:\n\nCheck Logs:\nfranklin logs --tail 100\ndocker logs $(docker ps -lq)\nClean Up:\n# Remove problematic containers\nfranklin cleanup --all\n\n# Clean Docker system\ndocker system prune -a\nResource Limits:\n# Launch with lower resources\nfranklin jupyter --memory 2g --cpus 1\nPort Conflicts:\n# Use different port\nfranklin jupyter --port 8889\n\n# Check what's using port 8888\nlsof -i :8888  # Mac/Linux\nnetstat -ano | findstr :8888  # Windows",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#exercise-download-issues",
    "href": "pages/troubleshooting.html#exercise-download-issues",
    "title": "Troubleshooting Guide",
    "section": "Exercise Download Issues",
    "text": "Exercise Download Issues\n\nNo Exercises Available\nProblem: No courses or exercises appear when running franklin download\nSolutions:\n\nCheck Network:\n# Test GitLab connectivity\ncurl https://gitlab.com/api/v4/version\nUpdate Franklin:\nconda update franklin\nfranklin update\nCheck Configuration:\n# View current config\ncat ~/.franklin/config.json\n\n# Reset if corrupted\nfranklin reset --config\nVerify with Instructor:\n\nEnsure exercises are published\nCheck course name spelling\nConfirm you have access\n\n\n\n\nDownload Fails or Hangs\nProblem: Download starts but doesn’t complete\nSolutions:\n\nCheck Disk Space:\n# Mac/Linux\ndf -h ~\n\n# Windows\nGet-PSDrive C\nClear Cache:\nfranklin cache clear\nrm -rf ~/.franklin/cache/*\nUse Direct URL:\n# If instructor provides URL\nfranklin download --url https://gitlab.com/course/exercise\nManual Download:\n# Clone with git\ngit clone https://gitlab.com/franklin/courses/exercise.git",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#jupyter-issues",
    "href": "pages/troubleshooting.html#jupyter-issues",
    "title": "Troubleshooting Guide",
    "section": "Jupyter Issues",
    "text": "Jupyter Issues\n\nJupyter Won’t Start\nProblem: Browser doesn’t open or shows error\nSolutions:\n\nManual URL:\n# Look for URL in terminal output\nJupyterLab URL: http://localhost:8888/lab?token=...\n# Copy and paste in browser\nBrowser Issues:\n# Set default browser\nexport BROWSER=chrome  # or firefox, safari\nfranklin jupyter\nToken Problems:\n# Get new token\nfranklin jupyter --generate-token\nFirewall/Antivirus:\n\nTemporarily disable firewall\nAdd exception for port 8888\nWhitelist Docker in antivirus\n\n\n\n\nKernel Crashes or Restarts\nProblem: Jupyter kernel dies during execution\nSolutions:\n\nIncrease Memory:\nfranklin jupyter --memory 8g\nCheck Code:\n# Monitor memory usage\nimport psutil\nprint(f\"Memory: {psutil.virtual_memory().percent}%\")\nRestart Kernel:\n\nKernel → Restart Kernel and Clear All Outputs\nRun cells one by one\n\nUpdate Packages:\n%franklin update jupyter ipykernel\n\n\n\nCan’t Install Packages\nProblem: %franklin magic doesn’t work\nSolutions:\n\nLoad Extension:\n%load_ext magic\nUse Full Path:\nimport sys\n!{sys.executable} -m pip install numpy\nCheck Pixi:\n# In terminal\npixi add numpy\nManual Installation:\nimport subprocess\nsubprocess.run([\"pixi\", \"add\", \"package_name\"])",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#permission-issues",
    "href": "pages/troubleshooting.html#permission-issues",
    "title": "Troubleshooting Guide",
    "section": "Permission Issues",
    "text": "Permission Issues\n\nAccess Denied Errors\n\nWindowsMac/Linux\n\n\n\nRun as Administrator:\n\nRight-click Miniforge Prompt\n“Run as administrator”\n\nFix Ownership:\n# Take ownership of Franklin directory\ntakeown /f $env:USERPROFILE\\.franklin /r\nAntivirus Exclusion:\n\nAdd C:\\Users\\YOUR_NAME\\.franklin to exclusions\nAdd Docker folders to exclusions\n\n\n\n\n\nFix Permissions:\n# Fix Franklin directory\nsudo chown -R $USER:$USER ~/.franklin\nchmod -R 755 ~/.franklin\nDocker Permissions:\n# Add to docker group\nsudo usermod -aG docker $USER\n# Log out and back in\nFile Permissions:\n# Fix exercise files\nchmod -R u+rw exercise-folder/",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#network-issues",
    "href": "pages/troubleshooting.html#network-issues",
    "title": "Troubleshooting Guide",
    "section": "Network Issues",
    "text": "Network Issues\n\nProxy Configuration\nProblem: Behind corporate firewall/proxy\nSolutions:\n\nSet Proxy:\nexport HTTP_PROXY=http://proxy.company.com:8080\nexport HTTPS_PROXY=http://proxy.company.com:8080\nexport NO_PROXY=localhost,127.0.0.1\nConfigure Git:\ngit config --global http.proxy http://proxy.company.com:8080\nConfigure Docker:\n\nDocker Desktop → Settings → Resources → Proxies\nAdd proxy configuration\n\nConda Configuration:\nconda config --set proxy_servers.http http://proxy.company.com:8080\nconda config --set proxy_servers.https http://proxy.company.com:8080\n\n\n\nSSL Certificate Errors\nProblem: SSL verification failures\nSolutions:\n\nTemporary Bypass (not recommended for production):\nexport PYTHONHTTPSVERIFY=0\nconda config --set ssl_verify false\nAdd Corporate Certificate:\n# Get certificate\nexport REQUESTS_CA_BUNDLE=/path/to/corporate-cert.pem\nexport SSL_CERT_FILE=/path/to/corporate-cert.pem\nUpdate Certificates:\nconda update ca-certificates\nconda update certifi",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#performance-issues",
    "href": "pages/troubleshooting.html#performance-issues",
    "title": "Troubleshooting Guide",
    "section": "Performance Issues",
    "text": "Performance Issues\n\nSlow Performance\nProblem: Franklin or exercises run slowly\nSolutions:\n\nIncrease Resources:\n\nDocker Desktop → Settings → Resources\nIncrease CPUs to 4+\nIncrease Memory to 8GB+\nIncrease Disk space\n\nClean Up:\n# Remove unused containers\ndocker container prune\n\n# Remove unused images\ndocker image prune -a\n\n# Clean everything\ndocker system prune -a --volumes\nDisable Antivirus Scanning:\n\nExclude Docker directories\nExclude .franklin directory\n\nUse SSD:\n\nMove Docker data to SSD\nStore exercises on SSD\n\n\n\n\nMemory Errors\nProblem: Out of memory errors\nSolutions:\n\nMonitor Usage:\nimport psutil\nprint(f\"Available: {psutil.virtual_memory().available / 1e9:.2f} GB\")\nProcess Data in Chunks:\n# Instead of loading entire file\nfor chunk in pd.read_csv('large.csv', chunksize=10000):\n    process(chunk)\nClear Variables:\n# Free memory\ndel large_variable\nimport gc\ngc.collect()",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#recovery-procedures",
    "href": "pages/troubleshooting.html#recovery-procedures",
    "title": "Troubleshooting Guide",
    "section": "Recovery Procedures",
    "text": "Recovery Procedures\n\nComplete Reset\nIf nothing else works, perform a complete reset:\n# 1. Backup your work\ncp -r ~/franklin-exercises ~/franklin-backup\n\n# 2. Remove Franklin\nconda remove franklin franklin-educator franklin-admin\nrm -rf ~/.franklin\n\n# 3. Clean Docker\ndocker stop $(docker ps -aq)\ndocker rm $(docker ps -aq)\ndocker system prune -a --volumes\n\n# 4. Reinstall\nconda install -c conda-forge -c munch-group franklin\n\n# 5. Test\nfranklin doctor\n\n\nData Recovery\nIf you lose work:\n\nCheck Auto-saves:\n# Jupyter auto-saves\nls -la .ipynb_checkpoints/\nDocker Volumes:\n# List volumes\ndocker volume ls\n\n# Inspect volume\ndocker volume inspect franklin_exercise_data\nGit History:\n# If exercise is git repository\ngit reflog\ngit checkout &lt;commit-hash&gt;",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#getting-help",
    "href": "pages/troubleshooting.html#getting-help",
    "title": "Troubleshooting Guide",
    "section": "Getting Help",
    "text": "Getting Help\n\nCollecting Debug Information\nWhen reporting issues, include:\n# System information\nfranklin doctor --verbose &gt; debug.txt\n\n# Franklin version\nfranklin --version &gt;&gt; debug.txt\n\n# Python version\npython --version &gt;&gt; debug.txt\n\n# Docker version\ndocker --version &gt;&gt; debug.txt\n\n# Recent logs\nfranklin logs --tail 100 &gt;&gt; debug.txt\n\n\nSupport Channels\n\nGitHub Issues: github.com/munch-group/franklin/issues\nDocumentation: munch-group.org/franklin\nCourse Instructor: For exercise-specific issues\nIT Support: For network/firewall issues\n\n\n\nCommon Error Messages\n\n\n\n\n\n\n\n\nError\nMeaning\nSolution\n\n\n\n\nDocker daemon not running\nDocker Desktop not started\nStart Docker Desktop\n\n\nPort 8888 already in use\nAnother service using port\nUse --port 8889\n\n\nNo such container\nContainer was removed\nRun franklin jupyter again\n\n\nPermission denied\nFile permission issue\nFix with chmod or chown\n\n\nNo space left on device\nDisk full\nClear Docker cache\n\n\nNetwork unreachable\nNetwork/firewall issue\nCheck proxy settings\n\n\nModule not found\nPackage not installed\nUse %franklin package_name\n\n\nKernel died\nOut of memory\nIncrease memory limit",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/troubleshooting.html#prevention-tips",
    "href": "pages/troubleshooting.html#prevention-tips",
    "title": "Troubleshooting Guide",
    "section": "Prevention Tips",
    "text": "Prevention Tips\n\n\n\n\n\n\nBest Practices\n\n\n\n\nRegular Updates: Keep Franklin updated with conda update franklin\nClean Regularly: Run franklin cleanup weekly\nMonitor Resources: Check Docker Desktop resource usage\nBackup Work: Commit to git frequently\nTest Early: Test exercises as soon as downloaded\nRead Logs: Check logs when issues occur\nDocument Issues: Keep notes on what worked\n\n\n\n\n\n\n\n\n\nCommon Mistakes to Avoid\n\n\n\n\nDon’t run multiple Franklin instances simultaneously\nDon’t modify Dockerfile unless you understand Docker\nDon’t ignore error messages - read them carefully\nDon’t delete .franklin directory without backup\nDon’t use sudo/admin unless specifically required",
    "crumbs": [
      "Help & Support",
      "Troubleshooting Guide"
    ]
  },
  {
    "objectID": "pages/student/index.html",
    "href": "pages/student/index.html",
    "title": "franklin",
    "section": "",
    "text": "Franklin takes care of the technical challenges in running jupyter notebook exercise on your computer. That way, you can focus on learning rather than library incompatibilities and platform specific dependencies.\nOnce installed, running lets you download the exercise you want.\n\n\nTerminal\n\nfranklin download\n\nRunning this command, starts a jupyter notebook on your computer that\n\n\nTerminal\n\nfranklin jupyter\n\nYou can find more detail along with installation instructions and tutorials in the side bar.\nShould you come across a bug or find yourself missing some functionality, you are welcome to submit an issue."
  },
  {
    "objectID": "pages/student/index.html#franklin",
    "href": "pages/student/index.html#franklin",
    "title": "franklin",
    "section": "",
    "text": "Franklin takes care of the technical challenges in running jupyter notebook exercise on your computer. That way, you can focus on learning rather than library incompatibilities and platform specific dependencies.\nOnce installed, running lets you download the exercise you want.\n\n\nTerminal\n\nfranklin download\n\nRunning this command, starts a jupyter notebook on your computer that\n\n\nTerminal\n\nfranklin jupyter\n\nYou can find more detail along with installation instructions and tutorials in the side bar.\nShould you come across a bug or find yourself missing some functionality, you are welcome to submit an issue."
  },
  {
    "objectID": "pages/sandbox.html",
    "href": "pages/sandbox.html",
    "title": "Sandbox",
    "section": "",
    "text": "To quickly get a feel for Jupyter and to browse tutorials, visit the JupyterLite Sandbox. JupyterLite is a JupyterLab distribution that runs entirely in the browser\nJupyterLite emulates the behavior of JupyterLab and Python and runs entirely in the browser. It does not access your local files. So to use it, you need to upload and download notebooks you want to play with. Still in development, JupyterLite does not include all JupyterLab features.\nTry the sandbox"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html",
    "href": "pages/python_r_julia_expanded.html",
    "title": "Python, R, and Julia for Data Science",
    "section": "",
    "text": "This guide provides a comprehensive comparison of Python, R, and Julia for data science tasks. Whether you’re transitioning between languages or choosing which to learn, this reference shows how to accomplish common data operations in all three languages.\n\n\n\n\n\n\n\n\n\n\n\nFeature\nPython\nR\nJulia\n\n\n\n\nPrimary Use\nGeneral purpose, Data Science, ML\nStatistics, Data Analysis\nScientific Computing, Performance\n\n\nLearning Curve\nModerate\nSteep initially\nModerate to Steep\n\n\nPerformance\nGood with NumPy\nModerate\nExcellent\n\n\nEcosystem\nVast\nStatistical focus\nGrowing rapidly\n\n\nSyntax\nClean, readable\nFunctional, vectorized\nMathematical, fast"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#introduction",
    "href": "pages/python_r_julia_expanded.html#introduction",
    "title": "Python, R, and Julia for Data Science",
    "section": "",
    "text": "This guide provides a comprehensive comparison of Python, R, and Julia for data science tasks. Whether you’re transitioning between languages or choosing which to learn, this reference shows how to accomplish common data operations in all three languages.\n\n\n\n\n\n\n\n\n\n\n\nFeature\nPython\nR\nJulia\n\n\n\n\nPrimary Use\nGeneral purpose, Data Science, ML\nStatistics, Data Analysis\nScientific Computing, Performance\n\n\nLearning Curve\nModerate\nSteep initially\nModerate to Steep\n\n\nPerformance\nGood with NumPy\nModerate\nExcellent\n\n\nEcosystem\nVast\nStatistical focus\nGrowing rapidly\n\n\nSyntax\nClean, readable\nFunctional, vectorized\nMathematical, fast"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#setup-and-libraries",
    "href": "pages/python_r_julia_expanded.html#setup-and-libraries",
    "title": "Python, R, and Julia for Data Science",
    "section": "Setup and Libraries",
    "text": "Setup and Libraries\n\nPythonRJulia\n\n\n# Core data science libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import preprocessing, model_selection\n\n# Set display options\npd.set_option('display.max_columns', 10)\npd.set_option('display.precision', 3)\n\n\n# Core tidyverse and data science packages\nlibrary(tidyverse)  # dplyr, ggplot2, tidyr, etc.\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(forcats)\nlibrary(stringr)\n\n# Set options\noptions(scipen = 999)\noptions(digits = 3)\n\n\n# Core data science packages\nusing DataFrames\nusing CSV\nusing Statistics\nusing StatsBase\nusing Plots\nusing Random\n\n# Set random seed\nRandom.seed!(42)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#creating-data-structures",
    "href": "pages/python_r_julia_expanded.html#creating-data-structures",
    "title": "Python, R, and Julia for Data Science",
    "section": "Creating Data Structures",
    "text": "Creating Data Structures\n\nPythonRJulia\n\n\n# Lists and arrays\nlst = [1, 2, 3, 4, 5]\narr = np.array([1, 2, 3, 4, 5])\n\n# Dictionary\ndict_data = {'name': ['Alice', 'Bob'], \n             'age': [25, 30]}\n\n# DataFrame\ndf = pd.DataFrame({\n    'id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 28],\n    'salary': [50000, 60000, 75000, 55000]\n})\n\n# Series\nseries = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n\n\n# Vectors\nvec &lt;- c(1, 2, 3, 4, 5)\n\n# List\nlst &lt;- list(name = c(\"Alice\", \"Bob\"), \n            age = c(25, 30))\n\n# Data frame (base R)\ndf &lt;- data.frame(\n  id = 1:4,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 28),\n  salary = c(50000, 60000, 75000, 55000)\n)\n\n# Tibble (tidyverse)\ntbl &lt;- tibble(\n  id = 1:4,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 28),\n  salary = c(50000, 60000, 75000, 55000)\n)\n\n\n# Arrays\narr = [1, 2, 3, 4, 5]\n\n# Dictionary\ndict_data = Dict(\"name\" =&gt; [\"Alice\", \"Bob\"],\n                 \"age\" =&gt; [25, 30])\n\n# DataFrame\ndf = DataFrame(\n    id = 1:4,\n    name = [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n    age = [25, 30, 35, 28],\n    salary = [50000, 60000, 75000, 55000]\n)\n\n# Named tuple\nnt = (name=\"Alice\", age=25)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#data-importexport",
    "href": "pages/python_r_julia_expanded.html#data-importexport",
    "title": "Python, R, and Julia for Data Science",
    "section": "Data Import/Export",
    "text": "Data Import/Export\n\nPythonRJulia\n\n\n# CSV\ndf = pd.read_csv('data.csv')\ndf.to_csv('output.csv', index=False)\n\n# Excel\ndf = pd.read_excel('data.xlsx', sheet_name='Sheet1')\ndf.to_excel('output.xlsx', index=False)\n\n# JSON\ndf = pd.read_json('data.json')\ndf.to_json('output.json', orient='records')\n\n# Parquet (efficient storage)\ndf = pd.read_parquet('data.parquet')\ndf.to_parquet('output.parquet')\n\n\n# CSV\ndf &lt;- read_csv(\"data.csv\")  # readr package\nwrite_csv(df, \"output.csv\")\n\n# Excel\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\", sheet = \"Sheet1\")\nlibrary(writexl)\nwrite_xlsx(df, \"output.xlsx\")\n\n# JSON\nlibrary(jsonlite)\ndf &lt;- fromJSON(\"data.json\")\nwrite_json(df, \"output.json\")\n\n# RDS (R's native format)\nsaveRDS(df, \"data.rds\")\ndf &lt;- readRDS(\"data.rds\")\n\n\nusing CSV, XLSX, JSON, Parquet\n\n# CSV\ndf = CSV.read(\"data.csv\", DataFrame)\nCSV.write(\"output.csv\", df)\n\n# Excel\ndf = DataFrame(XLSX.readtable(\"data.xlsx\", \"Sheet1\"))\nXLSX.writetable(\"output.xlsx\", df)\n\n# JSON\nusing JSON3\ndf = JSON3.read(read(\"data.json\", String))\nwrite(\"output.json\", JSON3.write(df))\n\n# Parquet\ndf = read_parquet(\"data.parquet\")\nwrite_parquet(\"output.parquet\", df)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#basic-data-inspection",
    "href": "pages/python_r_julia_expanded.html#basic-data-inspection",
    "title": "Python, R, and Julia for Data Science",
    "section": "Basic Data Inspection",
    "text": "Basic Data Inspection\n\nPythonRJulia\n\n\n# Basic info\nprint(df.shape)          # (rows, columns)\nprint(df.dtypes)         # Data types\nprint(df.info())         # Summary info\nprint(df.describe())     # Statistical summary\n\n# First/last rows\nprint(df.head())         # First 5 rows\nprint(df.tail())         # Last 5 rows\n\n# Unique values\nprint(df['name'].nunique())\nprint(df['name'].unique())\nprint(df['name'].value_counts())\n\n# Missing values\nprint(df.isnull().sum())\n\n\n# Basic info\ndim(df)                  # Dimensions\nstr(df)                  # Structure\nglimpse(df)              # dplyr version\nsummary(df)              # Statistical summary\n\n# First/last rows\nhead(df)                 # First 6 rows\ntail(df)                 # Last 6 rows\n\n# Unique values\nn_distinct(df$name)\nunique(df$name)\ntable(df$name)\n\n# Missing values\nsum(is.na(df))\ncolSums(is.na(df))\n\n\n# Basic info\nsize(df)                 # (rows, columns)\ndescribe(df)             # Statistical summary\nnames(df)                # Column names\neltype.(eachcol(df))     # Column types\n\n# First/last rows\nfirst(df, 5)             # First 5 rows\nlast(df, 5)              # Last 5 rows\n\n# Unique values\nlength(unique(df.name))\nunique(df.name)\ncountmap(df.name)        # Using StatsBase\n\n# Missing values\nsum(ismissing.(df.name))"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#selecting-data",
    "href": "pages/python_r_julia_expanded.html#selecting-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Selecting Data",
    "text": "Selecting Data\n\nPythonRJulia\n\n\n# Select columns\ndf['name']                    # Single column (Series)\ndf[['name', 'age']]          # Multiple columns\n\n# Select rows by position\ndf.iloc[0]                    # First row\ndf.iloc[0:3]                  # First 3 rows\ndf.iloc[[0, 2, 4]]           # Specific rows\n\n# Select rows by label\ndf.loc[0]                     # Row with index 0\ndf.loc[0:2, ['name', 'age']] # Rows and columns\n\n# Select by condition\ndf[df['age'] &gt; 30]\ndf[(df['age'] &gt; 25) & (df['salary'] &gt; 55000)]\ndf.query('age &gt; 25 and salary &gt; 55000')\n\n\n# Select columns\ndf$name                       # Single column\ndf[, c(\"name\", \"age\")]       # Multiple columns\nselect(df, name, age)         # dplyr\n\n# Select rows by position\ndf[1, ]                       # First row\ndf[1:3, ]                     # First 3 rows\nslice(df, 1:3)                # dplyr\n\n# Select by condition\ndf[df$age &gt; 30, ]\nfilter(df, age &gt; 30)          # dplyr\nfilter(df, age &gt; 25, salary &gt; 55000)\n\n# Combined selection\ndf %&gt;%\n  filter(age &gt; 25) %&gt;%\n  select(name, salary)\n\n\n# Select columns\ndf.name                       # Single column\ndf[:, [:name, :age]]         # Multiple columns\nselect(df, :name, :age)\n\n# Select rows by position\ndf[1, :]                      # First row\ndf[1:3, :]                    # First 3 rows\n\n# Select by condition\ndf[df.age .&gt; 30, :]\nfilter(row -&gt; row.age &gt; 30, df)\nfilter(row -&gt; row.age &gt; 25 && row.salary &gt; 55000, df)\n\n# Combined selection\ndf |&gt; \n  x -&gt; filter(row -&gt; row.age &gt; 25, x) |&gt;\n  x -&gt; select(x, :name, :salary)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#data-manipulation",
    "href": "pages/python_r_julia_expanded.html#data-manipulation",
    "title": "Python, R, and Julia for Data Science",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n\nPythonRJulia\n\n\n# Add new column\ndf['bonus'] = df['salary'] * 0.1\ndf = df.assign(total_comp=df['salary'] + df['bonus'])\n\n# Modify existing column\ndf['age'] = df['age'] + 1\n\n# Drop columns\ndf = df.drop(['bonus'], axis=1)\n\n# Rename columns\ndf = df.rename(columns={'name': 'employee_name'})\n\n# Replace values\ndf['name'] = df['name'].replace('Alice', 'Alicia')\n\n# Apply function\ndf['age_group'] = df['age'].apply(lambda x: 'Young' if x &lt; 30 else 'Adult')\n\n\n# Add new column\ndf$bonus &lt;- df$salary * 0.1\ndf &lt;- df %&gt;% mutate(total_comp = salary + bonus)\n\n# Modify existing column\ndf$age &lt;- df$age + 1\ndf &lt;- df %&gt;% mutate(age = age + 1)\n\n# Drop columns\ndf &lt;- df %&gt;% select(-bonus)\n\n# Rename columns\ndf &lt;- df %&gt;% rename(employee_name = name)\n\n# Replace values\ndf$name[df$name == \"Alice\"] &lt;- \"Alicia\"\ndf &lt;- df %&gt;% mutate(name = if_else(name == \"Alice\", \"Alicia\", name))\n\n# Apply function\ndf &lt;- df %&gt;% \n  mutate(age_group = if_else(age &lt; 30, \"Young\", \"Adult\"))\n\n\n# Add new column\ndf.bonus = df.salary .* 0.1\ntransform!(df, :salary =&gt; (x -&gt; x .* 0.1) =&gt; :bonus)\n\n# Modify existing column\ndf.age = df.age .+ 1\ntransform!(df, :age =&gt; (x -&gt; x .+ 1) =&gt; :age)\n\n# Drop columns\nselect!(df, Not(:bonus))\n\n# Rename columns\nrename!(df, :name =&gt; :employee_name)\n\n# Replace values\ndf.name = replace(df.name, \"Alice\" =&gt; \"Alicia\")\n\n# Apply function\ndf.age_group = [x &lt; 30 ? \"Young\" : \"Adult\" for x in df.age]"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#grouping-and-aggregation",
    "href": "pages/python_r_julia_expanded.html#grouping-and-aggregation",
    "title": "Python, R, and Julia for Data Science",
    "section": "Grouping and Aggregation",
    "text": "Grouping and Aggregation\n\nPythonRJulia\n\n\n# Simple aggregation\ndf.groupby('age_group')['salary'].mean()\n\n# Multiple aggregations\nagg_df = df.groupby('age_group').agg({\n    'salary': ['mean', 'std', 'count'],\n    'age': ['min', 'max']\n}).reset_index()\n\n# Custom aggregation\ndef custom_agg(x):\n    return pd.Series({\n        'mean_salary': x['salary'].mean(),\n        'total_comp': x['salary'].sum(),\n        'employee_count': len(x)\n    })\n\nresult = df.groupby('age_group').apply(custom_agg)\n\n# Transform (same size output)\ndf['salary_zscore'] = df.groupby('age_group')['salary'].transform(\n    lambda x: (x - x.mean()) / x.std()\n)\n\n\n# Simple aggregation\ndf %&gt;% \n  group_by(age_group) %&gt;% \n  summarise(mean_salary = mean(salary))\n\n# Multiple aggregations\nagg_df &lt;- df %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(\n    mean_salary = mean(salary),\n    std_salary = sd(salary),\n    count = n(),\n    min_age = min(age),\n    max_age = max(age)\n  )\n\n# Custom aggregation\ndf %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(\n    mean_salary = mean(salary),\n    total_comp = sum(salary),\n    employee_count = n(),\n    .groups = 'drop'\n  )\n\n# Transform (same size output)\ndf &lt;- df %&gt;%\n  group_by(age_group) %&gt;%\n  mutate(salary_zscore = (salary - mean(salary)) / sd(salary))\n\n\nusing Statistics\n\n# Simple aggregation\ncombine(groupby(df, :age_group), :salary =&gt; mean)\n\n# Multiple aggregations\nagg_df = combine(groupby(df, :age_group),\n    :salary =&gt; mean =&gt; :mean_salary,\n    :salary =&gt; std =&gt; :std_salary,\n    nrow =&gt; :count,\n    :age =&gt; minimum =&gt; :min_age,\n    :age =&gt; maximum =&gt; :max_age\n)\n\n# Custom aggregation\ncombine(groupby(df, :age_group)) do sdf\n    DataFrame(\n        mean_salary = mean(sdf.salary),\n        total_comp = sum(sdf.salary),\n        employee_count = nrow(sdf)\n    )\nend\n\n# Transform (same size output)\ntransform!(groupby(df, :age_group),\n    :salary =&gt; (x -&gt; (x .- mean(x)) ./ std(x)) =&gt; :salary_zscore\n)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#joiningmerging-data",
    "href": "pages/python_r_julia_expanded.html#joiningmerging-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Joining/Merging Data",
    "text": "Joining/Merging Data\n\nPythonRJulia\n\n\n# Sample DataFrames\ndf1 = pd.DataFrame({'id': [1, 2, 3], 'name': ['A', 'B', 'C']})\ndf2 = pd.DataFrame({'id': [2, 3, 4], 'value': [10, 20, 30]})\n\n# Inner join\ninner = pd.merge(df1, df2, on='id', how='inner')\n\n# Left join\nleft = pd.merge(df1, df2, on='id', how='left')\n\n# Right join\nright = pd.merge(df1, df2, on='id', how='right')\n\n# Outer join\nouter = pd.merge(df1, df2, on='id', how='outer')\n\n# Join on multiple columns\nmerged = pd.merge(df1, df2, on=['id', 'date'], how='inner')\n\n# Join with different column names\nmerged = pd.merge(df1, df2, left_on='id1', right_on='id2')\n\n\n# Sample data frames\ndf1 &lt;- tibble(id = c(1, 2, 3), name = c(\"A\", \"B\", \"C\"))\ndf2 &lt;- tibble(id = c(2, 3, 4), value = c(10, 20, 30))\n\n# Inner join\ninner &lt;- inner_join(df1, df2, by = \"id\")\n\n# Left join\nleft &lt;- left_join(df1, df2, by = \"id\")\n\n# Right join\nright &lt;- right_join(df1, df2, by = \"id\")\n\n# Full outer join\nouter &lt;- full_join(df1, df2, by = \"id\")\n\n# Join on multiple columns\nmerged &lt;- inner_join(df1, df2, by = c(\"id\", \"date\"))\n\n# Join with different column names\nmerged &lt;- left_join(df1, df2, by = c(\"id1\" = \"id2\"))\n\n\n# Sample DataFrames\ndf1 = DataFrame(id = [1, 2, 3], name = [\"A\", \"B\", \"C\"])\ndf2 = DataFrame(id = [2, 3, 4], value = [10, 20, 30])\n\n# Inner join\ninner = innerjoin(df1, df2, on = :id)\n\n# Left join\nleft = leftjoin(df1, df2, on = :id)\n\n# Right join\nright = rightjoin(df1, df2, on = :id)\n\n# Outer join\nouter = outerjoin(df1, df2, on = :id)\n\n# Join on multiple columns\nmerged = innerjoin(df1, df2, on = [:id, :date])\n\n# Join with different column names\nmerged = leftjoin(df1, df2, on = :id1 =&gt; :id2)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#reshaping-data",
    "href": "pages/python_r_julia_expanded.html#reshaping-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Reshaping Data",
    "text": "Reshaping Data\n\nPythonRJulia\n\n\n# Wide to long (melt)\nlong_df = pd.melt(df, \n                  id_vars=['id', 'name'],\n                  value_vars=['value1', 'value2'],\n                  var_name='variable',\n                  value_name='value')\n\n# Long to wide (pivot)\nwide_df = long_df.pivot(index='id',\n                        columns='variable',\n                        values='value')\n\n# Pivot table with aggregation\npivot_table = pd.pivot_table(df,\n                             values='value',\n                             index='category',\n                             columns='year',\n                             aggfunc='mean')\n\n# Stack/unstack\nstacked = df.set_index(['id', 'name']).stack()\nunstacked = stacked.unstack()\n\n\nlibrary(tidyr)\n\n# Wide to long\nlong_df &lt;- df %&gt;%\n  pivot_longer(cols = c(value1, value2),\n               names_to = \"variable\",\n               values_to = \"value\")\n\n# Long to wide\nwide_df &lt;- long_df %&gt;%\n  pivot_wider(names_from = variable,\n              values_from = value)\n\n# With aggregation\nwide_df &lt;- long_df %&gt;%\n  pivot_wider(names_from = variable,\n              values_from = value,\n              values_fn = mean)\n\n# Separate and unite columns\ndf %&gt;%\n  separate(full_name, into = c(\"first\", \"last\"), sep = \" \") %&gt;%\n  unite(full_name, first, last, sep = \"_\")\n\n\n# Wide to long (stack)\nlong_df = stack(df, [:value1, :value2],\n                variable_name = :variable,\n                value_name = :value)\n\n# Long to wide (unstack)\nwide_df = unstack(long_df, :id, :variable, :value)\n\n# With aggregation\nwide_df = unstack(long_df, :id, :variable, :value, \n                  combine = mean)\n\n# Custom reshaping\nwide_df = combine(groupby(long_df, [:id, :variable])) do sdf\n    DataFrame(value = mean(sdf.value))\nend |&gt; \nx -&gt; unstack(x, :id, :variable, :value)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#missing-data-handling",
    "href": "pages/python_r_julia_expanded.html#missing-data-handling",
    "title": "Python, R, and Julia for Data Science",
    "section": "Missing Data Handling",
    "text": "Missing Data Handling\n\nPythonRJulia\n\n\n# Check for missing\ndf.isnull().sum()\ndf.isna().any()\n\n# Drop missing\ndf.dropna()                     # Drop rows with any NaN\ndf.dropna(subset=['col1'])     # Drop rows where col1 is NaN\ndf.dropna(axis=1)              # Drop columns with any NaN\n\n# Fill missing\ndf.fillna(0)                   # Fill with constant\ndf.fillna(method='ffill')      # Forward fill\ndf.fillna(method='bfill')      # Backward fill\ndf.fillna(df.mean())           # Fill with mean\n\n# Interpolate\ndf.interpolate(method='linear')\n\n\n# Check for missing\nsum(is.na(df))\ncolSums(is.na(df))\ncomplete.cases(df)\n\n# Drop missing\nna.omit(df)                    # Drop rows with any NA\ndrop_na(df)                    # tidyr version\ndrop_na(df, col1)              # Drop rows where col1 is NA\n\n# Fill missing\nreplace_na(df, list(col1 = 0, col2 = \"Unknown\"))\nfill(df, col1, .direction = \"down\")  # Fill down\nfill(df, col1, .direction = \"up\")    # Fill up\n\n# Replace with mean\ndf %&gt;%\n  mutate(col1 = if_else(is.na(col1), mean(col1, na.rm = TRUE), col1))\n\n\n# Check for missing\nsum(ismissing.(df.col1))\nany(ismissing.(df.col1))\n\n# Drop missing\ndropmissing(df)                # Drop rows with any missing\ndropmissing(df, :col1)         # Drop rows where col1 is missing\n\n# Fill missing\ncoalesce.(df.col1, 0)          # Replace missing with 0\ndf.col1 = coalesce.(df.col1, mean(skipmissing(df.col1)))\n\n# Forward/backward fill\nfunction ffill!(v)\n    for i in 2:length(v)\n        if ismissing(v[i])\n            v[i] = v[i-1]\n        end\n    end\nend"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#string-operations",
    "href": "pages/python_r_julia_expanded.html#string-operations",
    "title": "Python, R, and Julia for Data Science",
    "section": "String Operations",
    "text": "String Operations\n\nPythonRJulia\n\n\n# String methods\ndf['name'].str.lower()          # Lowercase\ndf['name'].str.upper()          # Uppercase\ndf['name'].str.title()          # Title case\ndf['name'].str.strip()          # Remove whitespace\ndf['name'].str.len()            # String length\n\n# Pattern matching\ndf['name'].str.contains('pattern')\ndf['name'].str.startswith('A')\ndf['name'].str.endswith('z')\n\n# Extraction and replacement\ndf['name'].str.extract(r'(\\d+)')       # Extract numbers\ndf['name'].str.replace('old', 'new')   # Replace\ndf['name'].str.split('_', expand=True) # Split into columns\n\n# Concatenation\ndf['full_name'] = df['first'] + ' ' + df['last']\n\n\nlibrary(stringr)\n\n# String functions\nstr_to_lower(df$name)           # Lowercase\nstr_to_upper(df$name)           # Uppercase\nstr_to_title(df$name)           # Title case\nstr_trim(df$name)               # Remove whitespace\nstr_length(df$name)             # String length\n\n# Pattern matching\nstr_detect(df$name, \"pattern\")\nstr_starts(df$name, \"A\")\nstr_ends(df$name, \"z\")\n\n# Extraction and replacement\nstr_extract(df$name, \"\\\\d+\")    # Extract numbers\nstr_replace(df$name, \"old\", \"new\")\nstr_split(df$name, \"_\")         # Split\n\n# Concatenation\nstr_c(df$first, df$last, sep = \" \")\npaste(df$first, df$last)\n\n\n# String functions\nlowercase.(df.name)              # Lowercase\nuppercase.(df.name)              # Uppercase\ntitlecase.(df.name)              # Title case\nstrip.(df.name)                  # Remove whitespace\nlength.(df.name)                 # String length\n\n# Pattern matching\noccursin.(\"pattern\", df.name)\nstartswith.(df.name, \"A\")\nendswith.(df.name, \"z\")\n\n# Extraction and replacement\nmatch.(r\"\\d+\", df.name)          # Extract numbers\nreplace.(df.name, \"old\" =&gt; \"new\")\nsplit.(df.name, \"_\")             # Split\n\n# Concatenation\ndf.full_name = df.first .* \" \" .* df.last"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#date-and-time",
    "href": "pages/python_r_julia_expanded.html#date-and-time",
    "title": "Python, R, and Julia for Data Science",
    "section": "Date and Time",
    "text": "Date and Time\n\nPythonRJulia\n\n\n# Parse dates\ndf['date'] = pd.to_datetime(df['date_string'])\ndf['date'] = pd.to_datetime(df['date_string'], format='%Y-%m-%d')\n\n# Extract components\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\ndf['weekday'] = df['date'].dt.dayofweek\ndf['quarter'] = df['date'].dt.quarter\n\n# Date arithmetic\ndf['next_month'] = df['date'] + pd.DateOffset(months=1)\ndf['days_diff'] = (df['end_date'] - df['start_date']).dt.days\n\n# Date ranges\ndates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\nbusiness_days = pd.bdate_range('2023-01-01', '2023-12-31')\n\n\nlibrary(lubridate)\n\n# Parse dates\ndf$date &lt;- ymd(df$date_string)\ndf$date &lt;- as.Date(df$date_string, format = \"%Y-%m-%d\")\n\n# Extract components\ndf$year &lt;- year(df$date)\ndf$month &lt;- month(df$date)\ndf$day &lt;- day(df$date)\ndf$weekday &lt;- wday(df$date)\ndf$quarter &lt;- quarter(df$date)\n\n# Date arithmetic\ndf$next_month &lt;- df$date %m+% months(1)\ndf$days_diff &lt;- as.numeric(df$end_date - df$start_date)\n\n# Date sequences\ndates &lt;- seq(ymd(\"2023-01-01\"), ymd(\"2023-12-31\"), by = \"day\")\n\n\nusing Dates\n\n# Parse dates\ndf.date = Date.(df.date_string, \"yyyy-mm-dd\")\n\n# Extract components\ndf.year = year.(df.date)\ndf.month = month.(df.date)\ndf.day = day.(df.date)\ndf.weekday = dayofweek.(df.date)\ndf.quarter = quarterofyear.(df.date)\n\n# Date arithmetic\ndf.next_month = df.date .+ Month(1)\ndf.days_diff = df.end_date .- df.start_date\n\n# Date ranges\ndates = Date(2023,1,1):Day(1):Date(2023,12,31)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#statistical-operations",
    "href": "pages/python_r_julia_expanded.html#statistical-operations",
    "title": "Python, R, and Julia for Data Science",
    "section": "Statistical Operations",
    "text": "Statistical Operations\n\nPythonRJulia\n\n\n# Descriptive statistics\ndf.mean()\ndf.median()\ndf.std()\ndf.var()\ndf.quantile([0.25, 0.75])\ndf.corr()                       # Correlation matrix\n\n# Rolling statistics\ndf['rolling_mean'] = df['value'].rolling(window=7).mean()\ndf['rolling_std'] = df['value'].rolling(window=7).std()\n\n# Ranking\ndf['rank'] = df['value'].rank()\ndf['pct_rank'] = df['value'].rank(pct=True)\n\n# Statistical tests\nfrom scipy import stats\nt_stat, p_value = stats.ttest_ind(group1, group2)\ncorrelation, p_value = stats.pearsonr(x, y)\n\n\n# Descriptive statistics\nmean(df$value)\nmedian(df$value)\nsd(df$value)\nvar(df$value)\nquantile(df$value, c(0.25, 0.75))\ncor(df[, numeric_cols])        # Correlation matrix\n\n# Rolling statistics (using zoo or slider)\nlibrary(zoo)\ndf$rolling_mean &lt;- rollmean(df$value, 7, fill = NA)\n\n# Ranking\ndf$rank &lt;- rank(df$value)\ndf$pct_rank &lt;- percent_rank(df$value)\n\n# Statistical tests\nt.test(group1, group2)\ncor.test(x, y)\n\n\nusing Statistics\n\n# Descriptive statistics\nmean(df.value)\nmedian(df.value)\nstd(df.value)\nvar(df.value)\nquantile(df.value, [0.25, 0.75])\ncor(Matrix(df[:, numeric_cols]))  # Correlation matrix\n\n# Rolling statistics\nusing RollingFunctions\ndf.rolling_mean = rollmean(df.value, 7)\ndf.rolling_std = rollstd(df.value, 7)\n\n# Ranking\nusing StatsBase\ndf.rank = ordinalrank(df.value)\ndf.pct_rank = percentrank(df.value)\n\n# Statistical tests\nusing HypothesisTests\nOneSampleTTest(group1, group2)\nCorrelationTest(x, y)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#visualization-basics",
    "href": "pages/python_r_julia_expanded.html#visualization-basics",
    "title": "Python, R, and Julia for Data Science",
    "section": "Visualization Basics",
    "text": "Visualization Basics\n\nPythonRJulia\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Basic plots\nplt.plot(x, y)                 # Line plot\nplt.scatter(x, y)              # Scatter plot\nplt.hist(data, bins=30)        # Histogram\nplt.bar(categories, values)    # Bar plot\n\n# Seaborn plots\nsns.scatterplot(data=df, x='x', y='y', hue='category')\nsns.boxplot(data=df, x='category', y='value')\nsns.heatmap(df.corr(), annot=True)\n\n# Pandas plotting\ndf.plot(kind='line')\ndf.plot(kind='scatter', x='col1', y='col2')\ndf['value'].hist()\n\n\nlibrary(ggplot2)\n\n# Basic ggplot\nggplot(df, aes(x = x, y = y)) + \n  geom_point()                  # Scatter plot\n\nggplot(df, aes(x = x, y = y)) + \n  geom_line()                   # Line plot\n\nggplot(df, aes(x = value)) + \n  geom_histogram(bins = 30)    # Histogram\n\nggplot(df, aes(x = category, y = value)) + \n  geom_boxplot()                # Boxplot\n\n# Faceting\nggplot(df, aes(x = x, y = y)) + \n  geom_point() + \n  facet_wrap(~ category)\n\n\nusing Plots\n\n# Basic plots\nplot(x, y)                      # Line plot\nscatter(x, y)                   # Scatter plot\nhistogram(data, bins=30)        # Histogram\nbar(categories, values)         # Bar plot\n\n# StatsPlots for DataFrames\nusing StatsPlots\n@df df scatter(:x, :y, group=:category)\n@df df boxplot(:category, :value)\n\n# Multiple series\nplot(x, [y1 y2 y3], label=[\"Series 1\" \"Series 2\" \"Series 3\"])"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#performance-optimization",
    "href": "pages/python_r_julia_expanded.html#performance-optimization",
    "title": "Python, R, and Julia for Data Science",
    "section": "Performance Optimization",
    "text": "Performance Optimization\n\nPythonRJulia\n\n\n# Vectorization\n# Bad: Loop\nresult = []\nfor i in range(len(df)):\n    result.append(df.iloc[i]['col1'] * 2)\n\n# Good: Vectorized\nresult = df['col1'] * 2\n\n# Use NumPy for numerical operations\nnp_array = df['col1'].values\nresult = np_array * 2\n\n# Categorical data for memory efficiency\ndf['category'] = df['category'].astype('category')\n\n# Parallel processing\nfrom multiprocessing import Pool\nwith Pool(4) as p:\n    results = p.map(process_function, data_chunks)\n\n\n# Vectorization\n# Bad: Loop\nresult &lt;- c()\nfor(i in 1:nrow(df)) {\n  result[i] &lt;- df$col1[i] * 2\n}\n\n# Good: Vectorized\nresult &lt;- df$col1 * 2\n\n# Use data.table for speed\nlibrary(data.table)\ndt &lt;- as.data.table(df)\ndt[, new_col := col1 * 2]\n\n# Parallel processing\nlibrary(parallel)\ncl &lt;- makeCluster(4)\nresults &lt;- parLapply(cl, data_chunks, process_function)\nstopCluster(cl)\n\n\n# Julia is fast by default!\n# Type stability\nfunction process_data(x::Vector{Float64})\n    return x .* 2\nend\n\n# Broadcasting\nresult = df.col1 .* 2\n\n# Parallel processing\nusing Distributed\naddprocs(4)\n@distributed for i in 1:n\n    process_chunk(data[i])\nend\n\n# Threads\nThreads.@threads for i in 1:n\n    process_chunk(data[i])\nend"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#machine-learning-basics",
    "href": "pages/python_r_julia_expanded.html#machine-learning-basics",
    "title": "Python, R, and Julia for Data Science",
    "section": "Machine Learning Basics",
    "text": "Machine Learning Basics\n\nPythonRJulia\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\n\n\n# Split data\nlibrary(caret)\ntrain_idx &lt;- createDataPartition(y, p = 0.8, list = FALSE)\nX_train &lt;- X[train_idx, ]\nX_test &lt;- X[-train_idx, ]\ny_train &lt;- y[train_idx]\ny_test &lt;- y[-train_idx]\n\n# Train model\nmodel &lt;- lm(y ~ ., data = train_data)\n\n# Predict\ny_pred &lt;- predict(model, newdata = test_data)\n\n# Evaluate\nmse &lt;- mean((y_test - y_pred)^2)\n\n\nusing MLJ\n\n# Split data\ntrain, test = partition(eachindex(y), 0.8, shuffle=true)\nX_train, X_test = X[train, :], X[test, :]\ny_train, y_test = y[train], y[test]\n\n# Train model\nLinearRegressor = @load LinearRegressor pkg=MLJLinearModels\nmodel = LinearRegressor()\nmach = machine(model, X_train, y_train)\nfit!(mach)\n\n# Predict\ny_pred = predict(mach, X_test)\n\n# Evaluate\nmse = mean((y_test .- y_pred).^2)"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#best-practices-and-tips",
    "href": "pages/python_r_julia_expanded.html#best-practices-and-tips",
    "title": "Python, R, and Julia for Data Science",
    "section": "Best Practices and Tips",
    "text": "Best Practices and Tips\n\nWhen to Use Each Language\nPython - General-purpose programming - Machine learning and deep learning - Web applications with data backends - Large ecosystem of libraries\nR - Statistical analysis and modeling - Academic research - Data visualization (ggplot2) - Statistical reporting (R Markdown)\nJulia - High-performance computing - Scientific simulations - Numerical optimization - When Python is too slow but C is too complex\n\n\nCommon Pitfalls and Solutions\n\n\n\nIssue\nPython\nR\nJulia\n\n\n\n\nMemory\nUse chunks, dask\nUse data.table\nBuilt-in efficiency\n\n\nSpeed\nUse NumPy, Numba\nUse Rcpp\nAlready fast\n\n\nType Issues\nCheck dtypes\nUse typeof()\nType annotations\n\n\nMissing Data\nUse pd.NA\nUse NA\nUse missing\n\n\n\n\n\nPackage Ecosystems\n\n\n\n\n\n\n\n\n\nDomain\nPython\nR\nJulia\n\n\n\n\nData Manipulation\npandas\ndplyr, data.table\nDataFrames.jl\n\n\nVisualization\nmatplotlib, seaborn\nggplot2\nPlots.jl\n\n\nMachine Learning\nscikit-learn\ncaret, mlr3\nMLJ.jl\n\n\nDeep Learning\nTensorFlow, PyTorch\nkeras, torch\nFlux.jl\n\n\nStatistics\nscipy, statsmodels\nBuilt-in, many packages\nStatsBase.jl"
  },
  {
    "objectID": "pages/python_r_julia_expanded.html#conclusion",
    "href": "pages/python_r_julia_expanded.html#conclusion",
    "title": "Python, R, and Julia for Data Science",
    "section": "Conclusion",
    "text": "Conclusion\nEach language has its strengths: - Python: Versatility and ecosystem - R: Statistical depth and visualization - Julia: Performance and mathematical elegance\nChoose based on your specific needs, team expertise, and project requirements. Many data scientists use multiple languages, leveraging each for its strengths.\n\nFurther Resources\nPython - Pandas Documentation - Python Data Science Handbook\nR - R for Data Science - Advanced R\nJulia - Julia Documentation - Julia Data Science\nHappy coding in your language of choice!"
  },
  {
    "objectID": "pages/pixi_and_conda.html",
    "href": "pages/pixi_and_conda.html",
    "title": "Package Managers",
    "section": "",
    "text": "When you work with Python for scientific computing or data analysis, you need a way to install and manage software packages – collections of code that others have written to help you analyze data, create visualizations, or perform calculations. Sometimes, however, the versions of packages you need for one project conflicts with the versions you need for other projects that you work on in parallel. Such conflicts seem like an unsolvable problem. Would it not be fantastic if you could create small insulated worlds for each project, which then only contained the packages needed for each particular project?. If each project had its own isolated world, then there would be no such version conflicts. Fortunately, there are tools like Pixi and Conda that lets you do just that. The small worlds that are called “environments”. You can create as many environments as you like, and then use each one for a separate bioinformatics project, a course, a bachelor project, or whatever you would like to insulate from everything else.\nThis is where package managers come in. A package manager is a tool that handles all the complexity of downloading, installing, and organizing these packages for you. It’s like having an app store for your scientific computing needs. We’ll introduce two package managers: Pixi (a modern, fast tool) and Conda (the traditional aging standard). Both do the same job but in slightly different ways. We’ll start with Pixi because it’s simpler and faster for beginners.\nPackage management might seem complex at first, but it quickly becomes second nature. Every data scientist and researcher uses these tools daily – with a little practice, you’ll wonder how you ever worked without them.",
    "crumbs": [
      "Reference",
      "Package Managers"
    ]
  },
  {
    "objectID": "pages/pixi_and_conda.html#pixi-the-modern-approach",
    "href": "pages/pixi_and_conda.html#pixi-the-modern-approach",
    "title": "Package Managers",
    "section": "Pixi: The Modern Approach",
    "text": "Pixi: The Modern Approach\nImagine you’re starting a new research project. You create a folder on your computer for all your project files – your data, your analysis scripts, your results. Pixi works within this project folder, creating a self-contained environment just for this project.\nWhen you initialize Pixi in your project folder, it creates a special file called pixi.toml that acts like a shopping list of all the packages your project needs. Every time you add a package, Pixi updates this list. This means if you share your project with a colleague or move it to another computer, Pixi can read this list and install exactly the same packages, ensuring your analysis works the same way everywhere.\nPixi stores all the installed packages in a hidden folder called .pixi within your project. This keeps everything organized and separate from other projects on your computer. Different projects can use different versions of the same package without interfering with each other.\n\nInstalling Pixi\nBefore you can use Pixi, you need to install it on your computer. The installation is a one-time process.\n\nOn Mac/LinuxOn Windows\n\n\nOpen the Terminal and run:\ncurl -fsSL https://pixi.sh/install.sh | bash\nAfter installation, close and reopen your terminal to make sure your computer recognizes the new pixi command.\n\n\nOpen PowerShell and run:\niwr -useb https://pixi.sh/install.ps1 | iex\nAfter installation, close and reopen your powershell to make sure your computer recognizes the new pixi command.\n\n\n\n\n\nUsing Pixi\n\nGlobal Install: System-Wide Tools\nSometimes you want to install a tool that you’ll use across many projects, not just one specific project. These are tools that are not directly involved in any projects. Pixi’s global install feature is perfect for this. It’s like installing a program on your computer that you can use anywhere (by way of mention, this is also the way we would install franklin).\nFor example, to install git (a popular tool for version control in computing) globally:\npixi global install git\nAfter this command completes, you can start JupyterLab from anywhere on your computer by typing git in your terminal. The tool is available system-wide, not tied to any specific project.\n\n\nAdd: Installing Packages for Your Project\nWhen you’re working on a specific project and need packages just for that project, you use the add command. A special feature of Pixi is that it is is tied to and lives in the root folder of your project. So before you begin, navigate to your project folder in the terminal, then initialize Pixi if you haven’t already:\npixi init\nThis creates the pixi.toml file we mentioned earlier. Now you can add packages to your project. For example, if you’re doing data analysis, you might need pandas (for data manipulation) and matplotlib (for creating graphs):\npixi add pandas matplotlib\nPixi will download these packages and all their dependencies (other packages they need to work properly), storing them in your project’s .pixi folder. It also updates your pixi.toml file to remember what you’ve installed.\nYou can add as many packages as you need:\npixi add numpy scipy scikit-learn\nIf you need a package from PyPI (Python’s main package repository) that isn’t available in the conda ecosystem, you can add it with the --pypi flag:\npixi add --pypi requests beautifulsoup4\n\n\nShell: Activating Your Project Environment\nOnce you’ve added packages to your project, you need to “activate” the project environment to use them. This is like telling your computer “I want to work on this specific project now, so please use the packages I’ve installed for it.”\nTo activate your project environment:\npixi shell\nYour terminal prompt will change to show you’re now working in the Pixi environment. Now when you run Python or any of your installed packages, you’ll be using the versions specific to this project.\nWhile in the shell, you can: - Run Python scripts that use your installed packages - Start Jupyter notebooks - Use any command-line tools you’ve added to the project\nTo leave the project environment and return to your normal terminal, simply type:\nexit",
    "crumbs": [
      "Reference",
      "Package Managers"
    ]
  },
  {
    "objectID": "pages/pixi_and_conda.html#conda-the-traditional-standard",
    "href": "pages/pixi_and_conda.html#conda-the-traditional-standard",
    "title": "Package Managers",
    "section": "Conda: The Traditional Standard",
    "text": "Conda: The Traditional Standard\n\nHow Conda Works\nConda takes a different approach from Pixi and its environments are not tied to specific folders. Instead, Conda creates named environments that live in a central location on your computer. Think of it like having different workspaces that you can switch between, each with its own set of installed packages.\nWhen you create a Conda environment, you give it a name. This environment is like a separate Python installation with its own packages. You can have multiple environments – perhaps one for each project, or one for teaching, one for research, and one for experiments. You switch between these environments by “activating” the one you want to use.\nConda has been around much longer than Pixi and has an enormous collection of packages available, especially for scientific computing. It’s widely used in academia and industry.\n\nThe reason we still prefer Pixi is that it manages conda packages better than Conda itself, in addition to being faster and more robust.\n\n\n\nCreate: Making a New Environment\nCreating a new Conda environment is like setting up a fresh workspace. You give it a name and specify which version of Python you want to use.\nTo create a new environment called “myproject” with Python 3.11:\nconda create -n myproject python=3.11\nThe -n flag stands for “name”. Conda will ask you to confirm before creating the environment – just type ‘y’ and press Enter.\nYou can create as many environments as you need, each with a descriptive name:\nconda create -n data-analysis python=3.11\nconda create -n machine-learning python=3.10\nconda create -n web-scraping python=3.11\nEach environment is independent, so you can have different Python versions and different packages in each one.\n\n\nActivate and Deactivate: Switching Environments\nBefore you can use a Conda environment, you need to activate it. This tells your computer which set of packages to use.\nTo activate an environment:\nconda activate myproject\nYou’ll see your terminal prompt change to show the environment name in parentheses, like (myproject). This reminds you which environment you’re currently using.\nWhile an environment is activated, any Python scripts you run or packages you install will use that environment’s Python and packages.\nTo switch to a different environment, just activate it:\nconda activate data-analysis\nWhen you’re done working and want to return to your default system Python, deactivate the environment:\nconda deactivate\nYou can activate and deactivate environments as often as you like – it’s instant and doesn’t affect the packages or files in the environment.\n\n\nInstall: Adding Packages\nOnce you’ve created and activated an environment, you can install packages into it. The install command downloads and sets up packages in your current environment.\nFirst, make sure you’ve activated the environment where you want to install packages:\nconda activate myproject\nThen install packages:\nconda install numpy pandas matplotlib\nConda will show you what it plans to install and ask for confirmation. Type ‘y’ and press Enter to proceed.\nYou can install multiple packages at once or one at a time:\nconda install scipy\nconda install jupyter\nIf a package isn’t available in the default Conda repository, you might need to use the conda-forge channel (a community-maintained collection):\nconda install -c conda-forge plotly\nThe -c flag specifies the channel to use for that installation.",
    "crumbs": [
      "Reference",
      "Package Managers"
    ]
  },
  {
    "objectID": "pages/pixi_and_conda.html#try-it-out",
    "href": "pages/pixi_and_conda.html#try-it-out",
    "title": "Package Managers",
    "section": "Try it out",
    "text": "Try it out\nHere’s a simple example to get you started with each tool:\n\nYour First Pixi Project\n\nCreate a new folder for your project and navigate to it:\nmkdir my-analysis\ncd my-analysis\nInitialize Pixi:\npixi init\nAdd the packages you need:\npixi add python numpy pandas matplotlib jupyter\nStart working:\npixi shell\njupyter notebook\n\n\n\nYour First Conda Environment\n\nCreate a new environment:\nconda create -n my-first-env python=3.11\nActivate it:\nconda activate my-first-env\nInstall packages:\nconda install numpy pandas matplotlib jupyter\nStart working:\njupyter notebook",
    "crumbs": [
      "Reference",
      "Package Managers"
    ]
  },
  {
    "objectID": "pages/installing_python.html",
    "href": "pages/installing_python.html",
    "title": "Installing Python",
    "section": "",
    "text": "You will need to install a modern distribution of Python on your computer. We recommend Miniforge. It is free, lightweight, and comes pre-configured with the community-maintained conda-forge channel, which has the most up-to-date scientific packages.\nOnce Miniforge is installed, you have Conda on your system! The installation also: - Sets up a “base” environment (your default Python environment) - Configures conda-forge as your default package channel (where packages come from) - Adds the conda command to your system so you can use it from any terminal\nIf the conda --version command doesn’t work, try closing and reopening your terminal again. On some systems, you might need to log out and log back in for the changes to take full effect.",
    "crumbs": [
      "Setup",
      "Installing Python"
    ]
  },
  {
    "objectID": "pages/installing_python.html#important-step-after-installation",
    "href": "pages/installing_python.html#important-step-after-installation",
    "title": "Installing Python",
    "section": "Important Step After Installation",
    "text": "Important Step After Installation\nThe Miniforge installer has set up a “base” environment for you that is automatically activated when you open your terminal. You should not install anything into that environment so you are better off disabling the automatic activation like this:\nconda config --set auto_activate_base false\nBack to @installing.",
    "crumbs": [
      "Setup",
      "Installing Python"
    ]
  },
  {
    "objectID": "pages/gitlab.html",
    "href": "pages/gitlab.html",
    "title": "Introduction to GitLab",
    "section": "",
    "text": "GitLab is a complete DevOps platform that combines Git repository hosting with powerful collaboration and automation tools. While GitHub might be more familiar, GitLab offers unique advantages for educational environments, especially when self-hosted by universities.\n\n\n\n\n\nFeature\nGitLab\nGitHub\n\n\n\n\nHosting\nSelf-hosted or cloud\nPrimarily cloud\n\n\nCI/CD\nBuilt-in, unlimited\nActions with limits\n\n\nPrivacy\nComplete control (self-hosted)\nMicrosoft-owned\n\n\nFree Features\nMore generous\nMore limited\n\n\nIntegration\nAll-in-one platform\nRequires multiple tools",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#what-is-gitlab",
    "href": "pages/gitlab.html#what-is-gitlab",
    "title": "Introduction to GitLab",
    "section": "",
    "text": "GitLab is a complete DevOps platform that combines Git repository hosting with powerful collaboration and automation tools. While GitHub might be more familiar, GitLab offers unique advantages for educational environments, especially when self-hosted by universities.\n\n\n\n\n\nFeature\nGitLab\nGitHub\n\n\n\n\nHosting\nSelf-hosted or cloud\nPrimarily cloud\n\n\nCI/CD\nBuilt-in, unlimited\nActions with limits\n\n\nPrivacy\nComplete control (self-hosted)\nMicrosoft-owned\n\n\nFree Features\nMore generous\nMore limited\n\n\nIntegration\nAll-in-one platform\nRequires multiple tools",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#why-gitlab-for-education",
    "href": "pages/gitlab.html#why-gitlab-for-education",
    "title": "Introduction to GitLab",
    "section": "Why GitLab for Education?",
    "text": "Why GitLab for Education?\nEducational institutions often choose GitLab because:\n\nData Control: Self-hosted instances keep student work on university servers\nUnlimited CI/CD: No minute limits for automated testing and deployment\nPrivate Projects: Free private repositories for all students\nIntegration: Works seamlessly with university authentication (LDAP, SAML)\nCompliance: Meets educational privacy requirements",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#core-gitlab-features",
    "href": "pages/gitlab.html#core-gitlab-features",
    "title": "Introduction to GitLab",
    "section": "Core GitLab Features",
    "text": "Core GitLab Features\n\nRepository Management\nGitLab hosts Git repositories with additional features:\n\n\n\n\n\n\ngraph LR\n    A[Local Code] --&gt;|git push| B[GitLab Repo]\n    B --&gt;|git pull| C[Collaborator]\n    B --&gt;|Merge Request| D[Code Review]\n    D --&gt;|Approved| E[Main Branch]\n\n\n\n\nFigure 1: Repository management\n\n\n\n\n\n\n\nProject Organization\nGitLab Instance\n├── Groups (Courses)\n│   ├── Subgroups (Semesters)\n│   └── Projects (Exercises)\n└── Personal Projects\n    └── Student Work\n\n\nCI/CD Pipelines\nAutomatic testing and deployment:\n# .gitlab-ci.yml\ntest:\n  script:\n    - python -m pytest\n    - pixi run test-notebook\n  \ndeploy:\n  script:\n    - franklin exercise publish",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#getting-started-with-gitlab",
    "href": "pages/gitlab.html#getting-started-with-gitlab",
    "title": "Introduction to GitLab",
    "section": "Getting Started with GitLab",
    "text": "Getting Started with GitLab\n\nStep 1: Access Your GitLab Instance\nUniversities typically host GitLab at: - gitlab.university.edu - git.university.edu - code.university.edu\n# Example URLs\nhttps://gitlab.au.dk        # Aarhus University\nhttps://gitlab.ethz.ch      # ETH Zurich\nhttps://gitlab.com          # Public GitLab\n\n\nStep 2: Sign In\nMost university GitLab instances use Single Sign-On (SSO):\n\nNavigate to your GitLab instance\nClick “Sign in with SSO” or “University Login”\nEnter your university credentials\nAuthorize GitLab access\n\n\n\n\n\n\n\nFirst Time Login\n\n\n\nOn first login, GitLab may ask to: - Confirm your email - Set up two-factor authentication - Complete your profile\n\n\n\n\nStep 3: Set Up SSH Keys\nSSH keys enable secure, password-less access to GitLab.\n\nGenerate SSH Keys\n# Check for existing keys\nls -la ~/.ssh\n\n# Generate new Ed25519 key (recommended)\nssh-keygen -t ed25519 -C \"your.email@university.edu\"\n\n# Or RSA key (fallback)\nssh-keygen -t rsa -b 4096 -C \"your.email@university.edu\"\nWhen prompted: 1. Press Enter for default location 2. Enter a passphrase (optional but recommended) 3. Confirm passphrase\n\n\nAdd SSH Key to GitLab\n\nCopy your public key:\n# For Ed25519\ncat ~/.ssh/id_ed25519.pub\n\n# For RSA\ncat ~/.ssh/id_rsa.pub\nAdd to GitLab:\n\nClick your avatar → Preferences\nNavigate to SSH Keys in sidebar\nPaste your public key\nGive it a title (e.g., “Laptop”)\nSet expiration (optional)\nClick Add key\n\nTest connection:\nssh -T git@gitlab.university.edu\n# Should see: \"Welcome to GitLab, @username!\"",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#working-with-gitlab-projects",
    "href": "pages/gitlab.html#working-with-gitlab-projects",
    "title": "Introduction to GitLab",
    "section": "Working with GitLab Projects",
    "text": "Working with GitLab Projects\n\nCreating a Project\n\nClick New project button\nChoose creation method:\n\nCreate blank project: Start from scratch\nCreate from template: Use predefined templates\nImport project: From GitHub, Bitbucket, etc.\n\nConfigure project:\nProject name: my-assignment\nProject URL: gitlab.university.edu/username/\nVisibility: Private (default for coursework)\nInitialize with README: Yes\n\n\n\nCloning a Project\n# With SSH (recommended)\ngit clone git@gitlab.university.edu:username/project.git\n\n# With HTTPS (requires password)\ngit clone https://gitlab.university.edu/username/project.git\n\n# Clone into specific folder\ngit clone git@gitlab.university.edu:username/project.git my-folder\n\n\nBasic GitLab Workflow\n# 1. Clone project\ngit clone git@gitlab.university.edu:course/exercise.git\ncd exercise\n\n# 2. Create feature branch\ngit checkout -b my-solution\n\n# 3. Make changes\necho \"Solution code\" &gt; solution.py\n\n# 4. Commit changes\ngit add solution.py\ngit commit -m \"Add solution for problem 1\"\n\n# 5. Push to GitLab\ngit push origin my-solution\n\n# 6. Create Merge Request in GitLab UI",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#merge-requests-mrs",
    "href": "pages/gitlab.html#merge-requests-mrs",
    "title": "Introduction to GitLab",
    "section": "Merge Requests (MRs)",
    "text": "Merge Requests (MRs)\nMerge Requests are GitLab’s way of proposing changes:\n\nCreating a Merge Request\n\nPush your branch to GitLab\nGitLab shows banner: “Create merge request”\nFill in details:\n\nTitle: Clear description of changes\nDescription: Detailed explanation\nAssignee: Person to review\nMilestone: Related deadline\nLabels: Categories (bug, feature, etc.)\n\n\n\n\nMerge Request Features\n\nCode Review: Line-by-line comments\nCI/CD Integration: Automatic testing\nDiscussions: Threaded conversations\nApprovals: Require reviews before merging\nDiffs: Visual comparison of changes",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#gitlab-cicd",
    "href": "pages/gitlab.html#gitlab-cicd",
    "title": "Introduction to GitLab",
    "section": "GitLab CI/CD",
    "text": "GitLab CI/CD\n\nUnderstanding Pipelines\nGitLab CI/CD runs automated tasks when you push code:\n\n\n\n\n\n\ngraph LR\n    A[Push Code] --&gt; B[Pipeline Triggers]\n    B --&gt; C[Build Stage]\n    C --&gt; D[Test Stage]\n    D --&gt; E[Deploy Stage]\n    E --&gt; F[Success/Failure]\n\n\n\n\nFigure 2: Pipelines\n\n\n\n\n\n\n\nBasic Pipeline Configuration\nCreate .gitlab-ci.yml in your repository:\n# Define stages\nstages:\n  - build\n  - test\n  - deploy\n\n# Build job\nbuild:\n  stage: build\n  script:\n    - echo \"Building project...\"\n    - pip install -r requirements.txt\n\n# Test job\ntest:\n  stage: test\n  script:\n    - echo \"Running tests...\"\n    - python -m pytest\n    - python -m mypy .\n\n# Deploy job (only on main branch)\ndeploy:\n  stage: deploy\n  script:\n    - echo \"Deploying...\"\n    - franklin exercise publish\n  only:\n    - main\n\n\nPipeline Status\nView pipeline status: - Green checkmark ✓ = Passed - Red X = Failed - Yellow circle = Running - Gray circle = Pending",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#gitlab-for-franklin-users",
    "href": "pages/gitlab.html#gitlab-for-franklin-users",
    "title": "Introduction to GitLab",
    "section": "GitLab for Franklin Users",
    "text": "GitLab for Franklin Users\n\nStudent Workflow\nFranklin integrates seamlessly with GitLab:\n# Download exercise from GitLab\nfranklin download\n# → Automatically uses GitLab API\n# → Clones with proper authentication\n\n# Work on exercise\nfranklin jupyter\n\n# Commit changes\ngit add -A\ngit commit -m \"Complete exercise\"\ngit push\n\n\nEducator Workflow\n# Create exercise repository\nfranklin exercise new\n\n# Set up GitLab project\ngit remote add origin git@gitlab.university.edu:course/exercise.git\ngit push -u origin main\n\n# Configure CI/CD\ncat &gt; .gitlab-ci.yml &lt;&lt; EOF\ntest:\n  image: python:3.10\n  script:\n    - pip install pixi\n    - pixi run test-notebook\nEOF\n\n# Publish to students\nfranklin exercise publish\n\n\nGitLab Groups for Courses\nOrganize courses using GitLab groups:\ngitlab.university.edu/\n├── cs101-fall2024/          # Course group\n│   ├── exercises/            # Subgroup\n│   │   ├── week1/           # Exercise project\n│   │   ├── week2/\n│   │   └── final-project/\n│   └── solutions/            # Private subgroup\n└── cs102-spring2025/",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#advanced-gitlab-features",
    "href": "pages/gitlab.html#advanced-gitlab-features",
    "title": "Introduction to GitLab",
    "section": "Advanced GitLab Features",
    "text": "Advanced GitLab Features\n\nIssue Tracking\nTrack tasks, bugs, and questions:\n# Issue Template\n## Problem Description\nDescribe the issue...\n\n## Steps to Reproduce\n1. Run `franklin jupyter`\n2. Open notebook\n3. Error appears\n\n## Expected Behavior\nWhat should happen...\n\n## Environment\n- OS: Windows 11\n- Franklin: 0.24.165\n\n\nWiki Pages\nDocument your project: - Project overview - API documentation - Installation guide - Troubleshooting\n\n\nProtected Branches\nPrevent accidental changes: 1. Settings → Repository → Protected branches 2. Select branch (e.g., main) 3. Configure: - Allowed to merge: Maintainers - Allowed to push: No one\n\n\nAccess Tokens\nFor automation and scripts:\n# Create personal access token\n# GitLab → Settings → Access Tokens\n\n# Use in scripts\ngit clone https://oauth2:YOUR_TOKEN@gitlab.university.edu/project.git\n\n# Or with Franklin\nexport GITLAB_TOKEN=YOUR_TOKEN\nfranklin download --token",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#troubleshooting-gitlab",
    "href": "pages/gitlab.html#troubleshooting-gitlab",
    "title": "Introduction to GitLab",
    "section": "Troubleshooting GitLab",
    "text": "Troubleshooting GitLab\n\nSSH Connection Issues\n# Debug SSH connection\nssh -vvv git@gitlab.university.edu\n\n# Common fixes:\n# 1. Check SSH agent\nssh-add -l\n\n# 2. Add key to agent\nssh-add ~/.ssh/id_ed25519\n\n# 3. Check permissions\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/id_ed25519\n\n\nAuthentication Problems\n# HTTPS credentials\ngit config --global credential.helper store\n\n# SSH configuration\ncat &gt;&gt; ~/.ssh/config &lt;&lt; EOF\nHost gitlab.university.edu\n    User git\n    IdentityFile ~/.ssh/id_ed25519\n    Port 22\nEOF\n\n\nPush Rejected\nCommon reasons and solutions:\n\nProtected branch: Create merge request instead\nNo permissions: Check project access level\nLarge files: Use Git LFS for files &gt;100MB\nOutdated branch: Pull and merge first\n\n# Update your branch\ngit pull origin main\ngit merge main\ngit push",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#gitlab-best-practices",
    "href": "pages/gitlab.html#gitlab-best-practices",
    "title": "Introduction to GitLab",
    "section": "GitLab Best Practices",
    "text": "GitLab Best Practices\n\nFor Students\n✅ Do: - Use descriptive commit messages - Create merge requests for review - Keep repositories organized - Use issues for questions - Tag releases for submissions\n❌ Don’t: - Commit sensitive data (passwords, keys) - Force push to shared branches - Delete other people’s branches - Ignore CI/CD failures\n\n\nFor Educators\n✅ Do: - Use templates for consistency - Set up CI/CD for auto-grading - Create protected branches - Document requirements in README - Use milestones for deadlines\n❌ Don’t: - Store solutions in public repos - Forget to test pipelines - Ignore student access issues - Skip documentation",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#gitlab-vs-local-git",
    "href": "pages/gitlab.html#gitlab-vs-local-git",
    "title": "Introduction to GitLab",
    "section": "GitLab vs Local Git",
    "text": "GitLab vs Local Git\n\n\n\nOperation\nLocal Git\nGitLab\n\n\n\n\nVersion control\n✓\n✓\n\n\nBranching\n✓\n✓\n\n\nCollaboration\n✗\n✓\n\n\nBackup\n✗\n✓\n\n\nCI/CD\n✗\n✓\n\n\nIssue tracking\n✗\n✓\n\n\nCode review\n✗\n✓\n\n\nWiki/Docs\n✗\n✓",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#quick-reference",
    "href": "pages/gitlab.html#quick-reference",
    "title": "Introduction to GitLab",
    "section": "Quick Reference",
    "text": "Quick Reference\n\nEssential GitLab Commands\n# Clone project\ngit clone git@gitlab.university.edu:project.git\n\n# Add GitLab remote\ngit remote add origin git@gitlab.university.edu:project.git\n\n# Push new branch\ngit push -u origin feature-branch\n\n# Update from GitLab\ngit pull origin main\n\n# Check remote\ngit remote -v\n\n\nGitLab CLI (Optional)\n# Install GitLab CLI\nbrew install glab        # macOS\nwinget install glab      # Windows\n\n# Authenticate\nglab auth login\n\n# Create MR from terminal\nglab mr create --title \"Add feature\"\n\n# View pipelines\nglab pipeline list",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#resources",
    "href": "pages/gitlab.html#resources",
    "title": "Introduction to GitLab",
    "section": "Resources",
    "text": "Resources\n\nDocumentation\n\nGitLab Docs\nGitLab University\nGit Basics\n\n\n\nLearning\n\nGitLab 101\nCI/CD Examples\nGitLab Flow",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/gitlab.html#summary",
    "href": "pages/gitlab.html#summary",
    "title": "Introduction to GitLab",
    "section": "Summary",
    "text": "Summary\nGitLab is more than just Git hosting—it’s a complete platform for: - Version Control: Track all changes to your code - Collaboration: Work with classmates and instructors - Automation: Test and deploy automatically - Organization: Manage projects, issues, and documentation\nFor Franklin users, GitLab provides the infrastructure for distributing exercises, submitting solutions, and automated grading. Master these GitLab basics, and you’ll be ready for both academic work and professional software development!",
    "crumbs": [
      "Reference",
      "Introduction to GitLab"
    ]
  },
  {
    "objectID": "pages/getting_started.html#installing",
    "href": "pages/getting_started.html#installing",
    "title": "Getting started",
    "section": "Installing",
    "text": "Installing\nInstall Dependencies:\nFranklin depends on a few external tools that you need to install on your computer before you install Franklin:\n\nIf you have not installed Python already, you can follow the tutorial on how to install a modern version of Python and come back here to continue.\nFranklin is built to interact with the Chrome browser. So make sure is installed on your computer or download it here.\nFranklin uses Docker isolate the setup for each exercise, so you need to install Docker Desktop too. Follow the tutorial on installing Docker and come back here to continue.\n\nWe use Pixi to install Franklin. Pixi is a modern, fast package manager that’s fully compatible with conda packages but offers better performance and reliability. On the page about pixi and conda, you can see how to install it.\nInstall Franklin with Pixi:\n\nStudentEducatorAdministrator\n\n\npixi global install franklin --channel conda-forge --channel munch-group\nVerify installation:\nfranklin --version\n\n\n(Click if you absolutely must install with Conda - not recommended)\n\nActivate your conda environment and run:\nconda install -c conda-forge -c munch-group franklin\nVerify installation:\nfranklin --version\n\n\n\nEducators also include the educator tools in their installation:\npixi global install franklin-educator --channel conda-forge --channel munch-group\nVerify installation:\nfranklin --version\nfranklin exercise --help\n\n\n(Click if you absolutely must install with Conda - not recommended)\n\npixi global install franklin-educator --channel conda-forge --channel munch-group\nVerify installation:\nfranklin --version\nfranklin exercise --help\n\n\n\nEducators also include the educator tools in their installation:\npixi global install franklin-admin --channel conda-forge --channel munch-group\nVerify installation:\nfranklin --version\nfranklin exercise --help\n\n\n(Click if you absolutely must install with Conda - not recommended)\n\npixi global install franklin-admin --channel conda-forge --channel munch-group\nVerify installation:\nfranklin --version\nfranklin finger --help",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "pages/getting_started.html#using-franklin",
    "href": "pages/getting_started.html#using-franklin",
    "title": "Getting started",
    "section": "Using Franklin",
    "text": "Using Franklin\nSimple and robust command line interface in Terminal/PowerShell:\n\nStudentEducatorAdministrator\n\n\n Download an exercise:\n\nRun franklin download\nSelect your course\nSelect the exercise notebook to download\n\n Start working:\n\nRun franklin jupyter\nSelect your course and exercise to make JupyterLab opens in the Chrome browser.\nWork on the exercise\nSave your progress\nClose browser window to stop Franklin.\n\nSee Franklin core commands for the full documentation.\n\n\n Create a new exercise from an example template:\n\nRun franklin exercise new\nSelect your course and name exercise\nEdit exercise visibility in browser window.\nWait a few minutes while the new image builds.\n\n Edit exercise notebook:\n\nRun franklin exercise edit\nSelect your course and exercise to clone the repository pull image.\nEdit notebook in JupyterLab opening in Chrome.\nSave your work.\nClosing the browser window will add, commit, and push your changes to the GitLab exercise repository and initiate the building of an updated Docker image.\n\nSee Core commands, Educator commands, and Admin commands for the full documentation.\n\n\n List users:",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "pages/full_commands_core.html",
    "href": "pages/full_commands_core.html",
    "title": "Running exercises",
    "section": "",
    "text": "Franklin is a command line tool that your run from a terminal. If you are not famililiar with terminals, have a look at this brief introduction before you go on.\nFranklin uses the click library to define a hierarchy of commands and subcommands that you can run in the terminal. franklin is the main command and has the subcommands download, jupyter, update, show, and cleanup. To run each subcommand, you simply append it to franklin, E.g. franklin jupyter. The following sections explain what each subcommand do. Should you forget, you can always just run the main franklin command like this:\nThat will print the following help text to remind you."
  },
  {
    "objectID": "pages/full_commands_core.html#run-jupyter",
    "href": "pages/full_commands_core.html#run-jupyter",
    "title": "Running exercises",
    "section": "Run Jupyter",
    "text": "Run Jupyter\nIn order to open and run the downloaded jupyter notebook, you need a running jupyter with all the required dependencies installed. To spare you the trouble and to make sure everyone run the exercise the same way, franklin can run jupyter in way that exactly fits each exercise. To run jupyter for your downloaded exercise, first make sure you have navigated to the exercise folder using the terminal. Then run this command:\n\n\nTerminal\n\nfranklin jupyter\n\n\n\nClick to see what Franklin does\n\n\ncheck for updates\ncheck internet connection\ncheck enough disk space is available\nchecks that docker is installed\nstarts docker in the background\nFinds the course git repositories in the franklin group.\nPresents you with a list of courses to choose from.\nFinds the git repositories in the course group that are visible to students.\nMatch docker images in the registry to exercise repositories.\nPresents you with a list of exercises to choose from.\nStarts docker and waits for its engine boot up.\nPulls the docker image from the registry if it is not already on your computer.\nLaunches a Linux docker container running with all dependencies installed.\nMakes the container mount the folder with your local files so you can open them in JupyterLab.\nFind an open port if port 8888 is already in use.\nLaunches JupyterLab and forwards the display to a dedicated Google Chrome browser window.\nWaits until you close the Chrome window.\nStops jupyter and the docker container it runs in.\nCloses Docker Desktop\n\n\nJupyterLab opens in your browser. In the file menu in the right pane, you should be able to see your newly downloaded exercise. Open it by double-clicking it and you are ready to begin the exercise. To stop jupyter, simply close the browser window or press Ctrl-C in the terminal window (remember to save your notebook first).\n\n\n\n\n\n\nSubdirectories\n\n\n\nIf the your terminal shows a message saying “You have subdirectories in your current directory”, the folder (directory) from which you ran the franklin jupyter command has other directory in it. For security reasons, Franklin does not allow this. You need to either change to the exercise folder (which has no directory in it), or launch Franklin from another without any subdirectories."
  },
  {
    "objectID": "pages/full_commands_core.html#update-franklin",
    "href": "pages/full_commands_core.html#update-franklin",
    "title": "Running exercises",
    "section": "Update franklin",
    "text": "Update franklin\nFranklin should update automatically when you start it, but if you should need to update it manually you can do it running this command:\n\n\nTerminal\n\nfranklin update\n\n\n\nClick to see what Franklin does\n\n\nChecks for updates to franklin package using either Conda or Pixi dependeing on how franklin is installed.\nDetermines if you are a student or educator.\nUpdates franklin if a newer version exists.\nUpdates the franklin-educator package if you are an educator.\nCloses franklin reporting the update if any.\n\n\nYou can also see which version of franklin you have installed by running franklin --version."
  },
  {
    "objectID": "pages/full_commands_core.html#cleanup-after-franklin",
    "href": "pages/full_commands_core.html#cleanup-after-franklin",
    "title": "Running exercises",
    "section": "Cleanup after Franklin",
    "text": "Cleanup after Franklin\nTo free up disk space, you can run the command below. You will be prompted with a menu showing the “docker images” on your computer. Select all the ones you want to remove and press Enter. Deleting images will not delete any of your own files with saved work.\n\n\nTerminal\n\nfranklin cleanup\n\n\n\nClick to see what Franklin does\n\n\nStarts docker and waits for its engine boot up.\nFinds the exercise stored as docker images on your computer.\nPrompts you with the list of exercises (images), allowing you to select the ones you want to remove.\nCloses all docker containers for those images.\nRemoves the selected images\nPrunes all unused data cached by Docker.\n\n\nMake a habit of running franklin cleanup once in a while. This does not affect any of your own files. The only drawback is that you will have to wait a bit while Franklin downloads images again, should you need them at a later point."
  },
  {
    "objectID": "pages/full_commands_core.html#show-what-franklin-has-on-your-computer",
    "href": "pages/full_commands_core.html#show-what-franklin-has-on-your-computer",
    "title": "Running exercises",
    "section": "Show what Franklin has on your computer",
    "text": "Show what Franklin has on your computer\nIf you are curious, you can use the franklin show subcommands to see what Docker has stored on your computer. The sub commands are images, containers, and storage. To see a summary of how much disk space Docker takes up on your computer for what purpose, you can run this command:\n\n\nTerminal\n\nfranklin show storage\n\nFranklin downloads a linux “docker image” for every exercise. These can take up a lot of space on your computer. Fortunately, you only need each one, when you run the exercise it is made for. So you can delete the ones you are not using to free up space. Franklin will automatically download them again if you need them later. To see the images downloaded to your computer and how much space they take up, you can run this command:\n\n\nTerminal\n\nfranklin show images\n\nFranklin starts a Docker Linux container when you run franklin jupyter. These can take up a lot of space on your computer. Fortunately, you only need each one, when you run the exercise it is made for. So you can delete the ones you are not using to free up space. Franklin will automatically download them again if you need them later. To see the images downloaded to your computer and how much space they take up, you can run this command:\n\n\nTerminal\n\nfranklin show images"
  },
  {
    "objectID": "pages/full_commands_core.html#live-action",
    "href": "pages/full_commands_core.html#live-action",
    "title": "Running exercises",
    "section": "Live action",
    "text": "Live action"
  },
  {
    "objectID": "pages/faq.html",
    "href": "pages/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Under development\n\n\n\nThe content of this page is being developed.\n\n\n\nfranklin-educator is installed in my environemnt but I cannot see the exercise commands\nTry reinstalling franklin-educator:\n\n\nTerminal\n\nconda uninstall franklin-educator\n\nand then\n\n\nTerminal\n\nconda install -c conda-forge -c munch-group franklin-educator\n\n\n\nDocker is installed but franklin keeps complaining it is not\nWhen Docker Desktop is in Eco mode, franklin cannot get to it. If Docker Desktop is not running, franklin can start it for you. So Quit Docker Desktop and try running franklin again.\n\n\nI quit Docker Desktop but it is still running\nThe blue Docker Desktop window is the Docker dashboard. Closing that window will not close Docker Desktop. To close Docker Desktop find the small docker icon in the menu bar on Mac or in the bottom right taskbar on Windows. Look for a tiny whale with containers on its back.\n\n\nHow much space is frankling taking up on my hard disk?\n\n\nHow do I free up disk space used by franklin\n\n\nWhat happens if I delete an exercise in franklin\n\n\nHow do I rename an exercise\nChanges the display name using franklin exercise rename. Do not change the repository name on GitLab.",
    "crumbs": [
      "Help & Support",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/edu_quick_reference.html#jupyter-magic-commands",
    "href": "pages/edu_quick_reference.html#jupyter-magic-commands",
    "title": "Franklin Commands",
    "section": "Jupyter Magic Commands",
    "text": "Jupyter Magic Commands\nInside Jupyter notebooks:\n# Load Franklin magic\n%load_ext magic\n\n# Install packages\n%franklin numpy pandas matplotlib\n%pixi_install scikit-learn tensorflow\n\n# Install specific versions\n%franklin numpy==1.24.0 pandas&gt;=2.0\n\n# Install from different channels\n%franklin -c pytorch pytorch torchvision\n\nExercise Structure\nexercise-name/\n├── Dockerfile                  # Container configuration\n├── pixi.toml                  # Dependencies\n├── exercise.ipynb             # Main notebook\n├── README.md                  # Instructions\n├── data/                      # Data files\n├── tests/                     # Test files\n└── .gitlab-ci.yml            # CI/CD pipeline"
  },
  {
    "objectID": "pages/edu_quick_reference.html#pixi-commands",
    "href": "pages/edu_quick_reference.html#pixi-commands",
    "title": "Franklin Commands",
    "section": "Pixi Commands",
    "text": "Pixi Commands\n\nIn Exercise Directory\npixi install                    # Install dependencies\npixi add numpy                  # Add package\npixi remove pandas              # Remove package\npixi list                       # List installed packages\npixi run test-notebook          # Run tests\npixi shell                      # Activate environment\n\n\nGlobal Pixi\npixi global install jupyter     # Install globally\npixi global list               # List global packages\npixi global update             # Update all packages"
  },
  {
    "objectID": "pages/edu_quick_reference.html#git-commands-for-exercises",
    "href": "pages/edu_quick_reference.html#git-commands-for-exercises",
    "title": "Franklin Commands",
    "section": "Git Commands for Exercises",
    "text": "Git Commands for Exercises\n# Check status\ngit status\n\n# Save your work\ngit add -A\ngit commit -m \"Complete exercise 1\"\n\n# Create your own repository\ngit remote add personal https://github.com/you/solutions\ngit push personal main\n\n# Get updates\ngit pull origin main\n\n# View history\ngit log --oneline"
  },
  {
    "objectID": "pages/edu_quick_reference.html#troubleshooting-commands",
    "href": "pages/edu_quick_reference.html#troubleshooting-commands",
    "title": "Franklin Commands",
    "section": "Troubleshooting Commands",
    "text": "Troubleshooting Commands\n\nDiagnostic Commands\nfranklin doctor                 # System diagnostics\nfranklin doctor --verbose       # Detailed diagnostics\n\n# Check components\ndocker --version\ngit --version\npython --version\npixi --version\n\n\nReset and Repair\n# Reset Franklin configuration\nfranklin reset --config\n\n# Clear cache\nfranklin cache clear\n\n# Reinstall Franklin\nconda remove franklin\nconda install -c conda-forge -c munch-group franklin\n\n# Fix permissions (Linux/Mac)\nsudo chown -R $USER:$USER ~/.franklin\n\n\nLogs and Debugging\n# View logs\nfranklin logs                   # Recent logs\nfranklin logs --tail 50         # Last 50 lines\nfranklin logs --follow          # Follow log output\n\n# Debug mode\nFRANKLIN_DEBUG=1 franklin download\n\n# Verbose output\nfranklin --verbose jupyter"
  },
  {
    "objectID": "pages/edu_quick_reference.html#keyboard-shortcuts",
    "href": "pages/edu_quick_reference.html#keyboard-shortcuts",
    "title": "Franklin Commands",
    "section": "Keyboard Shortcuts",
    "text": "Keyboard Shortcuts\n\nJupyterLab\nShift+Enter    Run cell and move to next\nCtrl+Enter     Run cell\nAlt+Enter      Run cell and insert below\nEsc           Command mode\nEnter         Edit mode\nA             Insert cell above\nB             Insert cell below\nDD            Delete cell\nZ             Undo cell deletion\nCtrl+S        Save notebook\n\n\nTerminal (During Franklin Prompts)\n↑/↓           Navigate options\nEnter         Select option\nCtrl+C        Cancel operation\nTab           Auto-complete\nCtrl+L        Clear screen"
  },
  {
    "objectID": "pages/edu_quick_reference.html#common-workflows",
    "href": "pages/edu_quick_reference.html#common-workflows",
    "title": "Franklin Commands",
    "section": "Common Workflows",
    "text": "Common Workflows\n\nStudent Workflow\n# 1. Download exercise\nfranklin download\n\n# 2. Work on exercise\nfranklin jupyter\n\n# 3. Save and submit\n# (Work is auto-saved in exercise folder)\n\n\nEducator Workflow\n# 1. Create exercise\nfranklin exercise new\n\n# 2. Develop and test\ncd exercise-folder\njupyter lab\npixi run test-notebook\n\n# 3. Publish\nfranklin exercise publish\n\n\nAdministrator Workflow\n# 1. Setup course\nfranklin grant educator prof@university.edu\nfranklin grant ta assistant@university.edu\n\n# 2. Add students\nfranklin grant student --file roster.csv\n\n# 3. Monitor usage\nfranklin stats --course \"CS101\""
  },
  {
    "objectID": "pages/edu_quick_reference.html#package-management",
    "href": "pages/edu_quick_reference.html#package-management",
    "title": "Franklin Commands",
    "section": "Package Management",
    "text": "Package Management\n\nAdding Dependencies to Exercise\n# In exercise directory\npixi add numpy pandas           # Add to pixi.toml\n\n# Or in notebook\n%franklin numpy pandas\n\n# For specific versions\npixi add \"numpy&gt;=1.24,&lt;2.0\"\n\n\nCreating Requirements File\n# Export from pixi\npixi list --export &gt; requirements.txt\n\n# Export from conda\nconda env export &gt; environment.yml"
  },
  {
    "objectID": "pages/edu_quick_reference.html#cicd-integration",
    "href": "pages/edu_quick_reference.html#cicd-integration",
    "title": "Franklin Commands",
    "section": "CI/CD Integration",
    "text": "CI/CD Integration\n\nGitLab CI\n# .gitlab-ci.yml in exercise\ntest:\n  image: registry.gitlab.com/franklin/base:latest\n  script:\n    - pixi install\n    - pixi run test-notebook\n\n\nGitHub Actions\n# .github/workflows/test.yml\nname: Test Exercise\non: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: |\n          pixi install\n          pixi run test-notebook"
  },
  {
    "objectID": "pages/edu_quick_reference.html#help-and-support",
    "href": "pages/edu_quick_reference.html#help-and-support",
    "title": "Franklin Commands",
    "section": "Help and Support",
    "text": "Help and Support\n# Get help\nfranklin --help                 # General help\nfranklin download --help        # Command-specific help\n\n# Version information\nfranklin --version\n\n# Submit issues\n# https://github.com/munch-group/franklin/issues\n\n# Documentation\n# https://munch-group.org/franklin"
  },
  {
    "objectID": "pages/developing.html",
    "href": "pages/developing.html",
    "title": "Developing exercises",
    "section": "",
    "text": "Under development\n\n\n\nThe content of this page is being developed.",
    "crumbs": [
      "Educator guides",
      "Developing exercises"
    ]
  },
  {
    "objectID": "pages/developing.html#the-exercise-repository",
    "href": "pages/developing.html#the-exercise-repository",
    "title": "Developing exercises",
    "section": "The exercise repository",
    "text": "The exercise repository\nA git repository is where an exercise lives\n\nexercise.ipynb:: blah blah\nDockerfile: blah blah\nREADME.md:: blah blah\ndocker-entrypoint.sh:: blah blah\ntagged-release.sh:: blah blah",
    "crumbs": [
      "Educator guides",
      "Developing exercises"
    ]
  },
  {
    "objectID": "pages/developing.html#developchange-a-new-exercise-on-gitlab",
    "href": "pages/developing.html#developchange-a-new-exercise-on-gitlab",
    "title": "Developing exercises",
    "section": "Develop/change a new exercise on GitLab",
    "text": "Develop/change a new exercise on GitLab\nTo begin an automated edit workflow, just run the command below and follow instructions carefully:\n\n\nTerminal\n\nfranklin exercise edit\n\nFor more information about edit workflows, see the tutorial about developing exercises.\n\nAssisted workflow\nThis workflow is temporarily disabled\n\n\nTerminal\n\nfranklin exercise down\n\n\n\nTerminal\n\nfranklin exercise up\n\n\n\nSupported workflow\nUse this command to clone the exercise repository:\n\n\nTerminal\n\nfranklin exercise clone\n\nThen open the repository. If is is called data-exercise, you can open it in vscode like this:\n\n\nTerminal\n\ncode data-exercise\n\n\nFor Mac users: On Macs, the code command line utility needs to be installed first. Launch vscode and open the Command Palette (Cmd+Shift+P), type ‘shell command’, select “Shell Command: Install ‘code’ command in PATH command” and hit Enter. Restart the terminal for the change to take effect.\n\nOnce open in vscode, click “Reopen in Container” if prompted, or otherwise use Cmd-Shift-P to open the command palette and type “reopen”, select “Reopen in Container” and hit Enter.\n\n\n\nalt text\n\n\nVscode now builds the container (which takes a while), and then reopens the exercise folder in the linux container dedicated to the exercise. You can use this to run/develop the jupyter notebook. Make sure you select the franklin jupyter kernel among the environments available. For an introduction to jupyter in vscode, see Using notebooks in vscode.\nIf you need to install and use third-party python packages (e.g. pandas), these packages must be added as dependencies to the docker image. To do this, open vscode’s terminal window and install pixi by running this command:\n./install_pixi.sh\nRunning the command below, will both make pandas available and add it as a dependency for the exercise.\n! pixi run test-notebook\n! pixi run add-dependency\n! pixi run collect-dependencies\npixi run add-dependency pandas\nAn alternative approach scan the notebook and add dependencies automatically.\npixi run collect-dependencies\nYou can test that the exercise notebook runs as configured using this command:\npixi run test-notebook\nTo add/commit/push you can use vscode’s git interface, gitui, or the git command line tool.\n\nGitUI: Git gui opens up a page with 4 section: unstaged changes, staged changed commit box and modified, not staged. Git gui can be used for version control, meaning if you an another educator is editing the same exercise at the same time, Git Gui can help you select which changes you want to keep, if you have editet the exact same assignment or it will allow you to merge both your changes into the new version of the assignment\n\n\n# ! /install_pixi.sh\n# %load_ext magic\n# %franklin pandas matplotlib",
    "crumbs": [
      "Educator guides",
      "Developing exercises"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html",
    "href": "pages/devel_quick_reference.html",
    "title": "Franklin Quick Reference",
    "section": "",
    "text": "Pixi (Recommended)CondaDevelopment\n\n\n# Install Pixi package manager\ncurl -fsSL https://pixi.sh/install.sh | bash  # macOS/Linux\niwr -useb https://pixi.sh/install.ps1 | iex   # Windows PowerShell\n\n# Students\npixi global install franklin --channel conda-forge --channel munch-group\n\n# Educators\npixi global install franklin franklin-educator --channel conda-forge --channel munch-group\n\n# Administrators\npixi global install franklin-admin --channel conda-forge --channel munch-group\n\n\n# Students\nconda install -c conda-forge -c munch-group franklin\n\n# Educators\nconda install -c conda-forge -c munch-group franklin franklin-educator\n\n# Administrators\nconda install -c conda-forge -c munch-group franklin-admin\n\n\n# Clone and install in development mode\ngit clone https://github.com/munch-group/franklin.git\ncd franklin\npip install -e .",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#installation",
    "href": "pages/devel_quick_reference.html#installation",
    "title": "Franklin Quick Reference",
    "section": "",
    "text": "Pixi (Recommended)CondaDevelopment\n\n\n# Install Pixi package manager\ncurl -fsSL https://pixi.sh/install.sh | bash  # macOS/Linux\niwr -useb https://pixi.sh/install.ps1 | iex   # Windows PowerShell\n\n# Students\npixi global install franklin --channel conda-forge --channel munch-group\n\n# Educators\npixi global install franklin franklin-educator --channel conda-forge --channel munch-group\n\n# Administrators\npixi global install franklin-admin --channel conda-forge --channel munch-group\n\n\n# Students\nconda install -c conda-forge -c munch-group franklin\n\n# Educators\nconda install -c conda-forge -c munch-group franklin franklin-educator\n\n# Administrators\nconda install -c conda-forge -c munch-group franklin-admin\n\n\n# Clone and install in development mode\ngit clone https://github.com/munch-group/franklin.git\ncd franklin\npip install -e .",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#core-commands-students",
    "href": "pages/devel_quick_reference.html#core-commands-students",
    "title": "Franklin Quick Reference",
    "section": "Core Commands (Students)",
    "text": "Core Commands (Students)\n\nBasic Operations\nfranklin --version              # Check version\nfranklin --help                 # Show help\nfranklin update                 # Update Franklin\n\n\nWorking with Exercises\nfranklin download               # Download exercise (interactive)\nfranklin jupyter                # Launch Jupyter for exercise\nfranklin list                   # List available exercises\nfranklin cleanup                # Remove old containers\n\n\nAdvanced Options\n# Download with options\nfranklin download \\\n  --course \"Data Science\" \\\n  --exercise \"Lab 1\" \\\n  --output ~/exercises\n\n# Launch Jupyter with resources\nfranklin jupyter \\\n  --memory 4g \\\n  --cpus 2 \\\n  --port 8889\n\n# Cleanup old containers\nfranklin cleanup --days 7       # Remove containers older than 7 days\nfranklin cleanup --all          # Remove all Franklin containers",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#educator-commands",
    "href": "pages/devel_quick_reference.html#educator-commands",
    "title": "Franklin Quick Reference",
    "section": "Educator Commands",
    "text": "Educator Commands\n\nExercise Management\nfranklin exercise new           # Create new exercise\nfranklin exercise edit          # Edit existing exercise\nfranklin exercise list          # List your exercises\nfranklin exercise publish       # Publish to students\nfranklin exercise test          # Test exercise locally\n\n\nExercise Development Workflow\n# 1. Create new exercise\nfranklin exercise new\n&gt; Course: Introduction to Python\n&gt; Exercise: Variables and Types\n&gt; Template: default\n\n# 2. Edit exercise\ncd \"Variables and Types\"\njupyter lab exercise.ipynb\n\n# 3. Test locally\npixi run test-notebook\n\n# 4. Publish for students\nfranklin exercise publish\n\n\nGit Integration\nfranklin exercise clone &lt;url&gt;   # Clone exercise repository\nfranklin exercise push          # Push changes to GitLab\nfranklin exercise pull          # Pull latest changes\nfranklin exercise status        # Check git status",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#administrator-commands",
    "href": "pages/devel_quick_reference.html#administrator-commands",
    "title": "Franklin Quick Reference",
    "section": "Administrator Commands",
    "text": "Administrator Commands\n\nUser Management\nfranklin finger &lt;username&gt;      # Get user information\nfranklin grant &lt;role&gt; &lt;user&gt;    # Grant role to user\nfranklin token create &lt;user&gt;    # Create API token\nfranklin password set &lt;user&gt;    # Set user password\n\n\nRoles and Permissions\n# Available roles\nfranklin grant student &lt;username&gt;\nfranklin grant ta &lt;username&gt;          # Teaching assistant\nfranklin grant educator &lt;username&gt;\nfranklin grant admin &lt;username&gt;\n\n# Bulk operations\nfranklin grant student --file students.txt\nfranklin grant educator --course \"CS101\" &lt;username&gt;",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#jupyter-magic-commands",
    "href": "pages/devel_quick_reference.html#jupyter-magic-commands",
    "title": "Franklin Quick Reference",
    "section": "Jupyter Magic Commands",
    "text": "Jupyter Magic Commands\nInside Jupyter notebooks:\n# Load Franklin magic\n%load_ext magic\n\n# Install packages\n%franklin numpy pandas matplotlib\n%pixi_install scikit-learn tensorflow\n\n# Install specific versions\n%franklin numpy==1.24.0 pandas&gt;=2.0\n\n# Install from different channels\n%franklin -c pytorch pytorch torchvision",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#docker-commands",
    "href": "pages/devel_quick_reference.html#docker-commands",
    "title": "Franklin Quick Reference",
    "section": "Docker Commands",
    "text": "Docker Commands\n\nContainer Management\n# List Franklin containers\ndocker ps -a | grep franklin\n\n# Stop all Franklin containers\ndocker stop $(docker ps -q --filter \"label=franklin\")\n\n# Remove Franklin containers\ndocker rm $(docker ps -aq --filter \"label=franklin\")\n\n# Access container shell\nfranklin shell                  # Interactive shell in container\nfranklin shell --exercise \"Lab1\"\n\n\nImage Management\n# List Franklin images\ndocker images | grep franklin\n\n# Pull latest base image\ndocker pull registry.gitlab.com/franklin/base:latest\n\n# Remove unused images\ndocker image prune",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#configuration",
    "href": "pages/devel_quick_reference.html#configuration",
    "title": "Franklin Quick Reference",
    "section": "Configuration",
    "text": "Configuration\n\nSettings File\n# Location: ~/.franklin/settings.json\n{\n  \"default_course\": \"Data Science\",\n  \"jupyter_port\": 8888,\n  \"auto_update\": true,\n  \"max_containers\": 5,\n  \"default_memory\": \"4g\",\n  \"default_cpus\": 2\n}\n\n\nEnvironment Variables\n# Debug mode\nexport FRANKLIN_DEBUG=1\n\n# Custom config location\nexport FRANKLIN_CONFIG=/path/to/config.json\n\n# GitLab settings\nexport GITLAB_URL=https://gitlab.example.com\nexport GITLAB_TOKEN=your-token\n\n# Docker settings\nexport DOCKER_HOST=tcp://localhost:2375",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#file-locations",
    "href": "pages/devel_quick_reference.html#file-locations",
    "title": "Franklin Quick Reference",
    "section": "File Locations",
    "text": "File Locations\n\nDefault Paths\n# Configuration\n~/.franklin/config.json         # User configuration\n~/.franklin/settings.json       # User settings\n~/.franklin/cache/              # Downloaded exercises cache\n\n# Exercises\n~/franklin-exercises/           # Default exercise directory\n~/Desktop/                      # Alternative on Windows\n\n# Logs\n~/.franklin/logs/               # Franklin logs\n~/.franklin/crash-reports/      # Crash reports\n\n\nExercise Structure\nexercise-name/\n├── Dockerfile                  # Container configuration\n├── pixi.toml                  # Dependencies\n├── exercise.ipynb             # Main notebook\n├── README.md                  # Instructions\n├── data/                      # Data files\n├── tests/                     # Test files\n└── .gitlab-ci.yml            # CI/CD pipeline",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#pixi-commands",
    "href": "pages/devel_quick_reference.html#pixi-commands",
    "title": "Franklin Quick Reference",
    "section": "Pixi Commands",
    "text": "Pixi Commands\n\nIn Exercise Directory\npixi install                    # Install dependencies\npixi add numpy                  # Add package\npixi remove pandas              # Remove package\npixi list                       # List installed packages\npixi run test-notebook          # Run tests\npixi shell                      # Activate environment\n\n\nGlobal Pixi\npixi global install jupyter     # Install globally\npixi global list               # List global packages\npixi global update             # Update all packages",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#git-commands-for-exercises",
    "href": "pages/devel_quick_reference.html#git-commands-for-exercises",
    "title": "Franklin Quick Reference",
    "section": "Git Commands for Exercises",
    "text": "Git Commands for Exercises\n# Check status\ngit status\n\n# Save your work\ngit add -A\ngit commit -m \"Complete exercise 1\"\n\n# Create your own repository\ngit remote add personal https://github.com/you/solutions\ngit push personal main\n\n# Get updates\ngit pull origin main\n\n# View history\ngit log --oneline",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#troubleshooting-commands",
    "href": "pages/devel_quick_reference.html#troubleshooting-commands",
    "title": "Franklin Quick Reference",
    "section": "Troubleshooting Commands",
    "text": "Troubleshooting Commands\n\nDiagnostic Commands\nfranklin doctor                 # System diagnostics\nfranklin doctor --verbose       # Detailed diagnostics\n\n# Check components\ndocker --version\ngit --version\npython --version\npixi --version\n\n\nReset and Repair\n# Reset Franklin configuration\nfranklin reset --config\n\n# Clear cache\nfranklin cache clear\n\n# Reinstall Franklin\nconda remove franklin\nconda install -c conda-forge -c munch-group franklin\n\n# Fix permissions (Linux/Mac)\nsudo chown -R $USER:$USER ~/.franklin\n\n\nLogs and Debugging\n# View logs\nfranklin logs                   # Recent logs\nfranklin logs --tail 50         # Last 50 lines\nfranklin logs --follow          # Follow log output\n\n# Debug mode\nFRANKLIN_DEBUG=1 franklin download\n\n# Verbose output\nfranklin --verbose jupyter",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#keyboard-shortcuts",
    "href": "pages/devel_quick_reference.html#keyboard-shortcuts",
    "title": "Franklin Quick Reference",
    "section": "Keyboard Shortcuts",
    "text": "Keyboard Shortcuts\n\nJupyterLab\nShift+Enter    Run cell and move to next\nCtrl+Enter     Run cell\nAlt+Enter      Run cell and insert below\nEsc           Command mode\nEnter         Edit mode\nA             Insert cell above\nB             Insert cell below\nDD            Delete cell\nZ             Undo cell deletion\nCtrl+S        Save notebook\n\n\nTerminal (During Franklin Prompts)\n↑/↓           Navigate options\nEnter         Select option\nCtrl+C        Cancel operation\nTab           Auto-complete\nCtrl+L        Clear screen",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#common-workflows",
    "href": "pages/devel_quick_reference.html#common-workflows",
    "title": "Franklin Quick Reference",
    "section": "Common Workflows",
    "text": "Common Workflows\n\nStudent Workflow\n# 1. Download exercise\nfranklin download\n\n# 2. Work on exercise\nfranklin jupyter\n\n# 3. Save and submit\n# (Work is auto-saved in exercise folder)\n\n\nEducator Workflow\n# 1. Create exercise\nfranklin exercise new\n\n# 2. Develop and test\ncd exercise-folder\njupyter lab\npixi run test-notebook\n\n# 3. Publish\nfranklin exercise publish\n\n\nAdministrator Workflow\n# 1. Setup course\nfranklin grant educator prof@university.edu\nfranklin grant ta assistant@university.edu\n\n# 2. Add students\nfranklin grant student --file roster.csv\n\n# 3. Monitor usage\nfranklin stats --course \"CS101\"",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#package-management",
    "href": "pages/devel_quick_reference.html#package-management",
    "title": "Franklin Quick Reference",
    "section": "Package Management",
    "text": "Package Management\n\nAdding Dependencies to Exercise\n# In exercise directory\npixi add numpy pandas           # Add to pixi.toml\n\n# Or in notebook\n%franklin numpy pandas\n\n# For specific versions\npixi add \"numpy&gt;=1.24,&lt;2.0\"\n\n\nCreating Requirements File\n# Export from pixi\npixi list --export &gt; requirements.txt\n\n# Export from conda\nconda env export &gt; environment.yml",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#cicd-integration",
    "href": "pages/devel_quick_reference.html#cicd-integration",
    "title": "Franklin Quick Reference",
    "section": "CI/CD Integration",
    "text": "CI/CD Integration\n\nGitLab CI\n# .gitlab-ci.yml in exercise\ntest:\n  image: registry.gitlab.com/franklin/base:latest\n  script:\n    - pixi install\n    - pixi run test-notebook\n\n\nGitHub Actions\n# .github/workflows/test.yml\nname: Test Exercise\non: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: |\n          pixi install\n          pixi run test-notebook",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/devel_quick_reference.html#help-and-support",
    "href": "pages/devel_quick_reference.html#help-and-support",
    "title": "Franklin Quick Reference",
    "section": "Help and Support",
    "text": "Help and Support\n# Get help\nfranklin --help                 # General help\nfranklin download --help        # Command-specific help\n\n# Version information\nfranklin --version\n\n# Submit issues\n# https://github.com/munch-group/franklin/issues\n\n# Documentation\n# https://munch-group.org/franklin",
    "crumbs": [
      "Developer Resources",
      "Franklin Quick Reference"
    ]
  },
  {
    "objectID": "pages/commands_core.html",
    "href": "pages/commands_core.html",
    "title": "Main Commands",
    "section": "",
    "text": "Franklin is a command-line tool that manages Jupyter notebook exercises through Docker containers.",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/commands_core.html#overview",
    "href": "pages/commands_core.html#overview",
    "title": "Main Commands",
    "section": "Overview",
    "text": "Overview\nFranklin uses a hierarchical command structure:\nfranklin [GLOBAL OPTIONS] COMMAND [COMMAND OPTIONS] [ARGUMENTS]\nGlobal options: - --version shows the installed Franklin version and exits - --help shows help message for Franklin or any subcommand\nExample:\nfranklin --help            # Show main help\nfranklin download --help   # Show download command help",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/commands_core.html#exercise-commands",
    "href": "pages/commands_core.html#exercise-commands",
    "title": "Main Commands",
    "section": "Exercise Commands",
    "text": "Exercise Commands\n\nDownload an exercise\nThis command downloads an exercise repository to your computer.\nfranklin download\n\nThis happensTips\n\n\n\nYou are prompted to select your course\nYou are prompted to select the exercise to download\n\nFranklin downloads the exercise to a subfolder of your current folder\nInstructor-only files (solutions, etc.) are removed\n\n\n\n\nRun from an empty folder or a dedicated exercises directory\nCreate one folder per course to keep exercises organized\nThe exercise will be downloaded into a new subfolder named after the exercise\n\n\n\n\n\n\nTechnical details of the process\n\n\nRegistry Discovery: Queries GitLab API for available courses in the Franklin group\nImage Matching: Matches Docker images in the registry to exercise repositories\nPermission Check: Verifies user has access to selected repository\nRepository Clone: Uses git to clone the exercise repository\nCleanup: Removes .git folder, solution files, and instructor notes\nValidation: Ensures exercise contains required files (Dockerfile, notebook, etc.)\n\n\n\nThis happensTips\n\n\n\nFranklin validates the URL format\nChecks your access permissions\nDownloads the exercise to a subfolder of your current folder\n\n\n\n\nGet the URL from your course page or instructor\nThe URL must be a GitLab repository URL\nYou need access rights to the repository\n\n\n\n\n\n\nLaunch Jupyter\nThis command launches JupyterLab in a Docker container configured for the current exercise.\nfranklin jupyter\n\nThis happensTips\n\n\n\nDetects exercise in current folder (or prompts for selection)\nPulls Docker image with exercise dependencies if needed\nStarts container and mounts current folder\nOpens JupyterLab in your browser\nWaits for you to close the browser\nCleans up the container\n\n\n\n\nRun from inside the exercise folder for automatic detection\nFranklin finds an available port starting from 8888\nKeep Docker Desktop running during work sessions\nYour work is saved in the exercise folder, not the container\n\n\n\n\n\n\nTechnical details of the process\n\n\nDocker Check: Ensures Docker Desktop is installed and running\nDisk Space: Verifies at least 5GB free space\nImage Pull: Downloads Docker image if not cached locally\nContainer Start: Launches container with current directory mounted at /home/jovyan/work\nPort Management: Finds available port starting from 8888\nBrowser Launch: Opens Chrome/default browser with authentication token\nCleanup: Stops container when browser closes\n\n\n\nThis happensTips\n\n\n\nPulls the specified Docker image\nStarts container with current folder mounted\nOpens JupyterLab in browser\n\n\n\n\nUse when you know the exact image you need\nUseful for testing or special configurations\nThe image URL is shown in exercise documentation",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/commands_core.html#updating-franklin",
    "href": "pages/commands_core.html#updating-franklin",
    "title": "Main Commands",
    "section": "Updating Franklin",
    "text": "Updating Franklin\nThis command updates Franklin to the latest version.\nfranklin update\n\nThis happensTips\n\n\n\nDetects how Franklin was installed (Conda, Pixi, or pip)\nChecks for available updates\nUpdates Franklin and any installed plugins\nRestarts Franklin if updated\n\n\n\n\nFranklin checks for updates automatically when started\nUpdates are cached for 6 hours to avoid repeated checks\nUpdate before each semester for the latest features\nThe update includes franklin-educator and franklin-admin if installed\n\n\n\n\n\n\nTechnical details of the process\n\n\nInstallation Detection: Checks Python executable path for conda/pixi markers\nVersion Query: Fetches latest version from package repository\nPackage Manager: Uses appropriate command (conda update, pixi update, or pip install –upgrade)\nPlugin Updates: Also updates franklin-educator and franklin-admin if installed\nCache Management: Updates are cached to avoid repeated version checks\n\n\n\nCheck for updates\nCheck for updates without installing them.\nfranklin update --check\n\nThis happensTips\n\n\n\nQueries the package repository for latest version\nCompares with your installed version\nReports if an update is available\n\n\n\n\nUse to see if updates are available before installing\nNo changes are made to your system\nShows version numbers for comparison\n\n\n\n\n\n\nForce update\nForce a reinstall even if already up-to-date.\nfranklin update --force\n\nThis happensTips\n\n\n\nReinstalls Franklin regardless of version\nUseful for fixing corrupted installations\nAlso reinstalls plugins if present\n\n\n\n\nUse when Franklin is behaving strangely\nFixes most installation-related issues\nTakes longer than a regular update",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/commands_core.html#docker-resources",
    "href": "pages/commands_core.html#docker-resources",
    "title": "Main Commands",
    "section": "Docker resources",
    "text": "Docker resources\n\nShow images\nList all Docker images on your system.\nfranklin show images\n\nThis happensTips\n\n\n\nQueries Docker for all images\nDisplays them in a formatted table\nShows repository, tag, ID, and size\n\n\n\n\nUse before cleanup to see what’s installed\nLarge images (&gt;2GB) are exercise environments\nSmall images (&lt;1GB) are usually base images\n\n\n\n\n\n\nShow containers\nList all Docker containers (running and stopped).\nfranklin show containers\n\nThis happensTips\n\n\n\nQueries Docker for all containers\nShows both running and stopped containers\nDisplays ID, image, status, and ports\n\n\n\n\nRunning containers show “Up” status\nStopped containers show “Exited” status\nUse to check if Jupyter is still running\n\n\n\n\n\n\nShow storage\nDisplay Docker disk usage summary.\nfranklin show storage\n\nThis happensTips\n\n\n\nCalculates space used by images\nCalculates space used by containers\nShows total and reclaimable space\n\n\n\n\nUse before and after cleanup to see space saved\nCheck when Docker seems slow\nLarge build cache can often be cleared safely",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/commands_core.html#manage-docker-disk-usage",
    "href": "pages/commands_core.html#manage-docker-disk-usage",
    "title": "Main Commands",
    "section": "Manage Docker Disk Usage",
    "text": "Manage Docker Disk Usage\n\nClean up Docker images\nThis command removes Docker images and containers to free disk space.\nfranklin cleanup\n\nThis happensTips\n\n\n\nLists all Franklin-related Docker images\nShows size of each image\nLets you select which to remove (y/n for each)\nRemoves selected images\nShows total space freed\n\n\n\n\nImages can be re-downloaded when needed\nYour exercise files are never deleted\nRun weekly to keep disk usage under control\nConsider removing old course images at semester end\n\n\n\n\n\n\nTechnical details of the process\n\n\nImage Discovery: Lists all Docker images matching Franklin patterns\nContainer Check: Identifies stopped containers from those images\nSpace Calculation: Computes disk space for each image\nSafe Removal: Only removes images not currently in use\nCache Pruning: Optionally runs docker system prune for additional cleanup",
    "crumbs": [
      "Franklin commands",
      "Main Commands"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html",
    "href": "pages/automatic_updates.html",
    "title": "Automatic Updates",
    "section": "",
    "text": "Franklin is designed to automatically stay up-to-date, ensuring all users have the latest features and bug fixes without manual intervention. This page explains how automatic updates work with both Pixi and Conda installation methods.",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#overview",
    "href": "pages/automatic_updates.html#overview",
    "title": "Automatic Updates",
    "section": "",
    "text": "Franklin is designed to automatically stay up-to-date, ensuring all users have the latest features and bug fixes without manual intervention. This page explains how automatic updates work with both Pixi and Conda installation methods.",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#update-mechanisms",
    "href": "pages/automatic_updates.html#update-mechanisms",
    "title": "Automatic Updates",
    "section": "Update Mechanisms",
    "text": "Update Mechanisms\n\nPixi Global Packages\nWhen installed with pixi global install, Franklin benefits from Pixi’s automatic update features:\n# Initial installation\npixi global install franklin --channel conda-forge --channel munch-group\nAutomatic Update Process:\n\nGlobal Sync: Pixi periodically checks for updates to global packages\nVersion Resolution: Automatically resolves to the latest compatible version\nBackground Updates: Updates happen transparently when you run Franklin commands\nNo User Intervention: Updates are applied without requiring manual commands\n\nManual Update Check:\n# Force immediate update check\npixi global update franklin\n\n# Update all global packages\npixi global update --all\n\n\nConda Environment Updates\nWhen installed with conda, Franklin uses conda’s update mechanism:\n# Initial installation\nconda install -c conda-forge -c munch-group franklin\nUpdate Process:\n\nSolver-based Updates: Conda’s solver finds the latest compatible version\nChannel Priority: Updates come from the specified channels in priority order\nEnvironment Isolation: Updates are contained within the conda environment\n\nManual Update:\n# Update Franklin\nconda update -c conda-forge -c munch-group franklin\n\n# Update all packages in environment\nconda update --all",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#version-pinning-and-control",
    "href": "pages/automatic_updates.html#version-pinning-and-control",
    "title": "Automatic Updates",
    "section": "Version Pinning and Control",
    "text": "Version Pinning and Control\n\nPreventing Automatic Updates\nIf you need to lock to a specific version:\n\nWith Pixi:\n# Install specific version\npixi global install franklin==0.24.165 --channel conda-forge --channel munch-group\n\n# Pin version in project\necho \"franklin==0.24.165\" &gt;&gt; pixi.toml\n\n\nWith Conda:\n# Install specific version\nconda install franklin=0.24.165\n\n# Pin version\necho \"franklin==0.24.165\" &gt;&gt; $CONDA_PREFIX/conda-meta/pinned\n\n\n\nChecking Current Version\n# Check installed version\nfranklin --version\n\n# Check available versions (pixi)\npixi search franklin --channel munch-group\n\n# Check available versions (conda)\nconda search franklin -c munch-group",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#update-channels",
    "href": "pages/automatic_updates.html#update-channels",
    "title": "Automatic Updates",
    "section": "Update Channels",
    "text": "Update Channels\nFranklin releases follow this pattern:\n\nDevelopment: Nightly builds (not for production)\nBeta: Release candidates for testing\nStable: Production-ready releases (default)\n\n\nSubscribing to Different Channels\n# Stable (default)\npixi global install franklin --channel conda-forge --channel munch-group\n\n# Beta channel\npixi global install franklin --channel conda-forge --channel munch-group/label/beta\n\n# Development builds\npixi global install franklin --channel conda-forge --channel munch-group/label/dev",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#update-notifications",
    "href": "pages/automatic_updates.html#update-notifications",
    "title": "Automatic Updates",
    "section": "Update Notifications",
    "text": "Update Notifications\nFranklin checks for updates on startup and notifies you when a new version is available:\n╭────────────────────────────────────────────────╮\n│  A new version of Franklin is available!       │\n│  Current: 0.24.165 → Available: 0.24.166      │\n│  Run 'pixi global update franklin' to update   │\n╰────────────────────────────────────────────────╯\n\nConfiguring Update Checks\n# Disable update notifications\nfranklin config set updates.check false\n\n# Change update check frequency (hours)\nfranklin config set updates.check_interval 24\n\n# Disable automatic updates (pixi only)\nfranklin config set updates.auto_update false",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#plugin-updates",
    "href": "pages/automatic_updates.html#plugin-updates",
    "title": "Automatic Updates",
    "section": "Plugin Updates",
    "text": "Plugin Updates\nEducator and admin plugins update alongside the main Franklin package:\n# Update all Franklin components\npixi global update franklin franklin-educator franklin-admin\n\n# Check plugin versions\nfranklin --version\nfranklin exercise --version  # Educator plugin\nfranklin admin --version     # Admin plugin",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#rollback-procedures",
    "href": "pages/automatic_updates.html#rollback-procedures",
    "title": "Automatic Updates",
    "section": "Rollback Procedures",
    "text": "Rollback Procedures\nIf an update causes issues, you can rollback to a previous version:\n\nWith Pixi:\n# View update history\npixi global list --show-versions\n\n# Rollback to specific version\npixi global install franklin==0.24.164 --channel conda-forge --channel munch-group\n\n\nWith Conda:\n# View revision history\nconda list --revisions\n\n# Rollback to previous revision\nconda install --revision 2\n\n# Or install specific version\nconda install franklin=0.24.164",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#container-image-updates",
    "href": "pages/automatic_updates.html#container-image-updates",
    "title": "Automatic Updates",
    "section": "Container Image Updates",
    "text": "Container Image Updates\nFranklin also manages Docker container updates for exercises:\n# Pull latest base images\nfranklin docker pull --latest\n\n# Update exercise containers\nfranklin docker update --all\n\n# Clean old images\nfranklin docker prune --days 30",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#best-practices",
    "href": "pages/automatic_updates.html#best-practices",
    "title": "Automatic Updates",
    "section": "Best Practices",
    "text": "Best Practices\n\n\n\n\n\n\nUpdate Recommendations\n\n\n\n\nRegular Users: Let automatic updates run (default behavior)\nDuring Semester: Consider pinning version for stability\nBetween Semesters: Update to latest version for new features\nTesting: Use beta channel in non-production environments\nProduction: Always test updates in staging first",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#troubleshooting-updates",
    "href": "pages/automatic_updates.html#troubleshooting-updates",
    "title": "Automatic Updates",
    "section": "Troubleshooting Updates",
    "text": "Troubleshooting Updates\n\nUpdate Fails\n# Clear package cache\npixi cache clean\n# or\nconda clean --all\n\n# Force reinstall\npixi global uninstall franklin\npixi global install franklin --channel conda-forge --channel munch-group\n\n\nVersion Conflicts\n# Check dependencies\npixi info franklin\n# or\nconda info franklin\n\n# Resolve conflicts\npixi global update --force\n# or\nconda update --force-reinstall franklin\n\n\nNetwork Issues\n# Use offline mode if packages are cached\nfranklin --offline\n\n# Configure proxy for updates\nexport HTTP_PROXY=http://proxy.company.com:8080\nexport HTTPS_PROXY=http://proxy.company.com:8080",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#security-updates",
    "href": "pages/automatic_updates.html#security-updates",
    "title": "Automatic Updates",
    "section": "Security Updates",
    "text": "Security Updates\nCritical security updates are:\n\nAutomatically Applied: Within 24 hours of release\nLogged: Update history is maintained\nNotified: Administrators receive security notifications\nTested: Updates go through automated testing before release\n\n\nSecurity Update Policy\n# Check security status\nfranklin security status\n\n# View security updates\nfranklin security updates --list\n\n# Apply security updates immediately\nfranklin security update --now",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "pages/automatic_updates.html#summary",
    "href": "pages/automatic_updates.html#summary",
    "title": "Automatic Updates",
    "section": "Summary",
    "text": "Summary\nFranklin’s automatic update system ensures:\n\nConsistency: All users run the same version\nSecurity: Critical fixes are applied quickly\nReliability: Updates are tested before release\nFlexibility: Manual control when needed\nTransparency: Clear notifications and logs\n\nThe combination of Pixi’s modern package management and Franklin’s update checks provides a robust, automatic update system that keeps the platform current without disrupting users’ work.",
    "crumbs": [
      "Administration",
      "Automatic Updates"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Franklin",
    "section": "",
    "text": "No Setup Frustration: Students focus on learning, not troubleshooting. Franklin handles all environment setup, dependency management, and platform differences automatically.\n\n\n No Platform Issues: Same experience on Windows, Mac, and Linux. No more “it worked on my machine” problems for educators. Every student sees identical comparable results.\n\n\n Student Empowering: Acquired skills not limited to some cloud-based learning environment. Franklin opens JupyterLab in your own browser, uses your own CPU to run notebooks in your own folders.\n\n\n Smart Dependencies: Automatic dependency detection from notebook imports. Uses Pixi, a fast package manager that ensures reproducible environments across platforms.\n\n\n Batteries included: Multilayered design supports educators at any skill levels. Example notebooks provide plug an play notebook templates for developing exercises.\n\n\n Auto Updates: Franklin and its plugins update automatically. Bug fixes and improvements reach all students instantly. No more manual intervention or repeated trouble shooting.\n\n\n Container Isolation: Each exercise is developed and run in its own Docker container. No conflicts between courses or exercises, no pollution of system Python, complete isolation.\n\n\n Automatic error reports: Should Franklin crash, it submits a fully documented GitHub issue, unless the same issue is already submitted. No more troubleshooting with students.\n\n\n Backed by Git: Uses institution GitLab server for hosting exercise repositories grouped by course. Uses GitLab pipelines to automate building and hosting of Docker images.\n\n\n\n\n\nGet Started Or Get Help\n\n Documentation - Comprehensive guides\n Issue Tracker - Report bugs\n Contact - Direct support\n\n\n\nContribute\n\n Developer Guide - Start contributing\n GitHub - Star the project\n Plugins - Extend Franklin"
  },
  {
    "objectID": "api/pull.html",
    "href": "api/pull.html",
    "title": "pull",
    "section": "",
    "text": "franklin.docker.pull(image_url)\nPull Docker image.\n\n\n\nimage_url : str\n\nImage URL.",
    "crumbs": [
      "Docker",
      "pull"
    ]
  },
  {
    "objectID": "api/pull.html#parameters",
    "href": "api/pull.html#parameters",
    "title": "pull",
    "section": "",
    "text": "image_url : str\n\nImage URL.",
    "crumbs": [
      "Docker",
      "pull"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Some description…\n\n\n\n_run\n\n\n\n\n\n\n\nSome description…\n\n\n\nrun\nRuns a container from an image.\n\n\npull\nPull Docker image.",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#jupyter",
    "href": "api/index.html#jupyter",
    "title": "Function reference",
    "section": "",
    "text": "Some description…\n\n\n\n_run",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#docker",
    "href": "api/index.html#docker",
    "title": "Function reference",
    "section": "",
    "text": "Some description…\n\n\n\nrun\nRuns a container from an image.\n\n\npull\nPull Docker image.",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "ADDING CODE EXPLANATIONS JUPYTER NOTEBOOKS",
    "section": "",
    "text": "Add a markdown cell after each code cell with an explanation the code. The explanation should be formatted as a Markdown list wrapped in a html detail tag\n\n## Code cell \n\n\n::: {#1b6f3b4c .cell execution_count=1}\n``` {.python .cell-code}\nx = \"hello\"\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhello\n```\n:::\n:::\n\n\n## Markdown cell \n\n&lt;details&gt;\n&lt;summary&gt;&lt;small&gt;Click to see what Franklin does&lt;/small&gt;&lt;/summary&gt;\n\n- First `x` is assigned the value `\"hello\"`\n- Then the `print` function prints the value that the `x` value points to (`\"hello\"`).\n\n&lt;/details&gt;\n\n\nTemplate for simple documentation Click command\n\n### Download an exercise\n\nThis command downloads an exercise repository to your computer.\n\n```bash\nfranklin download\n```\n\n::: {.panel-tabset}\n\n# This happens\n\n1. You are prompted to select your course\n2. You are prompted to select the exercise to download  \n3. Franklin downloads the exercise to a subfolder of your current folder\n4. Instructor-only files (solutions, etc.) are removed\n\n# Tips  \n\n- Run from an empty folder or a dedicated exercises directory\n- Create one folder per course to keep exercises organized\n- The exercise will be downloaded into a new subfolder named after the exercise\n\n:::\n\n&lt;details&gt;\n&lt;summary&gt;Technical details of the process&lt;/summary&gt;\n\n1. **Registry Discovery**: Queries GitLab API for available courses in the Franklin group\n2. **Image Matching**: Matches Docker images in the registry to exercise repositories\n3. **Permission Check**: Verifies user has access to selected repository\n4. **Repository Clone**: Uses git to clone the exercise repository\n5. **Cleanup**: Removes `.git` folder, solution files, and instructor notes\n6. **Validation**: Ensures exercise contains required files (Dockerfile, notebook, etc.)\n\n&lt;/details&gt;\n\n\n\nTemplate for full documentation of Click command\nFormat like Click command documentation but ducument ALL features"
  },
  {
    "objectID": "api/launch_exercise.html",
    "href": "api/launch_exercise.html",
    "title": "launch_exercise",
    "section": "",
    "text": "launch_exercise\nfranklin.jupyter.launch_exercise()"
  },
  {
    "objectID": "api/run.html",
    "href": "api/run.html",
    "title": "run",
    "section": "",
    "text": "franklin.docker.run(image_url)\nRuns a container from an image.\n\n\n\nimage_url : str\n\nImage URL.\n\n\n\n\n\n\n : Tuple[Popen, str]\n\nTuple of subprocess handle for ‘docker run’ and host port used for jupyter display.",
    "crumbs": [
      "Docker",
      "run"
    ]
  },
  {
    "objectID": "api/run.html#parameters",
    "href": "api/run.html#parameters",
    "title": "run",
    "section": "",
    "text": "image_url : str\n\nImage URL.",
    "crumbs": [
      "Docker",
      "run"
    ]
  },
  {
    "objectID": "api/run.html#returns",
    "href": "api/run.html#returns",
    "title": "run",
    "section": "",
    "text": ": Tuple[Popen, str]\n\nTuple of subprocess handle for ‘docker run’ and host port used for jupyter display.",
    "crumbs": [
      "Docker",
      "run"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html",
    "href": "pages/admin_quick_reference.html",
    "title": "Quick Reference",
    "section": "",
    "text": "franklin --version              # Check version\nfranklin --help                 # Show help\nfranklin update                 # Update Franklin\n\n\n\nfranklin download               # Download exercise (interactive)\nfranklin jupyter                # Launch Jupyter for exercise\nfranklin list                   # List available exercises\nfranklin cleanup                # Remove old containers",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#core-commands-students",
    "href": "pages/admin_quick_reference.html#core-commands-students",
    "title": "Quick Reference",
    "section": "",
    "text": "franklin --version              # Check version\nfranklin --help                 # Show help\nfranklin update                 # Update Franklin\n\n\n\nfranklin download               # Download exercise (interactive)\nfranklin jupyter                # Launch Jupyter for exercise\nfranklin list                   # List available exercises\nfranklin cleanup                # Remove old containers",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#educator-commands",
    "href": "pages/admin_quick_reference.html#educator-commands",
    "title": "Quick Reference",
    "section": "Educator Commands",
    "text": "Educator Commands\n\nExercise Management\nfranklin exercise new           # Create new exercise\nfranklin exercise edit          # Edit existing exercise\nfranklin exercise list          # List your exercises\nfranklin exercise publish       # Publish to students\nfranklin exercise test          # Test exercise locally\n\n\nExercise Development Workflow\n# 1. Create new exercise\nfranklin exercise new\n&gt; Course: Introduction to Python\n&gt; Exercise: Variables and Types\n&gt; Template: default\n\n# 2. Edit exercise\ncd \"Variables and Types\"\njupyter lab exercise.ipynb\n\n# 3. Test locally\npixi run test-notebook\n\n# 4. Publish for students\nfranklin exercise publish\n\n\nGit Integration\nfranklin exercise clone &lt;url&gt;   # Clone exercise repository\nfranklin exercise push          # Push changes to GitLab\nfranklin exercise pull          # Pull latest changes\nfranklin exercise status        # Check git status",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#administrator-commands",
    "href": "pages/admin_quick_reference.html#administrator-commands",
    "title": "Quick Reference",
    "section": "Administrator Commands",
    "text": "Administrator Commands\n\nUser Management\nfranklin finger &lt;username&gt;      # Get user information\nfranklin grant &lt;role&gt; &lt;user&gt;    # Grant role to user\nfranklin token create &lt;user&gt;    # Create API token\nfranklin password set &lt;user&gt;    # Set user password\n\n\nRoles and Permissions\n# Available roles\nfranklin grant student &lt;username&gt;\nfranklin grant ta &lt;username&gt;          # Teaching assistant\nfranklin grant educator &lt;username&gt;\nfranklin grant admin &lt;username&gt;\n\n# Bulk operations\nfranklin grant student --file students.txt\nfranklin grant educator --course \"CS101\" &lt;username&gt;",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#jupyter-magic-commands",
    "href": "pages/admin_quick_reference.html#jupyter-magic-commands",
    "title": "Quick Reference",
    "section": "Jupyter Magic Commands",
    "text": "Jupyter Magic Commands\nInside Jupyter notebooks:\n# Load Franklin magic\n%load_ext magic\n\n# Install packages\n%franklin numpy pandas matplotlib\n%pixi_install scikit-learn tensorflow\n\n# Install specific versions\n%franklin numpy==1.24.0 pandas&gt;=2.0\n\n# Install from different channels\n%franklin -c pytorch pytorch torchvision",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#docker-commands",
    "href": "pages/admin_quick_reference.html#docker-commands",
    "title": "Quick Reference",
    "section": "Docker Commands",
    "text": "Docker Commands\n\nContainer Management\n# List Franklin containers\ndocker ps -a | grep franklin\n\n# Stop all Franklin containers\ndocker stop $(docker ps -q --filter \"label=franklin\")\n\n# Remove Franklin containers\ndocker rm $(docker ps -aq --filter \"label=franklin\")\n\n# Access container shell\nfranklin shell                  # Interactive shell in container\nfranklin shell --exercise \"Lab1\"\n\n\nImage Management\n# List Franklin images\ndocker images | grep franklin\n\n# Pull latest base image\ndocker pull registry.gitlab.com/franklin/base:latest\n\n# Remove unused images\ndocker image prune",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#configuration",
    "href": "pages/admin_quick_reference.html#configuration",
    "title": "Quick Reference",
    "section": "Configuration",
    "text": "Configuration\n\nSettings File\n# Location: ~/.franklin/settings.json\n{\n  \"default_course\": \"Data Science\",\n  \"jupyter_port\": 8888,\n  \"auto_update\": true,\n  \"max_containers\": 5,\n  \"default_memory\": \"4g\",\n  \"default_cpus\": 2\n}\n\n\nEnvironment Variables\n# Debug mode\nexport FRANKLIN_DEBUG=1\n\n# Custom config location\nexport FRANKLIN_CONFIG=/path/to/config.json\n\n# GitLab settings\nexport GITLAB_URL=https://gitlab.example.com\nexport GITLAB_TOKEN=your-token\n\n# Docker settings\nexport DOCKER_HOST=tcp://localhost:2375",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#file-locations",
    "href": "pages/admin_quick_reference.html#file-locations",
    "title": "Quick Reference",
    "section": "File Locations",
    "text": "File Locations\n\nDefault Paths\n# Configuration\n~/.franklin/config.json         # User configuration\n~/.franklin/settings.json       # User settings\n~/.franklin/cache/              # Downloaded exercises cache\n\n# Exercises\n~/franklin-exercises/           # Default exercise directory\n~/Desktop/                      # Alternative on Windows\n\n# Logs\n~/.franklin/logs/               # Franklin logs\n~/.franklin/crash-reports/      # Crash reports\n\n\nExercise Structure\nexercise-name/\n├── Dockerfile                  # Container configuration\n├── pixi.toml                  # Dependencies\n├── exercise.ipynb             # Main notebook\n├── README.md                  # Instructions\n├── data/                      # Data files\n├── tests/                     # Test files\n└── .gitlab-ci.yml            # CI/CD pipeline",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#pixi-commands",
    "href": "pages/admin_quick_reference.html#pixi-commands",
    "title": "Quick Reference",
    "section": "Pixi Commands",
    "text": "Pixi Commands\n\nIn Exercise Directory\npixi install                    # Install dependencies\npixi add numpy                  # Add package\npixi remove pandas              # Remove package\npixi list                       # List installed packages\npixi run test-notebook          # Run tests\npixi shell                      # Activate environment\n\n\nGlobal Pixi\npixi global install jupyter     # Install globally\npixi global list               # List global packages\npixi global update             # Update all packages",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#git-commands-for-exercises",
    "href": "pages/admin_quick_reference.html#git-commands-for-exercises",
    "title": "Quick Reference",
    "section": "Git Commands for Exercises",
    "text": "Git Commands for Exercises\n# Check status\ngit status\n\n# Save your work\ngit add -A\ngit commit -m \"Complete exercise 1\"\n\n# Create your own repository\ngit remote add personal https://github.com/you/solutions\ngit push personal main\n\n# Get updates\ngit pull origin main\n\n# View history\ngit log --oneline",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#troubleshooting-commands",
    "href": "pages/admin_quick_reference.html#troubleshooting-commands",
    "title": "Quick Reference",
    "section": "Troubleshooting Commands",
    "text": "Troubleshooting Commands\n\nDiagnostic Commands\nfranklin doctor                 # System diagnostics\nfranklin doctor --verbose       # Detailed diagnostics\n\n# Check components\ndocker --version\ngit --version\npython --version\npixi --version\n\n\nReset and Repair\n# Reset Franklin configuration\nfranklin reset --config\n\n# Clear cache\nfranklin cache clear\n\n# Reinstall Franklin\nconda remove franklin\nconda install -c conda-forge -c munch-group franklin\n\n# Fix permissions (Linux/Mac)\nsudo chown -R $USER:$USER ~/.franklin\n\n\nLogs and Debugging\n# View logs\nfranklin logs                   # Recent logs\nfranklin logs --tail 50         # Last 50 lines\nfranklin logs --follow          # Follow log output\n\n# Debug mode\nFRANKLIN_DEBUG=1 franklin download\n\n# Verbose output\nfranklin --verbose jupyter",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#keyboard-shortcuts",
    "href": "pages/admin_quick_reference.html#keyboard-shortcuts",
    "title": "Quick Reference",
    "section": "Keyboard Shortcuts",
    "text": "Keyboard Shortcuts\n\nJupyterLab\nShift+Enter    Run cell and move to next\nCtrl+Enter     Run cell\nAlt+Enter      Run cell and insert below\nEsc           Command mode\nEnter         Edit mode\nA             Insert cell above\nB             Insert cell below\nDD            Delete cell\nZ             Undo cell deletion\nCtrl+S        Save notebook\n\n\nTerminal (During Franklin Prompts)\n↑/↓           Navigate options\nEnter         Select option\nCtrl+C        Cancel operation\nTab           Auto-complete\nCtrl+L        Clear screen",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#common-workflows",
    "href": "pages/admin_quick_reference.html#common-workflows",
    "title": "Quick Reference",
    "section": "Common Workflows",
    "text": "Common Workflows\n\nStudent Workflow\n# 1. Download exercise\nfranklin download\n\n# 2. Work on exercise\nfranklin jupyter\n\n# 3. Save and submit\n# (Work is auto-saved in exercise folder)\n\n\nEducator Workflow\n# 1. Create exercise\nfranklin exercise new\n\n# 2. Develop and test\ncd exercise-folder\njupyter lab\npixi run test-notebook\n\n# 3. Publish\nfranklin exercise publish\n\n\nAdministrator Workflow\n# 1. Setup course\nfranklin grant educator prof@university.edu\nfranklin grant ta assistant@university.edu\n\n# 2. Add students\nfranklin grant student --file roster.csv\n\n# 3. Monitor usage\nfranklin stats --course \"CS101\"",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#package-management",
    "href": "pages/admin_quick_reference.html#package-management",
    "title": "Quick Reference",
    "section": "Package Management",
    "text": "Package Management\n\nAdding Dependencies to Exercise\n# In exercise directory\npixi add numpy pandas           # Add to pixi.toml\n\n# Or in notebook\n%franklin numpy pandas\n\n# For specific versions\npixi add \"numpy&gt;=1.24,&lt;2.0\"\n\n\nCreating Requirements File\n# Export from pixi\npixi list --export &gt; requirements.txt\n\n# Export from conda\nconda env export &gt; environment.yml",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#cicd-integration",
    "href": "pages/admin_quick_reference.html#cicd-integration",
    "title": "Quick Reference",
    "section": "CI/CD Integration",
    "text": "CI/CD Integration\n\nGitLab CI\n# .gitlab-ci.yml in exercise\ntest:\n  image: registry.gitlab.com/franklin/base:latest\n  script:\n    - pixi install\n    - pixi run test-notebook\n\n\nGitHub Actions\n# .github/workflows/test.yml\nname: Test Exercise\non: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: |\n          pixi install\n          pixi run test-notebook",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/admin_quick_reference.html#help-and-support",
    "href": "pages/admin_quick_reference.html#help-and-support",
    "title": "Quick Reference",
    "section": "Help and Support",
    "text": "Help and Support\n# Get help\nfranklin --help                 # General help\nfranklin download --help        # Command-specific help\n\n# Version information\nfranklin --version\n\n# Submit issues\n# https://github.com/munch-group/franklin/issues\n\n# Documentation\n# https://munch-group.org/franklin",
    "crumbs": [
      "Administration",
      "Quick Reference"
    ]
  },
  {
    "objectID": "pages/commands_admin.html",
    "href": "pages/commands_admin.html",
    "title": "Administrator Commands",
    "section": "",
    "text": "The franklin-admin plugin provides administrative tools for managing users, permissions, and course infrastructure.",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#installation",
    "href": "pages/commands_admin.html#installation",
    "title": "Administrator Commands",
    "section": "Installation",
    "text": "Installation\nInstall the franklin-admin plugin:\n\nUsing CondaUsing Pixi\n\n\nconda install -c conda-forge -c munch-group franklin-admin\n\n\npixi global install --channel conda-forge --channel munch-group franklin-admin\n\n\n\nThe admin plugin automatically installs both franklin and franklin-educator as dependencies.",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#prerequisites",
    "href": "pages/commands_admin.html#prerequisites",
    "title": "Administrator Commands",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGitLab account with Owner or Maintainer role in Franklin group\nAPI token with full access permissions\nSSH key configured for GitLab\nSecure password for token encryption",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#user-management",
    "href": "pages/commands_admin.html#user-management",
    "title": "Administrator Commands",
    "section": "User Management",
    "text": "User Management\n\nList users\nThis command lists all users in a GitLab group.\nfranklin admin users list\n\nThis happensTips\n\n\n\nQueries GitLab for group members\nRetrieves user information and roles\nDisplays formatted table with username, name, role, and email\n\n\n\n\nUse --group to specify a different group\nFilter by role with --role option\nExport to CSV with --format csv\nDefault group is “franklin”\n\n\n\n\n\nList with filters\nFilter users by group and role.\nfranklin admin users list --group intro-bio --role Maintainer\n\nThis happensTips\n\n\n\nQueries specified group\nFilters by specified role\nShows only matching users\n\n\n\n\nRoles: Guest, Reporter, Developer, Maintainer, Owner\nUse for auditing permissions\nCombine with --format json for scripting\n\n\n\n\n\n\n\nAdd user to group\nThis command adds a user to a GitLab group with a specific role.\nfranklin admin users add USERNAME --group GROUP --role ROLE\n\nThis happensTips\n\n\n\nLooks up user by username\nAdds user to specified group\nAssigns specified role\nConfirms successful addition\n\n\n\n\nUsername must exist in GitLab\nRole determines permissions level\nUse --expires-at for temporary access\nAdd TAs as Developer or Maintainer\n\n\n\n\n\n\nRemove user from group\nThis command removes a user from a GitLab group.\nfranklin admin users remove USERNAME --group GROUP\n\nThis happensTips\n\n\n\nConfirms user exists in group\nRemoves user from group\nUser loses access to group resources\n\n\n\n\nUse --confirm to skip confirmation\nUser’s work is preserved\nCan be re-added later\nRemove TAs at semester end\n\n\n\n\n\n\nUpdate user role\nThis command changes a user’s role in a group.\nfranklin admin users update USERNAME --group GROUP --role NEW_ROLE\n\nThis happensTips\n\n\n\nVerifies user is in group\nChanges role to new level\nUpdates permissions immediately\n\n\n\n\nPromote TAs to Maintainer for more access\nDowngrade to Reporter for read-only\nChanges take effect immediately\nCheck current role first with list",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#group-management",
    "href": "pages/commands_admin.html#group-management",
    "title": "Administrator Commands",
    "section": "Group Management",
    "text": "Group Management\n\nCreate course group\nThis command creates a new course subgroup.\nfranklin admin groups create GROUP_NAME\n\nThis happensTips\n\n\n\nCreates subgroup under Franklin parent\nSets initial permissions\nConfigures group settings\nReturns group URL\n\n\n\n\nUse descriptive names like “intro-bio-2024”\nSet visibility with --visibility\nAdd description with --description\nDefault parent is “franklin”\n\n\n\n\n\n\nTechnical details of the process\n\n\nName Validation: Ensures valid GitLab group name\nParent Check: Verifies parent group exists\nAPI Call: Creates group via GitLab API\nSettings: Applies visibility and description\nPermissions: Sets up initial access controls\n\n\n\n\nList groups\nThis command lists all subgroups.\nfranklin admin groups list\n\nThis happensTips\n\n\n\nQueries GitLab for subgroups\nRetrieves group metadata\nShows groups with member and project counts\n\n\n\n\nUse --details for more information\nFilter by parent with --parent\nShows visibility level for each group\nUseful for semester planning\n\n\n\n\n\n\nOpen group settings\nThis command opens group settings in browser.\nfranklin admin groups settings GROUP_NAME\n\nThis happensTips\n\n\n\nConstructs GitLab URL for group\nOpens browser to settings page\n\n\n\n\nFaster than navigating manually\nWorks with any group you can access\nUse for batch configuration\nCheck permissions if page won’t load",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#token-management",
    "href": "pages/commands_admin.html#token-management",
    "title": "Administrator Commands",
    "section": "Token Management",
    "text": "Token Management\n\nStore API token\nThis command stores an encrypted API token for a user.\nfranklin token set\n\nThis happensTips\n\n\n\nPrompts for username\nPrompts for password (for encryption)\nPrompts for API token (hidden input)\nEncrypts token with password\nStores in secure local storage\n\n\n\n\nToken is never transmitted\nPassword encrypts token locally\nUse strong, unique password\nToken needed for API operations\n\n\n\n\n\n\nTechnical details of the process\n\n\nInput Collection: Secure prompts for credentials\nEncryption: AES encryption with password-derived key\nStorage: Saves to local config directory\nValidation: Verifies token format\nSecurity: Never logs or transmits token\n\n\n\n\nRetrieve API token\nThis command retrieves and decrypts a stored API token.\nfranklin token get\n\nThis happensTips\n\n\n\nPrompts for username\nPrompts for password\nDecrypts stored token\nDisplays token (be careful!)\n\n\n\n\nOnly display in secure environment\nToken shown can be copied\nWrong password fails silently\nUse for debugging or backup\n\n\n\n\n\n\nVerify token validity\nThis command checks if a stored token is valid.\nfranklin token verify\n\nThis happensTips\n\n\n\nPrompts for credentials\nDecrypts token\nTests token with GitLab API\nReports validity and permissions\n\n\n\n\nRun periodically to check expiration\nShows token scopes\nConfirms API access works\nUse before important operations\n\n\n\n\n\n\nRotate API token\nThis command replaces an API token with a new one.\nfranklin token rotate\n\nThis happensTips\n\n\n\nCreates new token with same permissions\nUpdates stored encrypted token\nRevokes old token\nConfirms rotation success\n\n\n\n\nDo this periodically for security\nMaintains same access level\nOld token stops working immediately\nUpdate any scripts using old token",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#password-management",
    "href": "pages/commands_admin.html#password-management",
    "title": "Administrator Commands",
    "section": "Password Management",
    "text": "Password Management\n\nChange password\nThis command changes your password for token encryption.\nfranklin password change\n\nThis happensTips\n\n\n\nPrompts for username\nPrompts for current password\nPrompts for new password (twice)\nRe-encrypts token with new password\nUpdates stored credentials\n\n\n\n\nChoose strong password\nDifferent from GitLab password\nRequired to decrypt tokens\nChange regularly for security",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#user-discovery",
    "href": "pages/commands_admin.html#user-discovery",
    "title": "Administrator Commands",
    "section": "User Discovery",
    "text": "User Discovery\n\nFind users\nThis command searches for GitLab users by name or username.\nfranklin finger SEARCH_TERMS\n\nThis happensTips\n\n\n\nSearches GitLab user database\nMatches against name and username\nReturns list of matching users\nShows username, name, email, and state\n\n\n\n\nUse quotes for full names\nWildcards work for patterns\nRequires authentication\nUseful for finding TAs",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#permission-levels",
    "href": "pages/commands_admin.html#permission-levels",
    "title": "Administrator Commands",
    "section": "Permission Levels",
    "text": "Permission Levels\n\nGitLab Roles Explained\n\n\n\nRole\nView Code\nPush Code\nMerge\nCI/CD\nDelete\nMembers\n\n\n\n\nGuest\n❌\n❌\n❌\n❌\n❌\n❌\n\n\nReporter\n✅\n❌\n❌\n❌\n❌\n❌\n\n\nDeveloper\n✅\n✅\n❌\n✅\n❌\n❌\n\n\nMaintainer\n✅\n✅\n✅\n✅\n❌\nLimited\n\n\nOwner\n✅\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n\nRole Recommendations\nCourse Coordinator: Owner of course subgroup - Can create/delete exercises - Manages course TAs - Full control over course content\nTeaching Assistant: Maintainer of course subgroup - Can merge student submissions - Manages exercise settings - Cannot delete course\nEducator (Other Courses): Reporter in main group - Can view exercises for reference - Cannot modify content\nStudent: Guest or no access - Can only see public repositories - Cannot push code",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#bulk-operations",
    "href": "pages/commands_admin.html#bulk-operations",
    "title": "Administrator Commands",
    "section": "Bulk Operations",
    "text": "Bulk Operations\n\nImport users from CSV\nThis command adds multiple users from a CSV file.\nfranklin admin bulk import-users FILE.csv\n\nThis happensTips\n\n\n\nReads CSV file with user data\nValidates each row\nAdds users to specified groups\nReports success/failure for each\n\n\n\n\nCSV needs: username, email, name, group, role\nUse --dry-run to preview\nAdd --skip-existing to avoid errors\nProcess in batches for large lists\n\n\n\n\n\nCSV Format\nRequired CSV structure:\nusername,email,name,group,role\nstudent1,s1@au.dk,Alice Student,intro-bio,Reporter\nstudent2,s2@au.dk,Bob Student,intro-bio,Reporter\nta1,ta1@au.dk,Carol TA,intro-bio,Developer\n\n\n\nExport users to CSV\nThis command exports group members to a CSV file.\nfranklin admin bulk export-users --group GROUP\n\nThis happensTips\n\n\n\nQueries group members\nFormats as CSV\nWrites to output file\nIncludes all user metadata\n\n\n\n\nDefault output is “users.csv”\nUse --output for custom name\nGood for record keeping\nImport to spreadsheet for analysis\n\n\n\n\n\n\nAudit permissions\nThis command checks for permission issues.\nfranklin admin bulk audit\n\nThis happensTips\n\n\n\nScans all groups and users\nIdentifies permission problems\nFinds orphaned users\nReports excessive permissions\nSuggests fixes\n\n\n\n\nRun at semester start/end\nUse --fix-issues for auto-repair\nSave report with --report\nCheck for expired access",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#security-best-practices",
    "href": "pages/commands_admin.html#security-best-practices",
    "title": "Administrator Commands",
    "section": "Security Best Practices",
    "text": "Security Best Practices\n\nToken Security\n\nNever share API tokens - Treat like passwords\nUse token expiration - Set reasonable expiration dates\nRotate regularly - Change tokens periodically\nLimit scope - Only request needed permissions\nRevoke unused tokens - Clean up old tokens\n\n\n\nPassword Security\n\nUse strong passwords - Minimum 12 characters\nUnique passwords - Don’t reuse passwords\nChange regularly - Update every semester\nUse password manager - Store securely\nEnable 2FA - On GitLab account\n\n\n\nPermission Security\n\nPrinciple of least privilege - Minimum necessary access\nRegular audits - Review permissions each semester\nRemove old users - Clean up after course ends\nDocument changes - Keep permission change log\nUse groups - Manage permissions via groups",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#troubleshooting",
    "href": "pages/commands_admin.html#troubleshooting",
    "title": "Administrator Commands",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nAuthentication Failed\nProblem: “Invalid username or password”\nSolution: Verify credentials\nfranklin token verify --user USERNAME\n# Reset if needed\nfranklin password change\n\n\nPermission Denied\nProblem: “You don’t have permission to perform this action”\nSolution: Check your role\nfranklin admin users list --group GROUP | grep USERNAME\n# Request elevation from group owner\n\n\nToken Expired\nProblem: “401 Unauthorized”\nSolution: Create new token - Go to GitLab Profile → Access Tokens - Create new token with needed scopes - Update with franklin token set\n\n\nDebug Mode\nEnable detailed logging:\nexport FRANKLIN_ADMIN_DEBUG=true\nfranklin admin users list\nShows API calls, responses, and error details.",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_admin.html#getting-help",
    "href": "pages/commands_admin.html#getting-help",
    "title": "Administrator Commands",
    "section": "Getting Help",
    "text": "Getting Help\n\nBuilt-in help: franklin admin COMMAND --help\nDocumentation: This guide and GitLab docs\nSupport: Contact Franklin administrators\nIssues: Report bugs to development team",
    "crumbs": [
      "Franklin commands",
      "Administrator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html",
    "href": "pages/commands_edu.html",
    "title": "Educator Commands",
    "section": "",
    "text": "The franklin-educator plugin extends Franklin with commands for creating and managing exercises.",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html#prerequisites",
    "href": "pages/commands_edu.html#prerequisites",
    "title": "Educator Commands",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGitLab account with appropriate permissions\nSSH key configured for GitLab access\nEducator role in the Franklin GitLab group",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html#exercise-management-commands",
    "href": "pages/commands_edu.html#exercise-management-commands",
    "title": "Educator Commands",
    "section": "Exercise Management Commands",
    "text": "Exercise Management Commands\n\nCreate a new exercise\nThis command creates a new exercise repository with starter template.\nfranklin exercise new\n\nThis happensTips\n\n\n\nYou select the target course from a list\nYou enter a repository name (lowercase, no spaces)\nYou choose an exercise template\nFranklin creates the GitLab repository\nTemplate files are added automatically\nThe repository settings page opens in your browser\n\n\n\n\nUse descriptive names like week1-intro or lab3-analysis\nThe standard template includes everything needed to start\nSet repository visibility to “Public” in GitLab settings after creation\nAdd a clear description for students\n\n\n\n\n\n\nTechnical details of the process\n\n\nPermission Check: Verifies educator role in target course\nName Validation: Ensures name follows GitLab conventions\nRepository Creation: Uses GitLab API to create project\nTemplate Copy: Copies template files from Franklin package\nGit Operations: Initializes repo, adds files, makes initial commit\nPipeline Trigger: Starts CI/CD to build initial Docker image\nSettings Launch: Opens browser to repository settings\n\n\n\nCreate with parameters\nSkip interactive prompts by providing parameters directly.\nfranklin exercise new --course intro-bio --name week1-intro --template standard\n\nThis happensTips\n\n\n\nCreates repository directly without prompts\nUses specified course, name, and template\nOpens settings page when complete\n\n\n\n\nUseful for scripting or batch creation\nTemplate options: standard, advanced, minimal\nCourse name must match GitLab group name\n\n\n\n\n\n\n\nEdit an exercise\nThis command launches an exercise editing workflow with live testing.\nfranklin exercise edit\n\nThis happensTips\n\n\n\nYou select the exercise to edit\nFranklin clones it to a temporary directory\nDocker container starts with the exercise\nJupyterLab opens in your browser\nFile changes are watched and auto-saved to Git\nTests run automatically on save\nChanges are committed and pushed when done\n\n\n\n\nBest for quick edits and beginners\nNo Git knowledge required\nDependencies are detected automatically\nTest feedback appears in terminal\n\n\n\n\n\n\nTechnical details of the process\n\n\nExercise Selection: Choose exercise from course list\nClone Repository: Downloads to temporary directory\nLaunch Environment: Starts Docker with exercise\nOpen JupyterLab: Browser opens with files\nFile Watching: Auto-saves changes to Git\nTest on Save: Runs tests automatically\nCommit & Push: Pushes changes when done\n\n\n\nEdit workflows\nChoose different editing workflows based on your needs.\nfranklin exercise edit --workflow assisted  # Git-aware workflow\nfranklin exercise edit --workflow manual    # Just clone and exit\n\nWorkflow optionsTips\n\n\n\nautomated (default): Full automation with file watching\nassisted: Branch creation, manual commits\nmanual: Clone only, you handle everything\n\n\n\n\nUse assisted if comfortable with Git\nManual mode for advanced users\nAutomated mode best for beginners\n\n\n\n\n\n\n\nClone an exercise\nThis command clones an exercise repository for local development.\nfranklin exercise clone\n\nThis happensTips\n\n\n\nYou select the course\nYou select the exercise\nFranklin clones the repository to current directory\nAll files are preserved (including solutions)\n\n\n\n\nDifferent from student download - keeps all files\nPreserves Git history for version control\nUse for complex edits requiring multiple tools\nClone to a dedicated development folder\n\n\n\n\n\nClone with URL\nClone a specific repository directly.\nfranklin exercise clone https://gitlab.au.dk/franklin/course/exercise.git\n\nThis happensTips\n\n\n\nClones the specified repository\nPreserves all educator files\nMaintains Git history\n\n\n\n\nFaster when you know the URL\nUseful for automation\nWorks with any branch\n\n\n\n\n\n\n\nTest an exercise\nThis command runs the exercise test suite locally.\nfranklin exercise test\n\nThis happensTips\n\n\n\nDetects exercise in current directory\nBuilds Docker image if needed\nStarts test container\nRuns all tests in tests/ directory\nValidates notebooks execute without errors\nChecks expected outputs are present\nCleans up test container\n\n\n\n\nRun from exercise root directory\nTests include notebook execution and unit tests\nAdd --verbose for detailed output\nUse --notebook to test specific notebook\n\n\n\n\n\n\nTechnical details of the process\n\n\nDetection: Finds exercise in current directory\nImage Build: Builds Docker image if needed\nContainer Start: Launches test container\nTest Execution: Runs all tests in tests/\nNotebook Execution: Validates notebooks run\nOutput Check: Verifies expected outputs\nCleanup: Removes test container\n\n\n\n\nBuild Docker image\nThis command builds the Docker image for an exercise.\nfranklin exercise build\n\nThis happensTips\n\n\n\nValidates Dockerfile exists\nProcesses dependencies from pixi.toml\nBuilds Docker image\nTags with repository name\nReports image size\n\n\n\n\nRun after updating dependencies\nUse --no-cache for clean rebuild\nAdd --push to upload immediately\nLarge images (&gt;2GB) may be slow for students\n\n\n\n\n\n\nPublish an exercise\nThis command publishes an exercise to the GitLab registry.\nfranklin exercise publish\n\nThis happensTips\n\n\n\nRuns test suite (unless skipped)\nBuilds Docker image\nAuthenticates with GitLab registry\nPushes image to registry\nUpdates latest tag\nVerifies image accessibility\n\n\n\n\nAlways test before publishing\nUse version tags for releases\nStudents get latest tag by default\nRun from exercise directory\n\n\n\n\n\nPublish with tag\nPublish with a specific version tag.\nfranklin exercise publish --tag v1.0\nfranklin exercise publish --tag fall2024\n\nThis happensTips\n\n\n\nSame as regular publish\nAdditionally tags with specified version\nPreserves previous versions\n\n\n\n\nUse semantic versioning (v1.0, v1.1, etc.)\nTag by semester for clarity\nAlways also publish as latest\n\n\n\n\n\n\n\nOpen exercise settings\nThis command opens the GitLab settings page for an exercise.\nfranklin exercise settings\n\nThis happensTips\n\n\n\nYou select the exercise\nBrowser opens to GitLab settings page\n\n\n\n\nChange visibility to Public for student access\nAdd course description\nConfigure CI/CD variables\nManage access permissions\n\n\n\n\n\nOpen specific section\nNavigate directly to a settings section.\nfranklin exercise settings --section visibility\nfranklin exercise settings --section ci-cd\nfranklin exercise settings --section members\n\nSectionsTips\n\n\n\nvisibility: Project visibility settings\nci-cd: Pipeline configuration\nmembers: Access management\n\n\n\n\nSaves clicks when you know what to change\nUseful for batch configuration\nSome sections require maintainer access\n\n\n\n\n\n\n\nArchive an exercise\nThis command archives (hides) an exercise from students.\nfranklin exercise archive\n\nThis happensTips\n\n\n\nYou select the exercise to archive\nConfirmation prompt appears\nRepository is set to archived state\nExercise hidden from student lists\nImage remains in registry\n\n\n\n\nUse for outdated exercises\nCan be unarchived later\nStudents can’t see archived exercises\nAll data is preserved\n\n\n\n\n\n\nTechnical details of the process\n\n\nExercise Selection: Choose exercise to archive\nConfirmation: Confirm archival intent\nAPI Call: Sets repository to archived state\nRegistry Update: Removes from student view\nPreservation: Keeps all code, history, and images",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html#best-practices",
    "href": "pages/commands_edu.html#best-practices",
    "title": "Educator Commands",
    "section": "Best Practices",
    "text": "Best Practices\n\nExercise Design\n\nClear Learning Objectives: State what students will learn\nIncremental Complexity: Build from simple to complex\nFrequent Checkpoints: Let students verify progress\nRich Feedback: Provide hints and validation\nReal-World Relevance: Use meaningful datasets\n\n\n\nDependency Management\n\nMinimal Dependencies: Only what’s needed\nPin Major Versions: Avoid breaking changes\nTest Compatibility: Verify versions work together\nDocument Requirements: List in README\n\n\n\nVersion Control\n\nMeaningful Commits: Describe changes clearly\nTag Releases: Mark stable versions\nBranch Features: Develop in branches\nTest Before Merge: Ensure CI passes",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html#troubleshooting",
    "href": "pages/commands_edu.html#troubleshooting",
    "title": "Educator Commands",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nSSH Key Problems\nProblem: “Permission denied (publickey)”\nSolution: Configure SSH key\nssh-keygen -t ed25519 -C \"your-email@au.dk\"\n# Add public key to GitLab profile\n\n\nPermission Denied\nProblem: “You don’t have permission”\nSolution: Verify educator role - Contact course coordinator for access - Check GitLab group membership\n\n\nDocker Build Failures\nProblem: “Docker build failed”\nSolution: Check Dockerfile\ndocker build . --no-cache  # Clean rebuild\n# Verify base image exists\n# Check dependency conflicts\n\n\nTest Failures\nProblem: “Tests failed”\nSolution: Debug tests\nfranklin exercise test --verbose\n# Check test configuration\n# Verify notebook outputs",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/commands_edu.html#getting-help",
    "href": "pages/commands_edu.html#getting-help",
    "title": "Educator Commands",
    "section": "Getting Help",
    "text": "Getting Help\n\nBuilt-in help: franklin exercise COMMAND --help\nDocumentation: This guide and other resources\nGitLab issues: Report problems in exercise repository\nCourse coordinator: For access and permissions",
    "crumbs": [
      "Franklin commands",
      "Educator Commands"
    ]
  },
  {
    "objectID": "pages/developer_guide.html",
    "href": "pages/developer_guide.html",
    "title": "Franklin Developer Guide",
    "section": "",
    "text": "This guide is for developers who want to contribute to Franklin or build extensions. Franklin is a Python-based educational platform with a plugin architecture, making it extensible and maintainable.",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#introduction",
    "href": "pages/developer_guide.html#introduction",
    "title": "Franklin Developer Guide",
    "section": "",
    "text": "This guide is for developers who want to contribute to Franklin or build extensions. Franklin is a Python-based educational platform with a plugin architecture, making it extensible and maintainable.",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#architecture-overview",
    "href": "pages/developer_guide.html#architecture-overview",
    "title": "Franklin Developer Guide",
    "section": "Architecture Overview",
    "text": "Architecture Overview\n\n\n\n\n\n\ngraph TB\n    subgraph \"Franklin Core\"\n        CLI[CLI Interface]\n        PM[Plugin Manager]\n        DM[Docker Manager]\n        GM[GitLab Manager]\n        JM[Jupyter Manager]\n        AUTH[Auth Module]\n    end\n    \n    subgraph \"Plugins\"\n        EDU[franklin-educator]\n        ADMIN[franklin-admin]\n        MAGIC[franklin-container]\n    end\n    \n    subgraph \"External Services\"\n        DOCKER[Docker Engine]\n        GITLAB[GitLab API]\n        PIXI[Pixi Package Manager]\n    end\n    \n    CLI --&gt; PM\n    PM --&gt; EDU\n    PM --&gt; ADMIN\n    EDU --&gt; ADMIN\n    \n    DM --&gt; DOCKER\n    GM --&gt; GITLAB\n    JM --&gt; DOCKER\n    MAGIC --&gt; PIXI\n\n\n\n\nFigure 1: Architecture graphical outline\n\n\n\n\n\n\nCore Components\n\nCLI Framework: Built with Click, supports plugins via entry points\nPlugin System: Dynamic command registration through importlib.metadata\nDocker Integration: Container lifecycle management for isolated environments\nGitLab Integration: Exercise distribution and version control\nAuthentication: Centralized token and encryption management",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#development-setup",
    "href": "pages/developer_guide.html#development-setup",
    "title": "Franklin Developer Guide",
    "section": "Development Setup",
    "text": "Development Setup\n\n\nPrerequisites\n# Required tools\n- Python 3.9+\n- Docker Desktop\n- Git\n- Miniforge/Miniconda\n\n# Optional but recommended\n- VS Code with Python extension\n- Docker extension for VS Code\n- GitLab account for testing\n\n\nSetting Up Development Environment\n# Clone the repository\ngit clone https://github.com/munch-group/franklin.git\ncd franklin-ecosystem\n\n# Create development environment\nconda create -n franklin-dev python=3.11\nconda activate franklin-dev\n\n# Install in development mode\ncd franklin\npip install -e .\n\n# Install development dependencies\npip install pytest pytest-cov black mypy ruff\n\n# Install plugins in development mode\ncd ../franklin-educator\npip install -e .\ncd ../franklin-admin\npip install -e .\n\n\nProject Structure\nfranklin-ecosystem/\n├── franklin/                    # Core package\n│   ├── src/franklin/\n│   │   ├── __init__.py         # Main CLI entry point\n│   │   ├── plugin_interface.py # Plugin base classes\n│   │   ├── interfaces.py       # Facade interfaces\n│   │   ├── auth.py            # Authentication utilities\n│   │   ├── docker.py          # Docker management\n│   │   ├── gitlab.py          # GitLab integration\n│   │   ├── jupyter.py         # Jupyter management\n│   │   └── config.py          # Configuration\n│   ├── tests/\n│   ├── pyproject.toml\n│   └── docs/\n├── franklin-educator/          # Educator plugin\n├── franklin-admin/            # Admin plugin\n└── franklin-container/        # Jupyter magic",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#plugin-development",
    "href": "pages/developer_guide.html#plugin-development",
    "title": "Franklin Developer Guide",
    "section": "Plugin Development",
    "text": "Plugin Development\n\nCreating a New Plugin\n\nCreate plugin structure:\n\nfranklin-myplugin/\n├── src/\n│   └── franklin_myplugin/\n│       ├── __init__.py\n│       └── commands.py\n├── pyproject.toml\n├── README.md\n└── tests/\n\nConfigure pyproject.toml:\n\n[project]\nname = \"franklin-myplugin\"\nversion = \"0.1.0\"\ndependencies = [\n    \"franklin&gt;=0.24.165\",\n]\n\n[project.entry-points.\"franklin.plugins\"]\nmycommand = \"franklin_myplugin.commands:mycommand\"\n\nImplement plugin commands:\n\n# src/franklin_myplugin/commands.py\nimport click\nfrom franklin.interfaces import TerminalInterface, DockerInterface\nfrom franklin.plugin_interface import FranklinPlugin\n\n@click.command()\n@click.option('--name', help='Resource name')\ndef mycommand(name):\n    \"\"\"My custom Franklin command\"\"\"\n    term = TerminalInterface()\n    docker = DockerInterface()\n    \n    if docker.is_docker_running():\n        term.print_success(f\"Processing {name}\")\n    else:\n        term.print_error(\"Docker is not running\")\n\nclass MyPlugin(FranklinPlugin):\n    \"\"\"Custom Franklin plugin\"\"\"\n    \n    def get_commands(self):\n        return [mycommand]\n    \n    def get_config_schema(self):\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"setting1\": {\"type\": \"string\"},\n                \"setting2\": {\"type\": \"integer\"}\n            }\n        }\n\n\nUsing Facade Interfaces\nAlways use facade interfaces instead of importing internal modules:\n# Good - Using facades\nfrom franklin.interfaces import (\n    GitLabInterface, \n    TerminalInterface,\n    DockerInterface,\n    ConfigInterface\n)\n\ndef my_function():\n    gitlab = GitLabInterface()\n    term = TerminalInterface()\n    \n    user_info = gitlab.get_user_info()\n    term.print_info(f\"User: {user_info['name']}\")\n\n# Bad - Direct imports (avoid this)\nfrom franklin import gitlab, terminal  # Don't do this\n\n\nPlugin Best Practices\n\nDependency Management: Declare only franklin as dependency\nError Handling: Use Franklin’s terminal interface for consistent output\nConfiguration: Use the config schema for plugin settings\nTesting: Write tests for all commands\nDocumentation: Include docstrings and README",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#core-development",
    "href": "pages/developer_guide.html#core-development",
    "title": "Franklin Developer Guide",
    "section": "Core Development",
    "text": "Core Development\n\nWorking with Docker Integration\n# franklin/src/franklin/docker.py enhancements\nfrom typing import Optional, Dict, Any\nimport docker\n\nclass DockerManager:\n    \"\"\"Enhanced Docker management\"\"\"\n    \n    def __init__(self):\n        self.client = docker.from_env()\n    \n    def create_container(\n        self,\n        name: str,\n        image: str,\n        environment: Optional[Dict[str, str]] = None,\n        volumes: Optional[Dict[str, Dict[str, str]]] = None,\n        **kwargs\n    ) -&gt; docker.models.containers.Container:\n        \"\"\"Create a new container with specified configuration\"\"\"\n        \n        config = {\n            'name': name,\n            'image': image,\n            'detach': True,\n            'environment': environment or {},\n            'volumes': volumes or {},\n            **kwargs\n        }\n        \n        # Add Franklin-specific labels\n        config['labels'] = {\n            'franklin.version': get_version(),\n            'franklin.type': 'exercise',\n            **config.get('labels', {})\n        }\n        \n        return self.client.containers.create(**config)\n\n\nExtending GitLab Integration\n# Adding new GitLab functionality\nfrom franklin.interfaces import GitLabInterface\nimport requests\n\nclass ExtendedGitLab(GitLabInterface):\n    \"\"\"Extended GitLab functionality\"\"\"\n    \n    def create_merge_request(\n        self,\n        project_id: str,\n        source_branch: str,\n        target_branch: str,\n        title: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Create a merge request\"\"\"\n        \n        url = f\"{self.get_gitlab_url()}/api/v4/projects/{project_id}/merge_requests\"\n        headers = {\"PRIVATE-TOKEN\": self.get_api_token()}\n        \n        data = {\n            \"source_branch\": source_branch,\n            \"target_branch\": target_branch,\n            \"title\": title,\n            \"remove_source_branch\": True\n        }\n        \n        response = requests.post(url, headers=headers, json=data)\n        response.raise_for_status()\n        return response.json()\n\n\nAuthentication System\n# Working with the auth module\nfrom franklin.auth import encrypt_data, decrypt_data\nfrom pathlib import Path\n\ndef store_credentials(username: str, password: str, data: str):\n    \"\"\"Store encrypted credentials\"\"\"\n    \n    encrypted = encrypt_data(data, password)\n    \n    cred_path = Path.home() / \".franklin\" / \"credentials\" / f\"{username}.enc\"\n    cred_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    with open(cred_path, 'wb') as f:\n        f.write(encrypted)\n\ndef retrieve_credentials(username: str, password: str) -&gt; str:\n    \"\"\"Retrieve and decrypt credentials\"\"\"\n    \n    cred_path = Path.home() / \".franklin\" / \"credentials\" / f\"{username}.enc\"\n    \n    with open(cred_path, 'rb') as f:\n        encrypted = f.read()\n    \n    return decrypt_data(encrypted, password)",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#testing",
    "href": "pages/developer_guide.html#testing",
    "title": "Franklin Developer Guide",
    "section": "Testing",
    "text": "Testing\n\nUnit Testing\n# tests/test_commands.py\nimport pytest\nfrom click.testing import CliRunner\nfrom franklin import franklin\nfrom unittest.mock import patch, MagicMock\n\ndef test_download_command():\n    \"\"\"Test the download command\"\"\"\n    runner = CliRunner()\n    \n    with patch('franklin.gitlab.get_registry_listing') as mock_listing:\n        mock_listing.return_value = {\n            ('course1', 'Course 1'): 'image1',\n            ('course2', 'Course 2'): 'image2'\n        }\n        \n        result = runner.invoke(franklin, ['download', '--help'])\n        assert result.exit_code == 0\n        assert 'Download an exercise' in result.output\n\n@pytest.fixture\ndef mock_docker():\n    \"\"\"Mock Docker client\"\"\"\n    with patch('docker.from_env') as mock:\n        client = MagicMock()\n        mock.return_value = client\n        yield client\n\ndef test_container_management(mock_docker):\n    \"\"\"Test container creation and management\"\"\"\n    from franklin.docker import DockerManager\n    \n    manager = DockerManager()\n    container = manager.create_container(\n        name='test-container',\n        image='python:3.11'\n    )\n    \n    mock_docker.containers.create.assert_called_once()\n\n\nIntegration Testing\n# tests/test_integration.py\nimport subprocess\nimport tempfile\nfrom pathlib import Path\n\ndef test_full_workflow():\n    \"\"\"Test complete exercise workflow\"\"\"\n    \n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Create test exercise\n        result = subprocess.run(\n            ['franklin', 'exercise', 'new'],\n            input='Test Course\\nTest Exercise\\n',\n            text=True,\n            capture_output=True,\n            cwd=tmpdir\n        )\n        assert result.returncode == 0\n        \n        # Verify exercise structure\n        exercise_dir = Path(tmpdir) / 'Test Exercise'\n        assert exercise_dir.exists()\n        assert (exercise_dir / 'Dockerfile').exists()\n        assert (exercise_dir / 'pixi.toml').exists()\n        assert (exercise_dir / 'exercise.ipynb').exists()\n\n\nPerformance Testing\n# tests/test_performance.py\nimport time\nimport pytest\nfrom franklin.docker import DockerManager\n\n@pytest.mark.performance\ndef test_container_startup_time():\n    \"\"\"Test container startup performance\"\"\"\n    \n    manager = DockerManager()\n    \n    start_time = time.time()\n    container = manager.create_container(\n        name='perf-test',\n        image='python:3.11-slim'\n    )\n    container.start()\n    container.wait(condition='running', timeout=30)\n    elapsed = time.time() - start_time\n    \n    assert elapsed &lt; 10, f\"Container startup took {elapsed}s\"\n    \n    # Cleanup\n    container.remove(force=True)",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#debugging",
    "href": "pages/developer_guide.html#debugging",
    "title": "Franklin Developer Guide",
    "section": "Debugging",
    "text": "Debugging\n\nDebug Mode\nEnable debug mode for verbose output:\n# franklin/src/franklin/config.py\nimport os\nimport logging\n\ndef setup_logging():\n    \"\"\"Configure logging based on environment\"\"\"\n    \n    level = logging.DEBUG if os.environ.get('FRANKLIN_DEBUG') else logging.INFO\n    \n    logging.basicConfig(\n        level=level,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler('franklin.log'),\n            logging.StreamHandler()\n        ]\n    )\n\n# Use in code\nimport logging\nlogger = logging.getLogger(__name__)\n\ndef my_function():\n    logger.debug(\"Entering my_function\")\n    # ... function code ...\n    logger.debug(\"Exiting my_function\")\n\n\nRemote Debugging\n# Enable remote debugging with debugpy\nimport debugpy\n\ndef enable_remote_debugging(port=5678):\n    \"\"\"Enable remote debugging for VS Code\"\"\"\n    \n    debugpy.listen((\"0.0.0.0\", port))\n    print(f\"Waiting for debugger on port {port}...\")\n    debugpy.wait_for_client()\n\n# VS Code launch.json configuration\n{\n    \"name\": \"Attach to Franklin\",\n    \"type\": \"python\",\n    \"request\": \"attach\",\n    \"connect\": {\n        \"host\": \"localhost\",\n        \"port\": 5678\n    }\n}",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#cicd-pipeline",
    "href": "pages/developer_guide.html#cicd-pipeline",
    "title": "Franklin Developer Guide",
    "section": "CI/CD Pipeline",
    "text": "CI/CD Pipeline\n\nGitHub Actions Workflow\n# .github/workflows/test.yml\nname: Test Franklin\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        python: ['3.9', '3.10', '3.11']\n    \n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python }}\n    \n    - name: Install dependencies\n      run: |\n        pip install -e .[dev]\n        pip install pytest pytest-cov\n    \n    - name: Run tests\n      run: |\n        pytest tests/ --cov=franklin --cov-report=xml\n    \n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n\nRelease Process\n# 1. Update version in pyproject.toml\n# 2. Update CHANGELOG.md\n# 3. Commit changes\ngit add -A\ngit commit -m \"chore: release v0.24.166\"\n\n# 4. Create and push tag\n./release-tag.sh \"Release v0.24.166\"\n\n# 5. GitHub Actions automatically:\n#    - Builds packages\n#    - Publishes to conda-forge\n#    - Updates documentation",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#documentation",
    "href": "pages/developer_guide.html#documentation",
    "title": "Franklin Developer Guide",
    "section": "Documentation",
    "text": "Documentation\n\nBuilding Documentation\ncd franklin/docs\n\n# Install documentation dependencies\npip install quartodoc quarto\n\n# Build API documentation\nquartodoc build\n\n# Build and serve documentation\nquarto preview\n\n\nWriting Documentation\n\nAPI Documentation: Use NumPy-style docstrings\nTutorials: Create .qmd files in docs/pages/\nExamples: Include runnable code examples\nScreenshots: Store in docs/pages/images/",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#contributing-guidelines",
    "href": "pages/developer_guide.html#contributing-guidelines",
    "title": "Franklin Developer Guide",
    "section": "Contributing Guidelines",
    "text": "Contributing Guidelines\n\nCode Style\n# Format code with black\nblack src/ tests/\n\n# Check with ruff\nruff check src/ tests/\n\n# Type checking with mypy\nmypy src/franklin/\n\n\nCommit Convention\nFollow conventional commits:\nfeat: add new Docker management features\nfix: resolve container startup issue\ndocs: update developer guide\ntest: add integration tests for GitLab\nrefactor: simplify plugin loading mechanism\nchore: update dependencies\n\n\nPull Request Process\n\nFork the repository\nCreate feature branch: git checkout -b feature/my-feature\nMake changes and test thoroughly\nUpdate documentation if needed\nSubmit PR with clear description\nEnsure CI passes\nRequest review from maintainers",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#security-considerations",
    "href": "pages/developer_guide.html#security-considerations",
    "title": "Franklin Developer Guide",
    "section": "Security Considerations",
    "text": "Security Considerations\n\nHandling Sensitive Data\n# Never log sensitive information\nimport logging\n\ndef safe_log(data: dict):\n    \"\"\"Log data with sensitive fields redacted\"\"\"\n    \n    sensitive_keys = ['password', 'token', 'api_key', 'secret']\n    safe_data = {\n        k: '***REDACTED***' if k in sensitive_keys else v\n        for k, v in data.items()\n    }\n    logging.info(f\"Data: {safe_data}\")\n\n\nInput Validation\n# Validate all user input\nfrom pathlib import Path\nimport re\n\ndef validate_exercise_name(name: str) -&gt; bool:\n    \"\"\"Validate exercise name\"\"\"\n    \n    # Check length\n    if not 1 &lt;= len(name) &lt;= 50:\n        return False\n    \n    # Check characters (alphanumeric, spaces, hyphens)\n    if not re.match(r'^[a-zA-Z0-9\\s\\-]+$', name):\n        return False\n    \n    # Check for path traversal attempts\n    if '..' in name or '/' in name or '\\\\' in name:\n        return False\n    \n    return True",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#performance-optimization",
    "href": "pages/developer_guide.html#performance-optimization",
    "title": "Franklin Developer Guide",
    "section": "Performance Optimization",
    "text": "Performance Optimization\n\nCaching Strategies\nfrom functools import lru_cache\nimport time\n\nclass CachedGitLab:\n    \"\"\"GitLab client with caching\"\"\"\n    \n    def __init__(self):\n        self._cache_ttl = 300  # 5 minutes\n        self._cache = {}\n    \n    @lru_cache(maxsize=128)\n    def get_user_info(self, user_id: str):\n        \"\"\"Get user info with caching\"\"\"\n        \n        cache_key = f\"user_{user_id}\"\n        cached = self._cache.get(cache_key)\n        \n        if cached and time.time() - cached['time'] &lt; self._cache_ttl:\n            return cached['data']\n        \n        # Fetch from API\n        data = self._fetch_user(user_id)\n        \n        self._cache[cache_key] = {\n            'data': data,\n            'time': time.time()\n        }\n        \n        return data\n\n\nAsync Operations\nimport asyncio\nimport aiohttp\n\nasync def fetch_exercises(courses: list):\n    \"\"\"Fetch exercises for multiple courses concurrently\"\"\"\n    \n    async with aiohttp.ClientSession() as session:\n        tasks = [\n            fetch_course_exercises(session, course)\n            for course in courses\n        ]\n        return await asyncio.gather(*tasks)\n\nasync def fetch_course_exercises(session, course):\n    \"\"\"Fetch exercises for a single course\"\"\"\n    \n    url = f\"https://gitlab.com/api/v4/groups/{course}/projects\"\n    async with session.get(url) as response:\n        return await response.json()",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#troubleshooting-development-issues",
    "href": "pages/developer_guide.html#troubleshooting-development-issues",
    "title": "Franklin Developer Guide",
    "section": "Troubleshooting Development Issues",
    "text": "Troubleshooting Development Issues\n\nCommon Problems and Solutions\nImport errors in development\n# Ensure package is installed in editable mode\npip install -e .\n\n# Check Python path\npython -c \"import sys; print(sys.path)\"\nDocker permission issues\n# Add user to docker group (Linux)\nsudo usermod -aG docker $USER\n\n# Restart Docker service\nsudo systemctl restart docker\nPlugin not loading\n# Check entry points are registered\npython -c \"from importlib.metadata import entry_points; print(entry_points())\"\n\n# Reinstall package\npip install -e . --force-reinstall",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/developer_guide.html#resources",
    "href": "pages/developer_guide.html#resources",
    "title": "Franklin Developer Guide",
    "section": "Resources",
    "text": "Resources\n\nDocumentation\n\nClick Documentation\nDocker SDK for Python\nGitLab API Documentation\nPixi Documentation\n\n\n\nCommunity\n\nFranklin GitHub Discussions\nFranklin Issues\nContributing Guide\n\n\n\nTools\n\nPython Packaging Guide\nConventional Commits\nSemantic Versioning",
    "crumbs": [
      "Developer Resources",
      "Franklin Developer Guide"
    ]
  },
  {
    "objectID": "pages/docker.html",
    "href": "pages/docker.html",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Docker is a platform that packages applications and their dependencies into portable containers. Think of a container as a lightweight, self-contained box that includes everything needed to run your software—the code, runtime, system tools, libraries, and settings. This ensures your application runs identically on any computer, regardless of the operating system or installed software.\n\n\nWithout Docker: - “It works on my machine!” but fails on yours - Different versions of Python, libraries, or system tools - Complex installation instructions that vary by OS - Conflicts between projects requiring different dependencies - Difficulty reproducing research or coursework\nWith Docker: - Same environment everywhere - No installation conflicts - One command to run complex applications - Perfect reproducibility - Isolation between projects",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#what-is-docker",
    "href": "pages/docker.html#what-is-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Docker is a platform that packages applications and their dependencies into portable containers. Think of a container as a lightweight, self-contained box that includes everything needed to run your software—the code, runtime, system tools, libraries, and settings. This ensures your application runs identically on any computer, regardless of the operating system or installed software.\n\n\nWithout Docker: - “It works on my machine!” but fails on yours - Different versions of Python, libraries, or system tools - Complex installation instructions that vary by OS - Conflicts between projects requiring different dependencies - Difficulty reproducing research or coursework\nWith Docker: - Same environment everywhere - No installation conflicts - One command to run complex applications - Perfect reproducibility - Isolation between projects",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#how-docker-works",
    "href": "pages/docker.html#how-docker-works",
    "title": "Introduction to Docker",
    "section": "How Docker Works",
    "text": "How Docker Works\n\nContainers vs Virtual Machines\n\n\n\n\n\n\ngraph TB\n    subgraph \"Virtual Machine\"\n        VM[Guest OS&lt;br/&gt;20GB+] --&gt; APP1[App A]\n        VM --&gt; APP2[App B]\n        HOST1[Host OS] --&gt; HYP[Hypervisor] --&gt; VM\n    end\n    \n    subgraph \"Docker Container\"\n        HOST2[Host OS] --&gt; DOC[Docker Engine]\n        DOC --&gt; CON1[Container A&lt;br/&gt;~100MB]\n        DOC --&gt; CON2[Container B&lt;br/&gt;~100MB]\n    end\n\n\n\n\nFigure 1: Containers vs. virtual machines\n\n\n\n\n\nVirtual Machines: - Full operating system per VM - Heavy resource usage (GB of RAM) - Slow to start (minutes) - Complete isolation\nDocker Containers: - Share host OS kernel - Lightweight (MB of RAM) - Fast to start (seconds) - Process-level isolation\n\n\nCore Docker Concepts\n\nImage: A blueprint or template for creating containers (like a recipe)\nContainer: A running instance of an image (like a cooked meal)\nDockerfile: Instructions for building an image (like writing a recipe)\nRegistry: Storage for sharing images (like a cookbook library)",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-for-franklin-users",
    "href": "pages/docker.html#docker-for-franklin-users",
    "title": "Introduction to Docker",
    "section": "Docker for Franklin Users",
    "text": "Docker for Franklin Users\nFranklin uses Docker to ensure exercises run identically for all students:\n\nHow Franklin Uses Docker\n\n\n\n\n\n\ngraph LR\n    A[Franklin Exercise] --&gt; B[Docker Image]\n    B --&gt; C[Container Starts]\n    C --&gt; D[JupyterLab Runs]\n    D --&gt; E[Student Works]\n    E --&gt; F[Work Saved Locally]\n\n\n\n\nFigure 2: Franklin and Docker\n\n\n\n\n\n\nExercise includes Docker configuration\nFranklin pulls required image\nCreates isolated container\nMounts your files inside\nRuns JupyterLab in container\nYour work is saved on your computer\n\n\n\nStudent Perspective\nAs a Franklin student, Docker works behind the scenes:\n# Franklin handles Docker automatically\nfranklin jupyter\n# → Downloads Docker image if needed\n# → Starts container\n# → Opens JupyterLab\n# → Everything just works!\nYou don’t need to know Docker commands—Franklin manages everything.",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#installing-docker",
    "href": "pages/docker.html#installing-docker",
    "title": "Introduction to Docker",
    "section": "Installing Docker",
    "text": "Installing Docker\n\nWindowsmacOSLinux\n\n\n\nDownload Docker Desktop:\n\nVisit docker.com/products/docker-desktop\nDownload for Windows\nRun installer\n\nSystem Requirements:\n\nWindows 10/11 Pro, Enterprise, or Education\nWSL 2 enabled\n4GB RAM minimum\n\nPost-Installation:\n\nStart Docker Desktop\nWait for “Docker is running” status\nTest: docker --version\n\n\n\n\n\nDownload Docker Desktop:\n\nVisit docker.com/products/docker-desktop\nChoose Intel or Apple Silicon version\nRun installer\n\nSystem Requirements:\n\nmacOS 10.15 or newer\n4GB RAM minimum\n\nPost-Installation:\n\nStart Docker Desktop from Applications\nGrant necessary permissions\nTest: docker --version\n\n\n\n\n# Ubuntu/Debian\nsudo apt update\nsudo apt install docker.io\nsudo systemctl start docker\nsudo usermod -aG docker $USER\n# Log out and back in\n\n# Fedora\nsudo dnf install docker\nsudo systemctl start docker\nsudo usermod -aG docker $USER\n# Log out and back in\n\n# Test installation\ndocker --version\ndocker run hello-world",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#basic-docker-commands",
    "href": "pages/docker.html#basic-docker-commands",
    "title": "Introduction to Docker",
    "section": "Basic Docker Commands",
    "text": "Basic Docker Commands\nWhile Franklin handles Docker automatically, understanding basic commands helps troubleshooting:\n\nWorking with Images\n# List local images\ndocker images\n\n# Pull an image\ndocker pull python:3.10\n\n# Remove an image\ndocker rmi python:3.10\n\n# Search for images\ndocker search jupyter\n\n\nWorking with Containers\n# List running containers\ndocker ps\n\n# List all containers\ndocker ps -a\n\n# Stop a container\ndocker stop container_name\n\n# Remove a container\ndocker rm container_name\n\n# View container logs\ndocker logs container_name\n\n\nRunning Containers\n# Basic run\ndocker run python:3.10 python --version\n\n# Interactive mode\ndocker run -it python:3.10 bash\n\n# Run with port mapping\ndocker run -p 8888:8888 jupyter/base-notebook\n\n# Run with volume mount\ndocker run -v /local/path:/container/path python:3.10\n\n# Run in background\ndocker run -d nginx",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#understanding-dockerfiles",
    "href": "pages/docker.html#understanding-dockerfiles",
    "title": "Introduction to Docker",
    "section": "Understanding Dockerfiles",
    "text": "Understanding Dockerfiles\nA Dockerfile defines how to build an image:\n# Start from base image\nFROM python:3.10-slim\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements file\nCOPY requirements.txt .\n\n# Install dependencies\nRUN pip install -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Define startup command\nCMD [\"python\", \"app.py\"]\n\nFranklin Exercise Dockerfile\nFranklin exercises typically use:\n# Base scientific Python image\nFROM munchgroup/franklin-jupyter:latest\n\n# Install exercise-specific packages\nRUN pip install pandas numpy matplotlib\n\n# Copy exercise files\nCOPY exercise.ipynb /home/jovyan/\n\n# Set up environment\nENV PYTHONPATH=/home/jovyan\n\n# Start JupyterLab\nCMD [\"jupyter\", \"lab\"]",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-compose",
    "href": "pages/docker.html#docker-compose",
    "title": "Introduction to Docker",
    "section": "Docker Compose",
    "text": "Docker Compose\nFor multi-container applications:\n# docker-compose.yml\nversion: '3'\n\nservices:\n  web:\n    image: nginx\n    ports:\n      - \"80:80\"\n  \n  database:\n    image: postgres\n    environment:\n      POSTGRES_PASSWORD: secret\n    volumes:\n      - db-data:/var/lib/postgresql/data\n\nvolumes:\n  db-data:\nRun with:\ndocker-compose up    # Start services\ndocker-compose down  # Stop services",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-for-development",
    "href": "pages/docker.html#docker-for-development",
    "title": "Introduction to Docker",
    "section": "Docker for Development",
    "text": "Docker for Development\n\nCreating Development Environments\n# Python development\ndocker run -it -v $(pwd):/workspace python:3.10 bash\n\n# Node.js development\ndocker run -it -v $(pwd):/app node:18 bash\n\n# Data science environment\ndocker run -p 8888:8888 -v $(pwd):/home/jovyan jupyter/scipy-notebook\n\n\nBuilding Custom Images\n\nCreate Dockerfile:\n\nFROM python:3.10\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\n\nBuild image:\n\ndocker build -t my-app .\n\nRun container:\n\ndocker run my-app",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-best-practices",
    "href": "pages/docker.html#docker-best-practices",
    "title": "Introduction to Docker",
    "section": "Docker Best Practices",
    "text": "Docker Best Practices\n\nImage Optimization\n✅ Do: - Use specific version tags (python:3.10, not python:latest) - Minimize layers by combining RUN commands - Use .dockerignore to exclude unnecessary files - Start with minimal base images (alpine, slim) - Clean up after installations\n❌ Don’t: - Include sensitive data in images - Run as root unnecessarily - Use large base images when smaller ones work - Ignore security updates\n\n\nContainer Management\n✅ Do: - Name your containers meaningfully - Use volumes for persistent data - Set resource limits - Use health checks - Clean up stopped containers\n❌ Don’t: - Store data inside containers - Expose unnecessary ports - Run multiple processes per container - Ignore container logs",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#troubleshooting-docker",
    "href": "pages/docker.html#troubleshooting-docker",
    "title": "Introduction to Docker",
    "section": "Troubleshooting Docker",
    "text": "Troubleshooting Docker\n\nCommon Issues\n\nDocker Daemon Not Running\n# Check status\ndocker version\n\n# Start Docker\n# macOS/Windows: Start Docker Desktop app\n# Linux:\nsudo systemctl start docker\n\n\nPermission Denied\n# Linux: Add user to docker group\nsudo usermod -aG docker $USER\n# Log out and back in\n\n# Or use sudo (not recommended)\nsudo docker run hello-world\n\n\nPort Already in Use\n# Find process using port\nlsof -i :8888  # macOS/Linux\nnetstat -ano | findstr :8888  # Windows\n\n# Use different port\ndocker run -p 8889:8888 image_name\n\n\nOut of Disk Space\n# Clean up unused resources\ndocker system prune -a\n\n# Remove unused images\ndocker image prune -a\n\n# Remove stopped containers\ndocker container prune\n\n# Remove unused volumes\ndocker volume prune\n\n\n\nFranklin-Specific Issues\n\nContainer Won’t Start\n# Check Franklin logs\nfranklin jupyter --debug\n\n# Manually pull image\ndocker pull munchgroup/franklin-jupyter:latest\n\n# Reset Franklin Docker settings\nfranklin docker reset\n\n\nFiles Not Visible\n# Check mount points\ndocker inspect container_name | grep Mounts\n\n# Verify permissions\nls -la exercise_folder/\n\n# Run with explicit mount\ndocker run -v $(pwd):/home/jovyan image_name",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-in-research",
    "href": "pages/docker.html#docker-in-research",
    "title": "Introduction to Docker",
    "section": "Docker in Research",
    "text": "Docker in Research\n\nReproducible Research\nDocker ensures your research is reproducible:\n# Reproducible analysis environment\nFROM rocker/tidyverse:4.2.0\n\n# Install specific package versions\nRUN R -e \"install.packages('ggplot2', version='3.4.0')\"\n\n# Copy analysis scripts\nCOPY analysis.R /home/rstudio/\n\n# Document environment\nCOPY README.md /home/rstudio/\n\n\nSharing Research\n# Save image to file\ndocker save my-research &gt; research-env.tar\n\n# Load on another computer\ndocker load &lt; research-env.tar\n\n# Or push to registry\ndocker tag my-research username/research:v1\ndocker push username/research:v1",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#advanced-docker-topics",
    "href": "pages/docker.html#advanced-docker-topics",
    "title": "Introduction to Docker",
    "section": "Advanced Docker Topics",
    "text": "Advanced Docker Topics\n\nMulti-Stage Builds\nOptimize image size:\n# Build stage\nFROM python:3.10 AS builder\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt\n\n# Runtime stage\nFROM python:3.10-slim\nWORKDIR /app\nCOPY --from=builder /wheels /wheels\nRUN pip install --no-cache /wheels/*\nCOPY . .\nCMD [\"python\", \"app.py\"]\n\n\nDocker Networks\nConnect containers:\n# Create network\ndocker network create mynet\n\n# Run containers on network\ndocker run --network mynet --name db postgres\ndocker run --network mynet --name app my-app\n\n# Containers can now reach each other by name\n\n\nDocker Volumes\nPersist data:\n# Create named volume\ndocker volume create mydata\n\n# Use volume\ndocker run -v mydata:/data my-app\n\n# Backup volume\ndocker run --rm -v mydata:/source -v $(pwd):/backup \\\n  alpine tar czf /backup/backup.tar.gz -C /source .",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#docker-security",
    "href": "pages/docker.html#docker-security",
    "title": "Introduction to Docker",
    "section": "Docker Security",
    "text": "Docker Security\n\nSecurity Best Practices\n\nKeep Docker Updated: Regular security patches\nScan Images: Use docker scan image_name\nDon’t Run as Root: Use USER directive in Dockerfile\nLimit Resources: Set memory and CPU limits\nUse Official Images: Verified and maintained\nSign Images: Docker Content Trust\n\n\n\nSecurity Scanning\n# Scan for vulnerabilities\ndocker scan my-image\n\n# Check image layers\ndocker history my-image\n\n# Inspect image\ndocker inspect my-image",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#quick-reference",
    "href": "pages/docker.html#quick-reference",
    "title": "Introduction to Docker",
    "section": "Quick Reference",
    "text": "Quick Reference\n\nEssential Commands\n\n\n\nCommand\nPurpose\n\n\n\n\ndocker run image\nRun container from image\n\n\ndocker ps\nList running containers\n\n\ndocker images\nList local images\n\n\ndocker stop container\nStop container\n\n\ndocker rm container\nRemove container\n\n\ndocker rmi image\nRemove image\n\n\ndocker logs container\nView container logs\n\n\ndocker exec -it container bash\nEnter running container\n\n\ndocker build -t name .\nBuild image from Dockerfile\n\n\ndocker-compose up\nStart services\n\n\n\n\n\nUseful Flags\n\n\n\nFlag\nPurpose\n\n\n\n\n-d\nRun in background (detached)\n\n\n-it\nInteractive terminal\n\n\n-p 8080:80\nMap ports (host:container)\n\n\n-v /path:/path\nMount volume\n\n\n--rm\nRemove container after exit\n\n\n--name myname\nName container\n\n\n-e VAR=value\nSet environment variable",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#resources",
    "href": "pages/docker.html#resources",
    "title": "Introduction to Docker",
    "section": "Resources",
    "text": "Resources\n\nDocumentation\n\nDocker Docs\nDocker Hub\nDocker Compose\n\n\n\nLearning\n\nDocker 101 Tutorial\nPlay with Docker\nDocker for Data Science",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/docker.html#summary",
    "href": "pages/docker.html#summary",
    "title": "Introduction to Docker",
    "section": "Summary",
    "text": "Summary\nDocker revolutionizes software deployment by: - Ensuring Consistency: Same environment everywhere - Simplifying Setup: One command to run complex stacks - Enabling Isolation: No conflicts between projects - Supporting Reproducibility: Perfect for research and education\nFor Franklin users, Docker works invisibly to provide a consistent, reliable environment for all exercises. While you don’t need to be a Docker expert, understanding the basics helps you troubleshoot issues and leverage Docker for your own projects beyond Franklin.",
    "crumbs": [
      "Reference",
      "Introduction to Docker"
    ]
  },
  {
    "objectID": "pages/exercise_workflow.html",
    "href": "pages/exercise_workflow.html",
    "title": "Exercise Development Workflow",
    "section": "",
    "text": "This guide walks through the complete process of creating a Franklin exercise, from initial setup to final publication. We’ll create a real data analysis exercise as our example, showing best practices and advanced techniques."
  },
  {
    "objectID": "pages/exercise_workflow.html#overview",
    "href": "pages/exercise_workflow.html#overview",
    "title": "Exercise Development Workflow",
    "section": "Overview",
    "text": "Overview\nCreating a Franklin exercise involves: 1. Initial setup and repository creation 2. Developing content in notebooks 3. Managing dependencies 4. Testing and validation 5. Publishing for student use\nWe’ll explore three development approaches: - JupyterLab (beginner-friendly) - VSCode with DevContainers (advanced) - Hybrid workflow (best of both)"
  },
  {
    "objectID": "pages/exercise_workflow.html#example-exercise-data-analysis-with-penguins",
    "href": "pages/exercise_workflow.html#example-exercise-data-analysis-with-penguins",
    "title": "Exercise Development Workflow",
    "section": "Example Exercise: Data Analysis with Penguins",
    "text": "Example Exercise: Data Analysis with Penguins\nWe’ll create an exercise teaching data analysis using the Palmer Penguins dataset. Students will learn data loading, exploration, visualization, and basic statistics."
  },
  {
    "objectID": "pages/exercise_workflow.html#step-1-create-the-exercise-repository",
    "href": "pages/exercise_workflow.html#step-1-create-the-exercise-repository",
    "title": "Exercise Development Workflow",
    "section": "Step 1: Create the Exercise Repository",
    "text": "Step 1: Create the Exercise Repository\n\nInitialize the Exercise\nStart by creating a new exercise repository:\nfranklin exercise new\nInteractive selections: 1. Choose course: “Introduction to Data Science” 2. Enter name: penguins-analysis 3. Select template: “Standard”\nThe command creates:\npenguins-analysis/\n├── exercise.ipynb       # Main notebook\n├── Dockerfile           # Container configuration\n├── pixi.toml           # Dependencies\n├── README.md           # Student instructions\n├── .gitlab-ci.yml      # CI/CD pipeline\n└── tests/              # Test directory\n\n\nConfigure Repository Settings\nFranklin opens the GitLab settings page. Complete these steps:\n\nSet Visibility: Change to “Public” under General → Visibility\nAdd Description: “Analyzing Palmer Penguins Dataset”\nConfigure CI/CD Variables (if needed):\n\nREGISTRY_USER: Your GitLab username\nREGISTRY_PASSWORD: Your access token\n\n\n\n\nClone Locally\nClone the repository to start development:\nfranklin exercise clone\n# Select: Introduction to Data Science → penguins-analysis\ncd penguins-analysis"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-2-develop-content-with-jupyterlab",
    "href": "pages/exercise_workflow.html#step-2-develop-content-with-jupyterlab",
    "title": "Exercise Development Workflow",
    "section": "Step 2: Develop Content with JupyterLab",
    "text": "Step 2: Develop Content with JupyterLab\n\nLaunch Development Environment\nUse Franklin’s automated workflow for live development:\nfranklin exercise edit\nThis: - Builds a Docker container with dependencies - Launches JupyterLab - Watches for file changes - Auto-saves to Git\n\n\nStructure the Exercise Notebook\nOpen exercise.ipynb and structure it with clear sections:\n# Cell 1: Title and Introduction (Markdown)\n\"\"\"\n# Analyzing Palmer Penguins Dataset\n\nIn this exercise, you'll explore a dataset about penguins in Antarctica.\nYou'll learn to:\n- Load and inspect data\n- Create visualizations\n- Calculate statistics\n- Draw conclusions\n\n## Learning Objectives\nBy the end of this exercise, you will be able to:\n1. Load data using pandas\n2. Explore data with descriptive statistics\n3. Create meaningful visualizations\n4. Interpret results\n\"\"\"\n\n# Cell 2: Setup and Imports (Code)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure visualization defaults\nsns.set_theme(style=\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"Libraries loaded successfully!\")\n\n# Cell 3: Load Data (Code)\n# Load the penguins dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\nprint(f\"Dataset loaded: {penguins.shape[0]} penguins, {penguins.shape[1]} features\")\npenguins.head()\n\n\nAdd Student Tasks\nCreate cells with clear TODO markers:\n# Cell 4: Data Exploration Task (Markdown)\n\"\"\"\n## Task 1: Data Exploration\n\nExplore the dataset structure:\n1. Display basic information about the dataset\n2. Check for missing values\n3. Show summary statistics\n\"\"\"\n\n# Cell 5: Student Code Cell (Code)\n# TODO: Display information about the dataset\n# Hint: Use penguins.info()\n\n\n# TODO: Check for missing values\n# Hint: Use penguins.isnull().sum()\n\n\n# TODO: Show summary statistics\n# Hint: Use penguins.describe()\n\n\nProvide Examples and Scaffolding\nInclude worked examples before tasks:\n# Cell 6: Visualization Example (Code)\n# Example: Creating a scatter plot\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='flipper_length_mm',\n    y='body_mass_g',\n    hue='species',\n    style='sex',\n    s=100\n)\nplt.title('Penguin Body Mass vs Flipper Length')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Body Mass (g)')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n# Cell 7: Student Visualization Task (Markdown)\n\"\"\"\n## Task 2: Create Your Own Visualization\n\nCreate a plot showing the relationship between bill length and bill depth,\ncolored by species.\n\"\"\"\n\n# Cell 8: Student Code Cell (Code)\n# TODO: Create a scatter plot of bill_length_mm vs bill_depth_mm\n# Color points by species\n# Add appropriate title and labels\n\n\nAdd Interactive Elements\nUse widgets for exploration:\n# Cell 9: Interactive Widget (Code)\nfrom ipywidgets import interact, widgets\n\n@interact(\n    species=widgets.Dropdown(\n        options=['All'] + list(penguins['species'].unique()),\n        value='All',\n        description='Species:'\n    )\n)\ndef plot_distribution(species):\n    if species == 'All':\n        data = penguins\n    else:\n        data = penguins[penguins['species'] == species]\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # Histogram\n    axes[0].hist(data['body_mass_g'].dropna(), bins=20, edgecolor='black')\n    axes[0].set_xlabel('Body Mass (g)')\n    axes[0].set_ylabel('Count')\n    axes[0].set_title(f'Body Mass Distribution - {species}')\n    \n    # Box plot\n    data.boxplot(column='body_mass_g', by='sex', ax=axes[1])\n    axes[1].set_xlabel('Sex')\n    axes[1].set_ylabel('Body Mass (g)')\n    axes[1].set_title(f'Body Mass by Sex - {species}')\n    plt.suptitle('')  # Remove default title\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-3-using-magic-commands",
    "href": "pages/exercise_workflow.html#step-3-using-magic-commands",
    "title": "Exercise Development Workflow",
    "section": "Step 3: Using Magic Commands",
    "text": "Step 3: Using Magic Commands\nFranklin supports Jupyter magic commands for enhanced functionality.\n\nPackage Management Magic\n# Cell: Install additional packages (Code)\n# Install packages not in base image\n%pip install -q plotly\n\n# For conda packages\n%conda install -y -q scikit-learn\n\n# Reload modules after installation\n%load_ext autoreload\n%autoreload 2\n\n\nSystem Commands\n# Cell: System information (Code)\n# Check Python version\n!python --version\n\n# List files in current directory\n!ls -la\n\n# Check memory usage\n!free -h\n\n# Download data files\n!wget -q https://example.com/data.csv -O data/penguins_extended.csv\n\n\nTiming and Profiling\n# Cell: Performance testing (Code)\n# Time a single statement\n%timeit penguins.groupby('species')['body_mass_g'].mean()\n\n# Time entire cell\n%%time\nresult = penguins.groupby(['species', 'island']).agg({\n    'body_mass_g': ['mean', 'std'],\n    'flipper_length_mm': ['mean', 'std']\n})\nprint(result)\n\n# Profile memory usage\n%load_ext memory_profiler\n%memit penguins.describe()\n\n\nDisplay Enhancements\n# Cell: Rich display options (Code)\nfrom IPython.display import display, HTML, Markdown, Image\n\n# Display formatted markdown\ndisplay(Markdown(\"\"\"\n### Summary Statistics\n\nThe dataset contains **{}** penguins from **{}** species.\n\"\"\".format(len(penguins), penguins['species'].nunique())))\n\n# Display HTML table with styling\nstyled = penguins.head().style.highlight_max(axis=0)\ndisplay(styled)\n\n# Display external images\ndisplay(Image(url='https://example.com/penguin.jpg', width=400))"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-4-managing-dependencies",
    "href": "pages/exercise_workflow.html#step-4-managing-dependencies",
    "title": "Exercise Development Workflow",
    "section": "Step 4: Managing Dependencies",
    "text": "Step 4: Managing Dependencies\n\nAutomatic Dependency Detection\nFranklin scans notebooks for imports and updates pixi.toml:\n# pixi.toml - automatically updated\n[project]\nname = \"penguins-analysis\"\nchannels = [\"conda-forge\"]\nplatforms = [\"linux-64\", \"osx-64\", \"osx-arm64\", \"win-64\"]\n\n[dependencies]\npython = \"3.11.*\"\npandas = \"&gt;=2.0\"\nnumpy = \"&gt;=1.24\"\nmatplotlib = \"&gt;=3.7\"\nseaborn = \"&gt;=0.12\"\njupyter = \"*\"\nipywidgets = \"&gt;=8.0\"\n\n[pypi-dependencies]\nplotly = \"*\"\n\n\nManual Dependency Management\nAdd specific versions or additional packages:\n# Add a package with version constraint\npixi add \"scikit-learn&gt;=1.3\"\n\n# Add from PyPI\npixi add --pypi pandas-profiling\n\n# Add development dependencies\npixi add --feature test pytest nbval\n\n# Add system dependencies\npixi add gcc cmake\n\n\nDependency Best Practices\n\nPin major versions for stability:\npandas = \"2.0.*\"  # Allow patch updates only\nGroup related packages:\n[feature.viz]\ndependencies = { matplotlib = \"*\", seaborn = \"*\", plotly = \"*\" }\n\n[feature.ml]\ndependencies = { scikit-learn = \"*\", xgboost = \"*\" }\nDocument special requirements:\n# In notebook\n# Note: This exercise requires plotly for interactive plots\n# It will be installed automatically\nimport plotly.express as px"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-5-testing-the-exercise",
    "href": "pages/exercise_workflow.html#step-5-testing-the-exercise",
    "title": "Exercise Development Workflow",
    "section": "Step 5: Testing the Exercise",
    "text": "Step 5: Testing the Exercise\n\nNotebook Validation Tests\nCreate tests/test_notebook.py:\nimport nbformat\nfrom nbconvert.preprocessors import ExecutePreprocessor\nimport pytest\nimport os\n\ndef test_notebook_runs():\n    \"\"\"Test that the exercise notebook executes without errors.\"\"\"\n    notebook_path = \"exercise.ipynb\"\n    \n    with open(notebook_path) as f:\n        nb = nbformat.read(f, as_version=4)\n    \n    # Remove solution cells for testing\n    nb.cells = [cell for cell in nb.cells \n                if 'solution' not in cell.metadata.get('tags', [])]\n    \n    ep = ExecutePreprocessor(timeout=60, kernel_name='python3')\n    ep.preprocess(nb, {'metadata': {'path': './'}})\n    \n    print(\"✓ Notebook executed successfully\")\n\ndef test_required_imports():\n    \"\"\"Test that all required packages can be imported.\"\"\"\n    required = ['pandas', 'numpy', 'matplotlib', 'seaborn']\n    \n    for package in required:\n        try:\n            __import__(package)\n            print(f\"✓ {package} imported successfully\")\n        except ImportError:\n            pytest.fail(f\"Failed to import {package}\")\n\ndef test_data_loading():\n    \"\"\"Test that data can be loaded.\"\"\"\n    import pandas as pd\n    \n    url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n    df = pd.read_csv(url)\n    \n    assert len(df) &gt; 0, \"Dataset is empty\"\n    assert 'species' in df.columns, \"Missing species column\"\n    print(f\"✓ Data loaded: {len(df)} rows\")\n\ndef test_expected_outputs():\n    \"\"\"Test that notebook produces expected outputs.\"\"\"\n    # This would check for specific plots, tables, etc.\n    # Implementation depends on exercise requirements\n    pass\n\n\nRun Tests Locally\n# Run all tests\nfranklin exercise test\n\n# Run specific test\nfranklin exercise test --notebook exercise.ipynb\n\n# Verbose output\nfranklin exercise test --verbose\n\n\nContinuous Integration Testing\nThe .gitlab-ci.yml automatically tests on push:\nstages:\n  - test\n  - build\n  - deploy\n\ntest:\n  stage: test\n  image: mambaforge:latest\n  script:\n    - pixi install\n    - pixi run pytest tests/\n    - pixi run python -m nbval exercise.ipynb\n  artifacts:\n    reports:\n      junit: test-results.xml\n\nbuild:\n  stage: build\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE .\n  only:\n    - main\n\ndeploy:\n  stage: deploy\n  script:\n    - docker push $CI_REGISTRY_IMAGE:latest\n  only:\n    - main"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-6-vscode-development-with-devcontainers",
    "href": "pages/exercise_workflow.html#step-6-vscode-development-with-devcontainers",
    "title": "Exercise Development Workflow",
    "section": "Step 6: VSCode Development with DevContainers",
    "text": "Step 6: VSCode Development with DevContainers\n\nWhy Use VSCode?\nVSCode with DevContainers offers: - Full IDE features (IntelliSense, debugging) - Git integration - Extension ecosystem - Consistent environment - Better for complex exercises\n\n\nSetup DevContainer\nCreate .devcontainer/devcontainer.json:\n{\n  \"name\": \"Franklin Exercise Development\",\n  \"build\": {\n    \"dockerfile\": \"../Dockerfile\",\n    \"context\": \"..\"\n  },\n  \"customizations\": {\n    \"vscode\": {\n      \"extensions\": [\n        \"ms-python.python\",\n        \"ms-python.vscode-pylance\",\n        \"ms-toolsai.jupyter\",\n        \"ms-toolsai.jupyter-keymap\",\n        \"ms-toolsai.jupyter-renderers\",\n        \"ms-vscode.live-server\",\n        \"yzhang.markdown-all-in-one\",\n        \"github.copilot\"\n      ],\n      \"settings\": {\n        \"python.defaultInterpreterPath\": \"/opt/conda/bin/python\",\n        \"python.linting.enabled\": true,\n        \"python.linting.pylintEnabled\": true,\n        \"python.formatting.provider\": \"black\",\n        \"python.testing.pytestEnabled\": true,\n        \"python.testing.pytestArgs\": [\"tests\"],\n        \"jupyter.widgetScriptSources\": [\"jsdelivr.com\", \"unpkg.com\"],\n        \"terminal.integrated.defaultProfile.linux\": \"bash\"\n      }\n    }\n  },\n  \"forwardPorts\": [8888],\n  \"postCreateCommand\": \"pixi install && pip install -e .\",\n  \"remoteUser\": \"jovyan\",\n  \"features\": {\n    \"ghcr.io/devcontainers/features/git:1\": {},\n    \"ghcr.io/devcontainers/features/github-cli:1\": {}\n  }\n}\n\n\nOpen in VSCode\n\nInstall VSCode and Remote-Containers extension\nOpen the exercise folder in VSCode\nCommand Palette: “Remote-Containers: Reopen in Container”\nWait for container to build and start\n\n\n\nVSCode Notebook Features\n\nCell Execution and Debugging\n# Set breakpoint by clicking left of line number\ndef analyze_species(df, species_name):\n    \"\"\"Analyze a specific species.\"\"\"\n    species_data = df[df['species'] == species_name]\n    \n    stats = {\n        'count': len(species_data),\n        'mean_mass': species_data['body_mass_g'].mean(),\n        'mean_flipper': species_data['flipper_length_mm'].mean()\n    }\n    \n    return stats  # Breakpoint here\n\n# Debug this cell\nresult = analyze_species(penguins, 'Adelie')\nprint(result)\n\n\nVariable Explorer\n\nView all variables in the current kernel\nInspect DataFrames in table view\nPlot variables directly\nExport data\n\n\n\nInteractive Window\n# Use # %% to create code cells in .py files\n# %% [markdown]\n# # Data Analysis Script\n# This can be run as a notebook or script\n\n# %%\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# %%\n# Load and process data\ndata = pd.read_csv('data.csv')\nprocessed = data.groupby('category').mean()\n\n# %%\n# Create visualization\nprocessed.plot(kind='bar')\nplt.show()\n\n\n\nVSCode Testing Integration\n\nConfigure Testing\nIn settings.json:\n{\n  \"python.testing.pytestEnabled\": true,\n  \"python.testing.pytestArgs\": [\n    \"tests\",\n    \"--cov=.\",\n    \"--cov-report=html\"\n  ],\n  \"python.testing.autoTestDiscoverOnSaveEnabled\": true\n}\n\n\nRun Tests from VSCode\n\nClick test icons in gutter\nUse Testing sidebar\nView test output in terminal\nDebug failed tests\n\n\n\n\nGit Integration\nVSCode provides excellent Git support:\n\nSource Control panel: Stage, commit, push\nGitLens extension: Blame, history, comparisons\nMerge conflicts: Visual resolution\nBranch management: Create, switch, merge"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-7-creating-solution-notebooks",
    "href": "pages/exercise_workflow.html#step-7-creating-solution-notebooks",
    "title": "Exercise Development Workflow",
    "section": "Step 7: Creating Solution Notebooks",
    "text": "Step 7: Creating Solution Notebooks\n\nSeparate Solutions\nCreate solutions/exercise_solution.ipynb:\n# Complete solution with all code filled in\n# This file is excluded from student downloads\n\n# Task 1 Solution\npenguins.info()\nprint(\"\\nMissing values:\")\nprint(penguins.isnull().sum())\nprint(\"\\nSummary statistics:\")\nprint(penguins.describe())\n\n# Task 2 Solution\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    hue='species',\n    s=100\n)\nplt.title('Penguin Bill Dimensions by Species')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\nplt.legend(title='Species')\nplt.tight_layout()\nplt.show()\n\n\nInline Solutions (Hidden)\nUse cell metadata to hide solutions:\n# In exercise.ipynb\n# Cell metadata: {\"tags\": [\"solution\"]}\n\n# SOLUTION - This cell is removed for students\ndef calculate_statistics(df):\n    return df.groupby('species').agg({\n        'body_mass_g': ['mean', 'std'],\n        'flipper_length_mm': ['mean', 'std']\n    })\n\nresult = calculate_statistics(penguins)\nprint(result)"
  },
  {
    "objectID": "pages/exercise_workflow.html#step-8-publishing-the-exercise",
    "href": "pages/exercise_workflow.html#step-8-publishing-the-exercise",
    "title": "Exercise Development Workflow",
    "section": "Step 8: Publishing the Exercise",
    "text": "Step 8: Publishing the Exercise\n\nFinal Checklist\nBefore publishing, verify:\n\nNotebook runs without errors\nAll TODOs have corresponding solutions\nDependencies are properly specified\nTests pass locally\nREADME has clear instructions\nRepository is public\nCI/CD pipeline succeeds\n\n\n\nBuild and Publish\n# Run final tests\nfranklin exercise test\n\n# Build Docker image\nfranklin exercise build\n\n# Publish to registry\nfranklin exercise publish\n\n\nTest Student Experience\n# In a different directory\ncd /tmp\n\n# Test as student would\nfranklin download\n# Select: Introduction to Data Science → penguins-analysis\n\ncd penguins-analysis\nfranklin jupyter\n\n# Verify notebook opens and runs"
  },
  {
    "objectID": "pages/exercise_workflow.html#advanced-techniques",
    "href": "pages/exercise_workflow.html#advanced-techniques",
    "title": "Exercise Development Workflow",
    "section": "Advanced Techniques",
    "text": "Advanced Techniques\n\nMulti-Notebook Exercises\nCreate exercises with multiple notebooks:\nexercise/\n├── 01_data_loading.ipynb\n├── 02_exploration.ipynb\n├── 03_visualization.ipynb\n├── 04_modeling.ipynb\n└── utils.py  # Shared functions\nLink notebooks:\n# In 01_data_loading.ipynb\n# Save processed data\npenguins_clean.to_csv('data/penguins_clean.csv', index=False)\nprint(\"Data saved to data/penguins_clean.csv\")\nprint(\"Continue with 02_exploration.ipynb\")\n\n# In 02_exploration.ipynb\n# Load processed data\npenguins_clean = pd.read_csv('data/penguins_clean.csv')\nprint(\"Data loaded from previous notebook\")\n\n\nProgressive Disclosure\nReveal complexity gradually:\n# Basic task\n\"\"\"\n## Level 1: Simple Visualization\nCreate a bar chart showing the count of each species.\n\"\"\"\n\n# Intermediate task\n\"\"\"\n## Level 2: Grouped Visualization\nCreate a grouped bar chart showing counts by species and island.\n\"\"\"\n\n# Advanced task\n\"\"\"\n## Level 3: Complex Analysis\nCreate a multi-panel figure with:\n- Species distribution by island\n- Correlation heatmap\n- Statistical test results\n\"\"\"\n\n\nAdaptive Difficulty\nUse widgets for difficulty selection:\nfrom ipywidgets import interact, widgets\n\ndifficulty = widgets.RadioButtons(\n    options=['Beginner', 'Intermediate', 'Advanced'],\n    value='Beginner',\n    description='Difficulty:'\n)\n\n@interact(level=difficulty)\ndef show_task(level):\n    tasks = {\n        'Beginner': \"Calculate the mean body mass for all penguins\",\n        'Intermediate': \"Calculate mean body mass by species\",\n        'Advanced': \"Perform ANOVA test on body mass across species\"\n    }\n    print(f\"Task: {tasks[level]}\")\n\n\nAutomated Feedback\nProvide immediate validation:\ndef check_answer(student_result, expected):\n    \"\"\"Check student answer and provide feedback.\"\"\"\n    if student_result is None:\n        return \"⚠️ No answer provided yet\"\n    \n    if abs(student_result - expected) &lt; 0.01:\n        return \"✅ Correct! Well done!\"\n    elif abs(student_result - expected) &lt; 1:\n        return \"⚠️ Close! Check your calculation\"\n    else:\n        return \"❌ Not quite right. Try again!\"\n\n# Student calculates mean\nstudent_mean = None  # TODO: Calculate mean body mass\n\n# Check answer\nexpected_mean = penguins['body_mass_g'].mean()\nprint(check_answer(student_mean, expected_mean))"
  },
  {
    "objectID": "pages/exercise_workflow.html#best-practices-summary",
    "href": "pages/exercise_workflow.html#best-practices-summary",
    "title": "Exercise Development Workflow",
    "section": "Best Practices Summary",
    "text": "Best Practices Summary\n\nExercise Design\n\nClear Learning Objectives: State what students will learn\nIncremental Complexity: Build from simple to complex\nFrequent Checkpoints: Let students verify progress\nRich Feedback: Provide hints and validation\nReal-World Relevance: Use meaningful datasets\n\n\n\nCode Quality\n\nConsistent Style: Use black formatter\nType Hints: Add where helpful\nDocstrings: Document functions\nError Handling: Graceful failures\nPerformance: Consider student hardware\n\n\n\nTesting Strategy\n\nSmoke Tests: Notebook runs\nUnit Tests: Functions work\nIntegration Tests: Full workflow\nVisual Tests: Plots generated\nStudent Tests: Exercises completable\n\n\n\nDocumentation\n\nREADME: Clear setup instructions\nComments: Explain complex code\nMarkdown: Rich explanations\nExamples: Show expected output\nResources: Link to references"
  },
  {
    "objectID": "pages/exercise_workflow.html#troubleshooting-common-issues",
    "href": "pages/exercise_workflow.html#troubleshooting-common-issues",
    "title": "Exercise Development Workflow",
    "section": "Troubleshooting Common Issues",
    "text": "Troubleshooting Common Issues\n\nImport Errors\nProblem: Package not found\nModuleNotFoundError: No module named 'plotly'\nSolution: Add to pixi.toml and rebuild\npixi add --pypi plotly\nfranklin exercise build --no-cache\n\n\nKernel Crashes\nProblem: Kernel dies on large computations\nSolution: Increase memory limits in Dockerfile\nENV JUPYTER_MEMORY_LIMIT=4g\n\n\nSlow Performance\nProblem: Notebook takes too long to run\nSolutions: 1. Cache downloaded data 2. Use smaller sample datasets 3. Optimize algorithms 4. Add progress bars\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\n# Shows progress bar\nresult = penguins.progress_apply(complex_function, axis=1)\n\n\nGit Conflicts\nProblem: Merge conflicts in notebooks\nSolution: Use nbdime for better diffs\npip install nbdime\nnbdime config-git --enable\ngit mergetool  # Visual merge tool"
  },
  {
    "objectID": "pages/exercise_workflow.html#conclusion",
    "href": "pages/exercise_workflow.html#conclusion",
    "title": "Exercise Development Workflow",
    "section": "Conclusion",
    "text": "Conclusion\nThis workflow provides a complete approach to creating Franklin exercises. Key takeaways:\n\nStart with clear learning objectives\nUse appropriate development tools (JupyterLab vs VSCode)\nTest thoroughly at each stage\nLeverage automation (dependency detection, CI/CD)\nConsider the student experience throughout\n\nRemember: Great exercises are iterative. Collect feedback, monitor student performance, and continuously improve your content."
  },
  {
    "objectID": "pages/full_commands_admin.html",
    "href": "pages/full_commands_admin.html",
    "title": "Administrator Commands",
    "section": "",
    "text": "The franklin-admin plugin provides administrative tools for managing users, permissions, and course infrastructure. This reference documents all administrator commands and workflows."
  },
  {
    "objectID": "pages/full_commands_admin.html#installation",
    "href": "pages/full_commands_admin.html#installation",
    "title": "Administrator Commands",
    "section": "Installation",
    "text": "Installation\nAdministrator commands require the franklin-admin plugin:\n\nUsing Conda\nconda install -c conda-forge -c munch-group franklin-admin\n\n\nUsing Pixi\npixi global install --channel conda-forge --channel munch-group franklin-admin\nThe admin plugin automatically installs both franklin and franklin-educator as dependencies."
  },
  {
    "objectID": "pages/full_commands_admin.html#prerequisites",
    "href": "pages/full_commands_admin.html#prerequisites",
    "title": "Administrator Commands",
    "section": "Prerequisites",
    "text": "Prerequisites\nAdministrator commands require: - GitLab account with Owner or Maintainer role in Franklin group - API token with full access permissions - SSH key configured for GitLab - Secure password for token encryption"
  },
  {
    "objectID": "pages/full_commands_admin.html#overview",
    "href": "pages/full_commands_admin.html#overview",
    "title": "Administrator Commands",
    "section": "Overview",
    "text": "Overview\nAdmin commands are organized into three main groups:\nfranklin admin [SUBCOMMAND]     # User management\nfranklin password [SUBCOMMAND]  # Password management\nfranklin token [SUBCOMMAND]     # API token management"
  },
  {
    "objectID": "pages/full_commands_admin.html#user-management",
    "href": "pages/full_commands_admin.html#user-management",
    "title": "Administrator Commands",
    "section": "User Management",
    "text": "User Management"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-admin",
    "href": "pages/full_commands_admin.html#franklin-admin",
    "title": "Administrator Commands",
    "section": "franklin admin",
    "text": "franklin admin\nParent command for user and permission management.\n\nUsage\nfranklin admin [OPTIONS] COMMAND [ARGS]\n\n\nSubcommands\n\nusers: List and search users\ngroups: Manage GitLab groups\npermissions: Set user permissions\nfinger: Find users by name\n\n\n\nOptions\n\n--help: Show help message"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-admin-users",
    "href": "pages/full_commands_admin.html#franklin-admin-users",
    "title": "Administrator Commands",
    "section": "franklin admin users",
    "text": "franklin admin users\nManages GitLab users and their roles.\n\nUsage\nfranklin admin users [OPTIONS] COMMAND\n\n\nSubcommands\n\n\nfranklin admin users list\nLists all users in a GitLab group.\nfranklin admin users list [OPTIONS]\nOptions: - --group GROUP_NAME: Specify group (default: franklin) - --role ROLE: Filter by role (Guest/Reporter/Developer/Maintainer/Owner) - --format FORMAT: Output format (table/json/csv)\nExample:\n# List all users in franklin group\nfranklin admin users list\n\n# List only maintainers in a course group\nfranklin admin users list --group intro-bio --role Maintainer\nOutput:\nUSERNAME        NAME                ROLE        EMAIL\njohndoe         John Doe           Owner       john@au.dk\njanedoe         Jane Doe           Maintainer  jane@au.dk\nstudent1        Alice Student      Reporter    alice@au.dk\n\n\nfranklin admin users add\nAdds a user to a GitLab group with specific role.\nfranklin admin users add USERNAME --group GROUP --role ROLE\nOptions: - --group GROUP_NAME: Target group (required) - --role ROLE: Permission level (required) - --expires-at DATE: Access expiration date (YYYY-MM-DD)\nExample:\n# Add TA as Developer to course group\nfranklin admin users add ta_username --group intro-bio --role Developer\n\n# Add guest access expiring at semester end\nfranklin admin users add guest_user --group franklin --role Guest --expires-at 2024-12-31\n\n\nfranklin admin users remove\nRemoves a user from a GitLab group.\nfranklin admin users remove USERNAME --group GROUP\nOptions: - --group GROUP_NAME: Group to remove from (required) - --confirm: Skip confirmation prompt\nExample:\nfranklin admin users remove old_ta --group intro-bio --confirm\n\n\nfranklin admin users update\nUpdates a user’s role in a group.\nfranklin admin users update USERNAME --group GROUP --role NEW_ROLE\nExample:\n# Promote TA to Maintainer\nfranklin admin users update ta_username --group intro-bio --role Maintainer\n\n# Downgrade to Reporter\nfranklin admin users update student1 --group franklin --role Reporter"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-admin-groups",
    "href": "pages/full_commands_admin.html#franklin-admin-groups",
    "title": "Administrator Commands",
    "section": "franklin admin groups",
    "text": "franklin admin groups\nManages GitLab groups and subgroups.\n\nUsage\nfranklin admin groups [OPTIONS] COMMAND\n\n\nSubcommands\n\n\nfranklin admin groups create\nCreates a new course subgroup.\nfranklin admin groups create GROUP_NAME [OPTIONS]\nOptions: - --parent PARENT_GROUP: Parent group (default: franklin) - --description TEXT: Group description - --visibility LEVEL: public/internal/private (default: private)\nExample:\n# Create new course group\nfranklin admin groups create molecular-biology \\\n  --description \"Molecular Biology Fall 2024\" \\\n  --visibility private\n\n\nfranklin admin groups list\nLists all subgroups.\nfranklin admin groups list [OPTIONS]\nOptions: - --parent PARENT_GROUP: Parent group to list from - --details: Show detailed information\nOutput:\nGROUP PATH              VISIBILITY  PROJECTS  MEMBERS\nfranklin/intro-bio      private     12        25\nfranklin/chemistry      private     8         18\nfranklin/data-science   public      15        32\n\n\nfranklin admin groups settings\nOpens group settings in browser.\nfranklin admin groups settings GROUP_NAME"
  },
  {
    "objectID": "pages/full_commands_admin.html#permission-management",
    "href": "pages/full_commands_admin.html#permission-management",
    "title": "Administrator Commands",
    "section": "Permission Management",
    "text": "Permission Management"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-admin-permissions",
    "href": "pages/full_commands_admin.html#franklin-admin-permissions",
    "title": "Administrator Commands",
    "section": "franklin admin permissions",
    "text": "franklin admin permissions\nManages user permissions across courses.\n\nGitLab Permission Levels\n\n\n\n\n\n\n\n\n\n\n\n\nRole\nView Code\nPush Code\nMerge MR\nManage CI/CD\nDelete Project\nManage Members\n\n\n\n\nGuest\n❌\n❌\n❌\n❌\n❌\n❌\n\n\nReporter\n✅\n❌\n❌\n❌\n❌\n❌\n\n\nDeveloper\n✅\n✅\n❌\n✅\n❌\n❌\n\n\nMaintainer\n✅\n✅\n✅\n✅\n❌\n✅ (limited)\n\n\nOwner\n✅\n✅\n✅\n✅\n✅\n✅\n\n\n\n\n\nRole Recommendations\nCourse Coordinator: Owner of course subgroup - Can create/delete exercises - Manages course TAs - Full control over course content\nTeaching Assistant: Maintainer of course subgroup - Can merge student submissions - Manages exercise settings - Cannot delete course\nEducator (Other Courses): Reporter in main group - Can view exercises for reference - Cannot modify content\nStudent: Guest or no access - Can only see public repositories - Cannot push code\n\n\nBatch Permission Management\nfranklin admin permissions set-course-staff COURSE_NAME [OPTIONS]\nOptions: - --coordinator USERNAME: Set course coordinator (Owner) - --tas USERNAME1,USERNAME2: Add TAs (Maintainer) - --remove-old: Remove users not in new list\nExample:\n# Set up course staff for new semester\nfranklin admin permissions set-course-staff intro-bio \\\n  --coordinator prof_smith \\\n  --tas ta_jones,ta_williams,ta_brown \\\n  --remove-old"
  },
  {
    "objectID": "pages/full_commands_admin.html#token-management",
    "href": "pages/full_commands_admin.html#token-management",
    "title": "Administrator Commands",
    "section": "Token Management",
    "text": "Token Management"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-token",
    "href": "pages/full_commands_admin.html#franklin-token",
    "title": "Administrator Commands",
    "section": "franklin token",
    "text": "franklin token\nManages API tokens for GitLab access.\n\nUsage\nfranklin token [OPTIONS] COMMAND\n\n\nSubcommands\n\n\nfranklin token set\nStores an encrypted API token for a user.\nfranklin token set [OPTIONS]\nInteractive prompts: 1. Username 2. Password (for encryption) 3. API token (hidden input)\nProcess: - Token is encrypted with password - Stored in secure local storage - Never transmitted or logged\nExample:\nfranklin token set\n# Enter username: admin_user\n# Enter password: ********\n# Enter API token: ********\n✓ Token stored securely\n\n\nfranklin token get\nRetrieves and decrypts stored API token.\nfranklin token get [OPTIONS]\nInteractive prompts: 1. Username 2. Password (for decryption)\nOutput:\nStored personal access token: glpat-xxxxxxxxxxxxxxxxxxxx\nSecurity Note: Only display tokens in secure environments.\n\n\nfranklin token verify\nVerifies that stored token is valid.\nfranklin token verify [OPTIONS]\nOptions: - --user USERNAME: Specify user - --quiet: Only show success/failure\nOutput:\n✓ Token is valid\n  User: admin_user\n  Scopes: api, read_user, write_repository\n  Expires: 2024-12-31\n\n\nfranklin token rotate\nRotates (replaces) an API token.\nfranklin token rotate [OPTIONS]\nProcess: 1. Creates new token with same permissions 2. Updates stored encrypted token 3. Revokes old token"
  },
  {
    "objectID": "pages/full_commands_admin.html#password-management",
    "href": "pages/full_commands_admin.html#password-management",
    "title": "Administrator Commands",
    "section": "Password Management",
    "text": "Password Management"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-password",
    "href": "pages/full_commands_admin.html#franklin-password",
    "title": "Administrator Commands",
    "section": "franklin password",
    "text": "franklin password\nManages passwords for encrypted token storage.\n\nUsage\nfranklin password [OPTIONS] COMMAND\n\n\nSubcommands\n\n\nfranklin password set\nSets password for a user (requires admin token).\nfranklin password set USER PASSWORD [OPTIONS]\nOptions: - --admin ADMIN_USER: Admin username - --password ADMIN_PASS: Admin password\nUse case: Initial setup for new administrators\n\n\nfranklin password change\nChanges your own password.\nfranklin password change [OPTIONS]\nInteractive prompts: 1. Username 2. Current password 3. New password 4. Confirm new password\nProcess: - Verifies current password - Re-encrypts token with new password - Updates stored credentials\nExample:\nfranklin password change\n# Enter username: my_user\n# Enter current password: ********\n# Enter new password: ********\n# Confirm new password: ********\n✓ Password changed successfully"
  },
  {
    "objectID": "pages/full_commands_admin.html#user-discovery",
    "href": "pages/full_commands_admin.html#user-discovery",
    "title": "Administrator Commands",
    "section": "User Discovery",
    "text": "User Discovery"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-finger",
    "href": "pages/full_commands_admin.html#franklin-finger",
    "title": "Administrator Commands",
    "section": "franklin finger",
    "text": "franklin finger\nSearches for GitLab users by name or username.\n\nUsage\nfranklin finger SEARCH_TERMS [OPTIONS]\n\n\nOptions\n\n--user USERNAME: Your username for authentication\n--password PASSWORD: Your password\n--format FORMAT: Output format (table/json/csv)\n\n\n\nExamples\n# Search for user by name\nfranklin finger \"John Doe\"\n\n# Search by username pattern\nfranklin finger \"ta_*\"\n\n# Search with authentication\nfranklin finger \"Smith\" --user admin --password ********\n\n\nOutput\nUSERNAME        NAME                EMAIL           STATE\njdoe            John Doe           jdoe@au.dk      active\njsmith          Jane Smith         jsmith@au.dk    active\ntjsmith         Tom J Smith        tjs@au.dk       blocked"
  },
  {
    "objectID": "pages/full_commands_admin.html#bulk-operations",
    "href": "pages/full_commands_admin.html#bulk-operations",
    "title": "Administrator Commands",
    "section": "Bulk Operations",
    "text": "Bulk Operations"
  },
  {
    "objectID": "pages/full_commands_admin.html#franklin-admin-bulk",
    "href": "pages/full_commands_admin.html#franklin-admin-bulk",
    "title": "Administrator Commands",
    "section": "franklin admin bulk",
    "text": "franklin admin bulk\nPerforms bulk operations on users and permissions.\n\nImport Users from CSV\nfranklin admin bulk import-users FILE.csv [OPTIONS]\nCSV Format:\nusername,email,name,group,role\nstudent1,s1@au.dk,Alice Student,intro-bio,Reporter\nstudent2,s2@au.dk,Bob Student,intro-bio,Reporter\nta1,ta1@au.dk,Carol TA,intro-bio,Developer\nOptions: - --dry-run: Preview changes without applying - --skip-existing: Don’t update existing users - --notify: Send email invitations\n\n\nExport Users to CSV\nfranklin admin bulk export-users --group GROUP [OPTIONS]\nOptions: - --output FILE: Output filename (default: users.csv) - --include-tokens: Include API token status\n\n\nAudit Permissions\nfranklin admin bulk audit [OPTIONS]\nOptions: - --group GROUP: Audit specific group - --fix-issues: Automatically fix permission issues - --report FILE: Save audit report\nAudit checks: - Orphaned users (no group membership) - Excessive permissions - Expired access - Inactive users"
  },
  {
    "objectID": "pages/full_commands_admin.html#security-best-practices",
    "href": "pages/full_commands_admin.html#security-best-practices",
    "title": "Administrator Commands",
    "section": "Security Best Practices",
    "text": "Security Best Practices\n\nToken Security\n\nNever share API tokens - Treat like passwords\nUse token expiration - Set reasonable expiration dates\nRotate regularly - Change tokens periodically\nLimit scope - Only request needed permissions\nRevoke unused tokens - Clean up old tokens\n\n\n\nPassword Security\n\nUse strong passwords - Minimum 12 characters\nUnique passwords - Don’t reuse passwords\nChange regularly - Update every semester\nUse password manager - Store securely\nEnable 2FA - On GitLab account\n\n\n\nPermission Security\n\nPrinciple of least privilege - Minimum necessary access\nRegular audits - Review permissions each semester\nRemove old users - Clean up after course ends\nDocument changes - Keep permission change log\nUse groups - Manage permissions via groups, not individual"
  },
  {
    "objectID": "pages/full_commands_admin.html#automation-scripts",
    "href": "pages/full_commands_admin.html#automation-scripts",
    "title": "Administrator Commands",
    "section": "Automation Scripts",
    "text": "Automation Scripts\n\nSemester Setup Script\n#!/bin/bash\n# setup-semester.sh\n\n# Create course groups for new semester\nfranklin admin groups create bio-fall2024 --description \"Biology Fall 2024\"\nfranklin admin groups create chem-fall2024 --description \"Chemistry Fall 2024\"\n\n# Import users from registration\nfranklin admin bulk import-users fall2024-students.csv\n\n# Set up course coordinators\nfranklin admin users add prof_smith --group bio-fall2024 --role Owner\nfranklin admin users add prof_jones --group chem-fall2024 --role Owner\n\n# Add TAs\nfranklin admin bulk import-users fall2024-tas.csv\n\n# Audit and report\nfranklin admin bulk audit --report fall2024-setup.txt\n\n\nEnd of Semester Cleanup\n#!/bin/bash\n# cleanup-semester.sh\n\n# Export final user list for records\nfranklin admin bulk export-users --group bio-fall2024 --output bio-fall2024-final.csv\n\n# Archive course groups\nfranklin admin groups archive bio-fall2024\nfranklin admin groups archive chem-fall2024\n\n# Remove student access\nfranklin admin bulk remove-users fall2024-students.csv\n\n# Revoke temporary tokens\nfranklin token rotate --all-expired"
  },
  {
    "objectID": "pages/full_commands_admin.html#troubleshooting",
    "href": "pages/full_commands_admin.html#troubleshooting",
    "title": "Administrator Commands",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nCommon Issues\n\nAuthentication Failed\nProblem: “Invalid username or password”\n# Solution: Verify credentials\nfranklin token verify --user USERNAME\n\n# Reset if needed\nfranklin password change\n\n\nPermission Denied\nProblem: “You don’t have permission to perform this action”\n# Solution: Check your role\nfranklin admin users list --group GROUP | grep USERNAME\n\n# Request elevation from group owner\n\n\nToken Expired\nProblem: “401 Unauthorized”\n# Solution: Create new token in GitLab\n# Profile → Access Tokens → Create new token\n\n# Update stored token\nfranklin token set\n\n\nGroup Not Found\nProblem: “404 Group not found”\n# Solution: List available groups\nfranklin admin groups list\n\n# Check spelling and path\n\n\n\nDebug Mode\nEnable detailed logging:\nexport FRANKLIN_ADMIN_DEBUG=true\nfranklin admin users list\nShows: - API endpoints called - Request/response details - Permission checks - Error details"
  },
  {
    "objectID": "pages/full_commands_admin.html#api-token-scopes",
    "href": "pages/full_commands_admin.html#api-token-scopes",
    "title": "Administrator Commands",
    "section": "API Token Scopes",
    "text": "API Token Scopes\nWhen creating GitLab API tokens, use appropriate scopes:\n\nFor Administrators\nRequired scopes: - api: Full API access - read_user: Read user information - write_repository: Manage repositories - read_registry: Access container registry - write_registry: Push to registry\n\n\nFor Course Coordinators\nRequired scopes: - api: Full API access (limited by role) - read_user: Read user information - write_repository: Manage exercises\n\n\nFor Teaching Assistants\nRequired scopes: - read_api: Read-only API access - read_user: Read user information - read_repository: View exercises"
  },
  {
    "objectID": "pages/full_commands_admin.html#command-reference",
    "href": "pages/full_commands_admin.html#command-reference",
    "title": "Administrator Commands",
    "section": "Command Reference",
    "text": "Command Reference\n\nQuick Reference Table\n\n\n\n\n\n\n\n\nCommand\nPurpose\nCommon Usage\n\n\n\n\nadmin users list\nList group members\nfranklin admin users list --group intro-bio\n\n\nadmin users add\nAdd user to group\nfranklin admin users add USERNAME --group GROUP --role ROLE\n\n\nadmin groups create\nCreate course group\nfranklin admin groups create course-name\n\n\nadmin permissions\nManage permissions\nfranklin admin permissions set-course-staff COURSE\n\n\ntoken set\nStore API token\nfranklin token set\n\n\ntoken get\nRetrieve token\nfranklin token get\n\n\npassword change\nChange password\nfranklin password change\n\n\nfinger\nFind users\nfranklin finger \"NAME\"\n\n\nadmin bulk import\nImport users\nfranklin admin bulk import-users file.csv"
  },
  {
    "objectID": "pages/full_commands_admin.html#integration-with-other-plugins",
    "href": "pages/full_commands_admin.html#integration-with-other-plugins",
    "title": "Administrator Commands",
    "section": "Integration with Other Plugins",
    "text": "Integration with Other Plugins\n\nWith Franklin-Educator\nAdmins can assist educators:\n# Create course infrastructure\nfranklin admin groups create new-course\n\n# Set up educator access\nfranklin admin users add educator --group new-course --role Maintainer\n\n# Educator creates exercises\nfranklin exercise new  # Now works in new-course\n\n\nWith Core Franklin\nAdmins can test student experience:\n# Impersonate student view\nfranklin admin permissions simulate-student\n\n# Test as student would see\nfranklin download\nfranklin jupyter"
  },
  {
    "objectID": "pages/full_commands_admin.html#compliance-and-auditing",
    "href": "pages/full_commands_admin.html#compliance-and-auditing",
    "title": "Administrator Commands",
    "section": "Compliance and Auditing",
    "text": "Compliance and Auditing\n\nGDPR Compliance\nFor EU data protection:\n# Export user data\nfranklin admin users export --user USERNAME --full\n\n# Delete user data\nfranklin admin users delete --user USERNAME --purge\n\n# Anonymize old records\nfranklin admin bulk anonymize --older-than 2years\n\n\nAudit Logging\nTrack administrative actions:\n# Enable audit logging\nexport FRANKLIN_AUDIT_LOG=/var/log/franklin-audit.log\n\n# View recent actions\nfranklin admin audit-log --recent 100\n\n# Generate compliance report\nfranklin admin audit-log --report compliance-2024.pdf"
  },
  {
    "objectID": "pages/full_commands_admin.html#future-features",
    "href": "pages/full_commands_admin.html#future-features",
    "title": "Administrator Commands",
    "section": "Future Features",
    "text": "Future Features\nPlanned enhancements: - LDAP Integration: Sync with university directory - Automated Provisioning: Create courses from registration system - Role Templates: Predefined permission sets - Approval Workflows: Multi-step permission changes - Activity Monitoring: Track usage and access patterns"
  },
  {
    "objectID": "pages/full_commands_edu.html",
    "href": "pages/full_commands_edu.html",
    "title": "Educator Commands",
    "section": "",
    "text": "The franklin-educator plugin extends Franklin with commands for creating and managing exercises. This reference documents all educator-specific commands and workflows."
  },
  {
    "objectID": "pages/full_commands_edu.html#installation",
    "href": "pages/full_commands_edu.html#installation",
    "title": "Educator Commands",
    "section": "Installation",
    "text": "Installation\nBefore using educator commands, install the franklin-educator plugin:\n\nUsing Conda\nconda install -c conda-forge -c munch-group franklin-educator\n\n\nUsing Pixi\npixi global install --channel conda-forge --channel munch-group franklin-educator\nThe educator plugin automatically installs the base Franklin package as a dependency."
  },
  {
    "objectID": "pages/full_commands_edu.html#overview",
    "href": "pages/full_commands_edu.html#overview",
    "title": "Educator Commands",
    "section": "Overview",
    "text": "Overview\nEducator commands are accessed through the franklin exercise command group:\nfranklin exercise [SUBCOMMAND] [OPTIONS]\nAll educator commands require: - GitLab account with appropriate permissions - SSH key configured for GitLab access - Educator role in the Franklin GitLab group"
  },
  {
    "objectID": "pages/full_commands_edu.html#main-command-group",
    "href": "pages/full_commands_edu.html#main-command-group",
    "title": "Educator Commands",
    "section": "Main Command Group",
    "text": "Main Command Group"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise",
    "href": "pages/full_commands_edu.html#franklin-exercise",
    "title": "Educator Commands",
    "section": "franklin exercise",
    "text": "franklin exercise\nParent command for all exercise management operations.\n\nUsage\nfranklin exercise [OPTIONS] COMMAND [ARGS]\n\n\nOptions\n\n--help: Show help message and list all subcommands\n\n\n\nAvailable Subcommands\nfranklin exercise --help\nOutput:\nCommands:\n  new        Create a new exercise\n  edit       Edit an existing exercise\n  clone      Clone exercise repository for editing\n  test       Test exercise locally\n  build      Build Docker image for exercise\n  publish    Publish exercise to registry\n  settings   Open exercise settings in GitLab\n  archive    Archive (hide) an exercise"
  },
  {
    "objectID": "pages/full_commands_edu.html#creating-exercises",
    "href": "pages/full_commands_edu.html#creating-exercises",
    "title": "Educator Commands",
    "section": "Creating Exercises",
    "text": "Creating Exercises"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-new",
    "href": "pages/full_commands_edu.html#franklin-exercise-new",
    "title": "Educator Commands",
    "section": "franklin exercise new",
    "text": "franklin exercise new\nCreates a new exercise repository with starter template.\n\nUsage\nfranklin exercise new [OPTIONS]\n\n\nOptions\n\n--course COURSE_NAME: Specify course (skips interactive selection)\n--name EXERCISE_NAME: Specify exercise name (skips prompt)\n--template TEMPLATE_NAME: Use specific template (default: standard)\n--help: Show help message\n\n\n\nInteractive Mode\nfranklin exercise new\nProcess: 1. Course Selection: Choose target course from list 2. Name Input: Enter repository name (lowercase, no spaces) 3. Template Selection: Choose exercise template 4. Repository Creation: Creates GitLab repository 5. Initial Setup: Adds template files 6. Browser Launch: Opens repository settings\nExample interaction:\nSelect course:\n  1. Introduction to Biology\n  2. Advanced Chemistry\n  3. Data Science Fundamentals\nSelect course number: 1\n\nEnter exercise repository name (e.g., 'week1-intro'): week1-intro\n\nSelect template:\n  1. Standard (notebook + tests)\n  2. Advanced (multiple notebooks)\n  3. Minimal (single notebook)\nSelect template number: 1\n\nCreating exercise repository...\n✓ Repository created: https://gitlab.au.dk/franklin/intro-bio/week1-intro\n✓ Template files added\n✓ Opening settings page in browser...\n\n\nDirect Mode\nCreate exercise with all parameters:\nfranklin exercise new --course intro-bio --name week1-intro --template standard\n\n\nTemplates\nStandard Template includes: - exercise.ipynb: Starter notebook - Dockerfile: Container configuration - pixi.toml: Dependency specification - README.md: Student instructions - .gitlab-ci.yml: CI/CD pipeline - tests/: Test directory structure\nAdvanced Template adds: - Multiple notebook files - data/: Sample data directory - src/: Helper modules - Extended test suite\nMinimal Template contains: - Single notebook file - Basic Dockerfile - Minimal dependencies\n\n\nPost-Creation Steps\nAfter creation, you should: 1. Set repository visibility to “Public” in GitLab settings 2. Add exercise title in repository description 3. Configure CI/CD variables if needed 4. Clone locally for development\n\n\nBehind the Scenes\n\n\nTechnical details of exercise creation\n\n\nPermission Check: Verifies educator role in target course\nName Validation: Ensures name follows GitLab conventions\nRepository Creation: Uses GitLab API to create project\nTemplate Copy: Copies template files from Franklin package\nGit Operations: Initializes repo, adds files, makes initial commit\nPipeline Trigger: Starts CI/CD to build initial Docker image\nSettings Launch: Opens browser to repository settings"
  },
  {
    "objectID": "pages/full_commands_edu.html#editing-exercises",
    "href": "pages/full_commands_edu.html#editing-exercises",
    "title": "Educator Commands",
    "section": "Editing Exercises",
    "text": "Editing Exercises"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-edit",
    "href": "pages/full_commands_edu.html#franklin-exercise-edit",
    "title": "Educator Commands",
    "section": "franklin exercise edit",
    "text": "franklin exercise edit\nLaunches exercise editing workflow with live testing.\n\nUsage\nfranklin exercise edit [OPTIONS]\n\n\nOptions\n\n--workflow WORKFLOW: Choose workflow (automated/assisted/manual)\n--no-browser: Don’t auto-launch browser\n--port PORT: Jupyter port (default: 8888)\n--help: Show help message\n\n\n\nWorkflows\n\n\nAutomated Workflow (Default)\nBest for quick edits and beginners:\nfranklin exercise edit\nProcess: 1. Exercise Selection: Choose exercise to edit 2. Clone Repository: Downloads to temporary directory 3. Launch Environment: Starts Docker with exercise 4. Open JupyterLab: Browser opens with files 5. File Watching: Auto-saves changes to Git 6. Test on Save: Runs tests automatically 7. Commit & Push: Pushes changes when done\nFeatures: - No Git knowledge required - Automatic dependency detection - Live test feedback - Guided commit messages\n\n\nAssisted Workflow\nFor users comfortable with Git:\nfranklin exercise edit --workflow assisted\nProcess: 1. Clone Repository: To current directory 2. Branch Creation: Makes feature branch 3. Launch Environment: Docker with hot-reload 4. Manual Editing: Use any editor 5. Test Command: Run tests manually 6. Git Operations: Commit and push yourself\nFeatures: - Full Git control - Choice of editors - Branch-based workflow - Manual test timing\n\n\nManual Workflow\nFor advanced users:\nfranklin exercise edit --workflow manual\nSimply clones the repository and exits. You handle everything: - Environment setup - Testing - Git operations - CI/CD monitoring\n\n\nFile Watching\nIn automated mode, Franklin watches for changes to: - *.ipynb: Notebook files - *.py: Python modules - Dockerfile: Container configuration - pixi.toml: Dependencies - tests/*.py: Test files\nChanges trigger: 1. Auto-save to Git staging 2. Test execution 3. Feedback in terminal\n\n\nDependency Management\nFranklin automatically detects and adds dependencies: 1. Import Detection: Scans notebooks for imports 2. Version Resolution: Finds compatible versions 3. pixi.toml Update: Adds to dependency list 4. Image Rebuild: Triggers if needed\nExample:\n# In notebook cell:\nimport pandas as pd\nimport seaborn as sns\nFranklin detects and adds:\n# In pixi.toml:\n[dependencies]\npandas = \"&gt;=2.0\"\nseaborn = \"&gt;=0.12\""
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-clone",
    "href": "pages/full_commands_edu.html#franklin-exercise-clone",
    "title": "Educator Commands",
    "section": "franklin exercise clone",
    "text": "franklin exercise clone\nClones exercise repository for local development.\n\nUsage\nfranklin exercise clone [OPTIONS] [URL]\n\n\nArguments\n\nURL (optional): Direct repository URL to clone\n\n\n\nOptions\n\n--branch BRANCH: Checkout specific branch\n--depth DEPTH: Shallow clone depth (default: full)\n--help: Show help message\n\n\n\nInteractive Mode\nfranklin exercise clone\nProcess: 1. Shows course selection menu 2. Shows exercise selection menu 3. Clones selected repository 4. Preserves all files (including solutions)\n\n\nDirect Mode\nfranklin exercise clone https://gitlab.au.dk/franklin/course/exercise.git\n\n\nDifference from Student Download\n\n\n\nAspect\nexercise clone\ndownload\n\n\n\n\nTarget Users\nEducators\nStudents\n\n\nFiles Included\nAll files\nStudent files only\n\n\nGit History\nPreserved\nRemoved\n\n\nBranch Access\nAll branches\nMain only\n\n\nPush Rights\nYes\nNo"
  },
  {
    "objectID": "pages/full_commands_edu.html#testing-exercises",
    "href": "pages/full_commands_edu.html#testing-exercises",
    "title": "Educator Commands",
    "section": "Testing Exercises",
    "text": "Testing Exercises"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-test",
    "href": "pages/full_commands_edu.html#franklin-exercise-test",
    "title": "Educator Commands",
    "section": "franklin exercise test",
    "text": "franklin exercise test\nRuns exercise test suite locally.\n\nUsage\nfranklin exercise test [OPTIONS]\n\n\nOptions\n\n--notebook NOTEBOOK: Test specific notebook (default: all)\n--verbose: Show detailed test output\n--no-docker: Run tests in current environment\n--help: Show help message\n\n\n\nDefault Behavior\nfranklin exercise test\nProcess: 1. Detection: Finds exercise in current directory 2. Image Build: Builds Docker image if needed 3. Container Start: Launches test container 4. Test Execution: Runs all tests in tests/ 5. Notebook Execution: Validates notebooks run 6. Output Check: Verifies expected outputs 7. Cleanup: Removes test container\n\n\nTest Types\nNotebook Tests: - Cell execution without errors - Output presence verification - Variable state checking - Plot generation validation\nUnit Tests: - Helper function testing - Data loading verification - Model correctness checks\nIntegration Tests: - Full workflow execution - Multi-notebook pipelines - Data flow validation\n\n\nTest Configuration\nTests are configured in tests/test_config.yml:\nnotebooks:\n  - name: exercise.ipynb\n    timeout: 60\n    check_outputs: true\n    allowed_errors: []\n    \n  - name: advanced.ipynb\n    timeout: 120\n    check_outputs: false\n    allowed_errors: ['DeprecationWarning']\n\nunit_tests:\n  - tests/test_helpers.py\n  - tests/test_data.py\n\nintegration_tests:\n  - tests/test_full_workflow.py\n\n\nWriting Tests\nNotebook test example:\n# tests/test_notebook.py\ndef test_exercise_notebook():\n    \"\"\"Test that exercise notebook runs without errors.\"\"\"\n    notebook_path = \"exercise.ipynb\"\n    \n    # Execute notebook\n    with open(notebook_path) as f:\n        nb = nbformat.read(f, as_version=4)\n    \n    ep = ExecutePreprocessor(timeout=60)\n    ep.preprocess(nb, {'metadata': {'path': './'}})\n    \n    # Check for specific outputs\n    assert any('plot' in cell.source for cell in nb.cells)\n    assert any('result' in cell.source for cell in nb.cells)\n\n\nCommon Test Failures\n\nImport Error: Missing dependency in pixi.toml\nTimeout: Notebook takes too long (increase timeout)\nOutput Mismatch: Expected output not found\nFile Not Found: Data files not included"
  },
  {
    "objectID": "pages/full_commands_edu.html#building-and-publishing",
    "href": "pages/full_commands_edu.html#building-and-publishing",
    "title": "Educator Commands",
    "section": "Building and Publishing",
    "text": "Building and Publishing"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-build",
    "href": "pages/full_commands_edu.html#franklin-exercise-build",
    "title": "Educator Commands",
    "section": "franklin exercise build",
    "text": "franklin exercise build\nBuilds Docker image for exercise.\n\nUsage\nfranklin exercise build [OPTIONS]\n\n\nOptions\n\n--tag TAG: Image tag (default: latest)\n--no-cache: Build without cache\n--push: Push after building\n--help: Show help message\n\n\n\nBuild Process\nfranklin exercise build\nSteps: 1. Validation: Checks Dockerfile exists 2. Dependency Resolution: Processes pixi.toml 3. Image Build: Runs Docker build 4. Layer Caching: Optimizes rebuild speed 5. Tagging: Applies repository tags 6. Size Check: Warns if &gt;2GB\n\n\nBuild Optimization\nDockerfile best practices:\n# Good: Dependencies before code\nFROM mambaforge:latest\nCOPY pixi.toml .\nRUN pixi install\nCOPY . .\n\n# Bad: Code changes bust cache\nFROM mambaforge:latest\nCOPY . .\nRUN pixi install\n\n\nMulti-stage Builds\nFor smaller images:\n# Build stage\nFROM mambaforge:latest as builder\nCOPY pixi.toml .\nRUN pixi install\n\n# Runtime stage\nFROM python:3.11-slim\nCOPY --from=builder /opt/conda /opt/conda\nCOPY . ."
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-publish",
    "href": "pages/full_commands_edu.html#franklin-exercise-publish",
    "title": "Educator Commands",
    "section": "franklin exercise publish",
    "text": "franklin exercise publish\nPublishes exercise to GitLab registry.\n\nUsage\nfranklin exercise publish [OPTIONS]\n\n\nOptions\n\n--tag TAG: Image tag (default: latest)\n--force: Overwrite existing tag\n--test: Run tests before publishing\n--help: Show help message\n\n\n\nPublishing Process\nfranklin exercise publish\nSteps: 1. Test Execution: Runs test suite (unless skipped) 2. Image Build: Builds Docker image 3. Registry Login: Authenticates with GitLab 4. Image Push: Uploads to registry 5. Tag Update: Updates latest tag 6. Visibility Check: Ensures image is accessible\n\n\nVersion Tagging\nBest practice for versions:\nfranklin exercise publish --tag v1.0\nfranklin exercise publish --tag fall2024\nfranklin exercise publish --tag latest\nStudents always get latest unless specified otherwise.\n\n\nRegistry Structure\nImages are organized as:\nregistry.gitlab.au.dk/\n└── franklin/\n    └── [course-name]/\n        └── [exercise-name]:tag\nExample:\nregistry.gitlab.au.dk/franklin/intro-bio/week1-intro:latest"
  },
  {
    "objectID": "pages/full_commands_edu.html#repository-management",
    "href": "pages/full_commands_edu.html#repository-management",
    "title": "Educator Commands",
    "section": "Repository Management",
    "text": "Repository Management"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-settings",
    "href": "pages/full_commands_edu.html#franklin-exercise-settings",
    "title": "Educator Commands",
    "section": "franklin exercise settings",
    "text": "franklin exercise settings\nOpens exercise GitLab settings page.\n\nUsage\nfranklin exercise settings [OPTIONS]\n\n\nOptions\n\n--section SECTION: Specific settings section\n--help: Show help message\n\n\n\nInteractive Mode\nfranklin exercise settings\nOpens general settings page after exercise selection.\n\n\nDirect Navigation\nfranklin exercise settings --section visibility\nfranklin exercise settings --section ci-cd\nfranklin exercise settings --section members\n\n\nCommon Settings Tasks\nMake Repository Public: 1. Run franklin exercise settings --section visibility 2. Change “Project visibility” to “Public” 3. Save changes\nAdd Teaching Assistants: 1. Run franklin exercise settings --section members 2. Click “Invite members” 3. Add users with “Developer” role\nConfigure CI/CD: 1. Run franklin exercise settings --section ci-cd 2. Add variables for registry credentials 3. Configure pipeline triggers"
  },
  {
    "objectID": "pages/full_commands_edu.html#franklin-exercise-archive",
    "href": "pages/full_commands_edu.html#franklin-exercise-archive",
    "title": "Educator Commands",
    "section": "franklin exercise archive",
    "text": "franklin exercise archive\nArchives (hides) an exercise from students.\n\nUsage\nfranklin exercise archive [OPTIONS]\n\n\nOptions\n\n--confirm: Skip confirmation prompt\n--help: Show help message\n\n\n\nArchive Process\nfranklin exercise archive\nSteps: 1. Exercise Selection: Choose exercise to archive 2. Confirmation: Confirm archival intent 3. API Call: Sets repository to archived state 4. Registry Update: Removes from student view\n\n\nEffects of Archiving\nWhat happens: - Repository becomes read-only - Hidden from student exercise lists - Image remains in registry - Can be unarchived later\nWhat’s preserved: - All code and history - Issues and merge requests - CI/CD pipelines - Docker images\n\n\nUnarchiving\nTo restore an archived exercise: 1. Go to GitLab settings 2. Expand “Advanced” section 3. Click “Unarchive project”"
  },
  {
    "objectID": "pages/full_commands_edu.html#advanced-features",
    "href": "pages/full_commands_edu.html#advanced-features",
    "title": "Educator Commands",
    "section": "Advanced Features",
    "text": "Advanced Features"
  },
  {
    "objectID": "pages/full_commands_edu.html#continuous-integration",
    "href": "pages/full_commands_edu.html#continuous-integration",
    "title": "Educator Commands",
    "section": "Continuous Integration",
    "text": "Continuous Integration\nAll exercises include GitLab CI/CD pipelines:\n.gitlab-ci.yml template:\nstages:\n  - test\n  - build\n  - publish\n\ntest:\n  stage: test\n  script:\n    - pixi run test\n    - pixi run notebook-test\n\nbuild:\n  stage: build\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE .\n\npublish:\n  stage: publish\n  script:\n    - docker push $CI_REGISTRY_IMAGE:latest\n  only:\n    - main\n\nPipeline Triggers\nPipelines run on: - Push to main branch - Merge requests - Tag creation - Manual trigger\n\n\nPipeline Monitoring\nView pipeline status:\n# Opens pipelines page\nfranklin exercise settings --section pipelines"
  },
  {
    "objectID": "pages/full_commands_edu.html#exercise-metadata",
    "href": "pages/full_commands_edu.html#exercise-metadata",
    "title": "Educator Commands",
    "section": "Exercise Metadata",
    "text": "Exercise Metadata\nExercises contain metadata in .franklin.yml:\ncourse: intro-bio\nname: week1-intro\nversion: 1.0.0\ndifficulty: beginner\ntopics:\n  - data-analysis\n  - visualization\n  - pandas\n\nestimated_time: 90  # minutes\nprerequisites:\n  - python-basics\n  - jupyter-intro\n\nlearning_objectives:\n  - Load and explore datasets\n  - Create basic visualizations\n  - Perform simple analyses"
  },
  {
    "objectID": "pages/full_commands_edu.html#dependency-scanning",
    "href": "pages/full_commands_edu.html#dependency-scanning",
    "title": "Educator Commands",
    "section": "Dependency Scanning",
    "text": "Dependency Scanning\nFranklin scans for dependencies in: 1. Import statements in notebooks 2. Requirements in markdown cells 3. Magic commands like %pip install\nDetected packages are added to pixi.toml with appropriate versions."
  },
  {
    "objectID": "pages/full_commands_edu.html#solution-management",
    "href": "pages/full_commands_edu.html#solution-management",
    "title": "Educator Commands",
    "section": "Solution Management",
    "text": "Solution Management\nSolutions are stored separately: - solutions/: Solution notebooks - .solutions.yml: Solution metadata - Excluded from student downloads - Included in educator clones\nBest practice:\n# In exercise notebook\n# TODO: Calculate the mean of the data\nmean_value = None  # Your code here\n\n# In solution notebook\nmean_value = data.mean()"
  },
  {
    "objectID": "pages/full_commands_edu.html#troubleshooting",
    "href": "pages/full_commands_edu.html#troubleshooting",
    "title": "Educator Commands",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nCommon Issues\n\nSSH Key Problems\nProblem: “Permission denied (publickey)”\n# Solution: Configure SSH key\nssh-keygen -t ed25519 -C \"your-email@au.dk\"\n# Add public key to GitLab profile\n\n\nPermission Denied\nProblem: “You don’t have permission”\n# Solution: Verify educator role\n# Contact course coordinator for access\n\n\nDocker Build Failures\nProblem: “Docker build failed”\n# Solution: Check Dockerfile syntax\ndocker build . --no-cache\n# Verify base image exists\n# Check dependency conflicts\n\n\nTest Failures\nProblem: “Tests failed”\n# Solution: Run tests locally\nfranklin exercise test --verbose\n# Check test configuration\n# Verify notebook outputs\n\n\n\nDebug Mode\nEnable verbose output:\nexport FRANKLIN_DEBUG=true\nfranklin exercise edit\nShows: - Git commands executed - Docker build output - Test details - API calls made"
  },
  {
    "objectID": "pages/full_commands_edu.html#best-practices",
    "href": "pages/full_commands_edu.html#best-practices",
    "title": "Educator Commands",
    "section": "Best Practices",
    "text": "Best Practices\n\nExercise Design\n\nStart Simple: Begin with working example\nClear Instructions: Use markdown cells liberally\nIncremental Difficulty: Build complexity gradually\nTest Everything: Include comprehensive tests\nProvide Hints: Guide without giving away solutions\n\n\n\nDependency Management\n\nMinimal Dependencies: Only what’s needed\nPin Major Versions: Avoid breaking changes\nTest Compatibility: Verify versions work together\nDocument Requirements: List in README\n\n\n\nVersion Control\n\nMeaningful Commits: Describe changes clearly\nTag Releases: Mark stable versions\nBranch Features: Develop in branches\nTest Before Merge: Ensure CI passes\n\n\n\nStudent Experience\n\nFast Startup: Optimize Docker images\nClear Errors: Helpful error messages\nExample Outputs: Show expected results\nResource Limits: Consider student hardware"
  },
  {
    "objectID": "pages/full_commands_edu.html#command-reference",
    "href": "pages/full_commands_edu.html#command-reference",
    "title": "Educator Commands",
    "section": "Command Reference",
    "text": "Command Reference\n\nQuick Reference Table\n\n\n\n\n\n\n\n\nCommand\nPurpose\nCommon Usage\n\n\n\n\nexercise new\nCreate new exercise\nfranklin exercise new\n\n\nexercise edit\nEdit with live testing\nfranklin exercise edit\n\n\nexercise clone\nClone for development\nfranklin exercise clone\n\n\nexercise test\nRun test suite\nfranklin exercise test\n\n\nexercise build\nBuild Docker image\nfranklin exercise build\n\n\nexercise publish\nPush to registry\nfranklin exercise publish\n\n\nexercise settings\nOpen GitLab settings\nfranklin exercise settings\n\n\nexercise archive\nHide from students\nfranklin exercise archive\n\n\n\n\n\nCommand Aliases\nSome commands have shortcuts: - franklin ex → franklin exercise - franklin exercise create → franklin exercise new - franklin exercise hide → franklin exercise archive"
  },
  {
    "objectID": "pages/full_commands_edu.html#integration-with-core-franklin",
    "href": "pages/full_commands_edu.html#integration-with-core-franklin",
    "title": "Educator Commands",
    "section": "Integration with Core Franklin",
    "text": "Integration with Core Franklin\nEducator commands integrate with core Franklin:\nTesting student experience:\n# As educator, test what students see\nfranklin exercise clone      # Get exercise\nfranklin download            # Test student download\nfranklin jupyter            # Test student environment\nWorkflow example:\n# Create and test exercise\nfranklin exercise new\nfranklin exercise edit\nfranklin exercise test\nfranklin exercise publish\n\n# Verify student experience\ncd /tmp\nfranklin download  # As student would\ncd exercise-name\nfranklin jupyter   # As student would"
  },
  {
    "objectID": "pages/full_commands_edu.html#future-features",
    "href": "pages/full_commands_edu.html#future-features",
    "title": "Educator Commands",
    "section": "Future Features",
    "text": "Future Features\nPlanned enhancements: - Auto-grading: Automatic submission grading - Analytics: Track student progress - Collaboration: Multi-educator workflows - Templates: More exercise templates - Import/Export: Course package management"
  },
  {
    "objectID": "pages/git.html",
    "href": "pages/git.html",
    "title": "Introduction to Git",
    "section": "",
    "text": "Git is a version control system that tracks changes to your files over time. Think of it as a sophisticated “undo” system that remembers every version of your work, allows you to collaborate with others, and helps you organize your coding projects.\n\n\nImagine you’re writing an essay: - You save multiple versions: essay_v1.doc, essay_v2.doc, essay_final.doc, essay_final_REALLY_final.doc - You accidentally delete an important paragraph - You want to see what you changed between versions - You’re working with a classmate and need to combine your changes\nGit solves all these problems elegantly for code (and any text files).",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#what-is-git",
    "href": "pages/git.html#what-is-git",
    "title": "Introduction to Git",
    "section": "",
    "text": "Git is a version control system that tracks changes to your files over time. Think of it as a sophisticated “undo” system that remembers every version of your work, allows you to collaborate with others, and helps you organize your coding projects.\n\n\nImagine you’re writing an essay: - You save multiple versions: essay_v1.doc, essay_v2.doc, essay_final.doc, essay_final_REALLY_final.doc - You accidentally delete an important paragraph - You want to see what you changed between versions - You’re working with a classmate and need to combine your changes\nGit solves all these problems elegantly for code (and any text files).",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#core-concepts",
    "href": "pages/git.html#core-concepts",
    "title": "Introduction to Git",
    "section": "Core Concepts",
    "text": "Core Concepts\n\nRepository (Repo)\nA repository is a folder that Git tracks. It contains all your project files and the entire history of changes.\n# Turn any folder into a Git repository\ngit init\n\n\nCommits\nA commit is a snapshot of your work at a specific point in time. Each commit has: - A unique ID (hash) - Author information - Timestamp - A message describing the changes\n# Create a commit\ngit add myfile.py          # Stage the file\ngit commit -m \"Add data analysis function\"  # Commit with message\n\n\nThe Three States\nFiles in Git exist in three states:\n\n\n\n\n\n\ngraph LR\n    A[Working Directory] --&gt;|git add| B[Staging Area]\n    B --&gt;|git commit| C[Repository]\n    C --&gt;|git checkout| A\n\n\n\n\nFigure 1: Git file states\n\n\n\n\n\n\nWorking Directory: Where you edit files\nStaging Area: Where you prepare changes for commit\nRepository: Where Git permanently stores snapshots",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#essential-git-commands",
    "href": "pages/git.html#essential-git-commands",
    "title": "Introduction to Git",
    "section": "Essential Git Commands",
    "text": "Essential Git Commands\n\nStarting a Project\n# Create a new repository\ngit init\n\n# Clone an existing repository\ngit clone https://github.com/username/project.git\n\n# Check repository status\ngit status\n\n\nMaking Changes\n# Stage specific files\ngit add filename.py\ngit add data.csv\n\n# Stage all changes\ngit add .\n\n# Commit staged changes\ngit commit -m \"Describe what you changed\"\n\n# See what changed\ngit diff                    # Changes not yet staged\ngit diff --staged          # Changes staged for commit\n\n\nViewing History\n# View commit history\ngit log\n\n# View history with graph\ngit log --oneline --graph --all\n\n# View specific commit\ngit show abc123\n\n# See who changed what\ngit blame filename.py\n\n\nUndoing Changes\n# Discard changes in working directory\ngit checkout -- filename.py\n\n# Unstage a file\ngit reset HEAD filename.py\n\n# Undo last commit (keep changes)\ngit reset --soft HEAD~1\n\n# Undo last commit (discard changes)\ngit reset --hard HEAD~1",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#branching-and-merging",
    "href": "pages/git.html#branching-and-merging",
    "title": "Introduction to Git",
    "section": "Branching and Merging",
    "text": "Branching and Merging\nBranches allow you to work on different features without affecting the main code.\n\nWorking with Branches\n# Create new branch\ngit branch feature-name\n\n# Switch to branch\ngit checkout feature-name\n\n# Create and switch in one command\ngit checkout -b feature-name\n\n# List branches\ngit branch\n\n# Delete branch\ngit branch -d feature-name\n\n\nMerging Changes\n# Merge feature branch into current branch\ngit merge feature-name\n\n# Resolve merge conflicts manually, then:\ngit add conflicted-file.py\ngit commit -m \"Resolve merge conflict\"",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#remote-repositories",
    "href": "pages/git.html#remote-repositories",
    "title": "Introduction to Git",
    "section": "Remote Repositories",
    "text": "Remote Repositories\nRemote repositories (like GitHub, GitLab) allow you to: - Back up your code - Collaborate with others - Share your work\n\nWorking with Remotes\n# Add remote repository\ngit remote add origin https://github.com/username/repo.git\n\n# View remotes\ngit remote -v\n\n# Push to remote\ngit push origin main\n\n# Pull from remote\ngit pull origin main\n\n# Fetch without merging\ngit fetch origin",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#git-with-franklin",
    "href": "pages/git.html#git-with-franklin",
    "title": "Introduction to Git",
    "section": "Git with Franklin",
    "text": "Git with Franklin\nFranklin exercises are Git repositories, making version control seamless:\n\nStudent Workflow\n# After downloading an exercise\ncd \"Exercise Name\"\n\n# Check git status\ngit status\n\n# Save your work\ngit add exercise.ipynb\ngit commit -m \"Complete part 1 of exercise\"\n\n# Create your own backup\ngit remote add backup https://github.com/yourusername/solutions.git\ngit push backup main\n\n\nEducator Workflow\n# Creating an exercise\nfranklin exercise new\n\n# Track changes\ngit add -A\ngit commit -m \"Add exercise instructions\"\n\n# Update exercise\ngit commit -m \"Clarify problem 3\"\nfranklin exercise publish",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#best-practices",
    "href": "pages/git.html#best-practices",
    "title": "Introduction to Git",
    "section": "Best Practices",
    "text": "Best Practices\n\nCommit Messages\nWrite clear, descriptive commit messages:\n# Good commit messages\ngit commit -m \"Add data validation to user input\"\ngit commit -m \"Fix bug in sorting algorithm\"\ngit commit -m \"Update documentation for API endpoints\"\n\n# Bad commit messages\ngit commit -m \"Fixed stuff\"\ngit commit -m \"asdf\"\ngit commit -m \"Monday's work\"\n\n\nCommit Frequency\n\nCommit often: Small, logical changes\nCommit working code: Don’t break the build\nCommit related changes: One commit = one purpose\n\n\n\n.gitignore\nUse .gitignore to exclude files from version control:\n# .gitignore file\n*.pyc               # Python compiled files\n__pycache__/        # Python cache directory\n.DS_Store           # Mac system files\n*.log               # Log files\nsecrets.txt         # Sensitive information\nvenv/               # Virtual environment",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#common-scenarios",
    "href": "pages/git.html#common-scenarios",
    "title": "Introduction to Git",
    "section": "Common Scenarios",
    "text": "Common Scenarios\n\nScenario 1: Accidentally Committed a Large File\n# Remove file from history\ngit rm --cached large_file.zip\ngit commit -m \"Remove large file\"\n\n# Add to .gitignore\necho \"*.zip\" &gt;&gt; .gitignore\ngit add .gitignore\ngit commit -m \"Ignore zip files\"\n\n\nScenario 2: Need to Switch Tasks Quickly\n# Save current work without committing\ngit stash\n\n# Work on urgent fix\ngit checkout main\n# ... make fixes ...\ngit commit -m \"Emergency fix\"\n\n# Return to previous work\ngit checkout feature-branch\ngit stash pop\n\n\nScenario 3: Made Changes to Wrong Branch\n# Save changes\ngit stash\n\n# Switch to correct branch\ngit checkout correct-branch\n\n# Apply changes\ngit stash pop",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#git-vs-githubgitlab",
    "href": "pages/git.html#git-vs-githubgitlab",
    "title": "Introduction to Git",
    "section": "Git vs GitHub/GitLab",
    "text": "Git vs GitHub/GitLab\nGit is the version control system that runs on your computer.\nGitHub/GitLab are web services that host Git repositories and add features like: - Web interface - Issue tracking - Pull/Merge requests - Collaboration tools - CI/CD pipelines",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#visual-git-tools",
    "href": "pages/git.html#visual-git-tools",
    "title": "Introduction to Git",
    "section": "Visual Git Tools",
    "text": "Visual Git Tools\nWhile command line is powerful, visual tools can help:\n\nGUI Applications\n\nGitKraken: User-friendly, cross-platform\nSourceTree: Free, comprehensive\nGitHub Desktop: Simple, integrated with GitHub\nVS Code: Built-in Git support\n\n\n\nVS Code Git Integration\nVS Code has excellent Git integration: - See changes in the sidebar - Stage/unstage with clicks - Commit with UI - View diffs visually - Resolve merge conflicts",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#quick-reference",
    "href": "pages/git.html#quick-reference",
    "title": "Introduction to Git",
    "section": "Quick Reference",
    "text": "Quick Reference\n\n\n\nCommand\nPurpose\n\n\n\n\ngit init\nStart tracking a folder\n\n\ngit clone [url]\nCopy a repository\n\n\ngit add [file]\nStage changes\n\n\ngit commit -m \"[message]\"\nSave snapshot\n\n\ngit status\nCheck what’s changed\n\n\ngit log\nView history\n\n\ngit branch [name]\nCreate branch\n\n\ngit checkout [branch]\nSwitch branches\n\n\ngit merge [branch]\nCombine branches\n\n\ngit push\nUpload to remote\n\n\ngit pull\nDownload from remote",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#learning-resources",
    "href": "pages/git.html#learning-resources",
    "title": "Introduction to Git",
    "section": "Learning Resources",
    "text": "Learning Resources\n\nInteractive Tutorials\n\nLearn Git Branching - Visual and interactive\nGitHub’s Git Tutorial - Step-by-step guide\nAtlassian Git Tutorial - Comprehensive guide\n\n\n\nPractice\nThe best way to learn Git is to use it: 1. Start with a personal project 2. Make commits for every change 3. Try branching for new features 4. Push to GitHub/GitLab for backup",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/git.html#summary",
    "href": "pages/git.html#summary",
    "title": "Introduction to Git",
    "section": "Summary",
    "text": "Summary\nGit might seem complex at first, but you only need a few commands to get started: 1. git add and git commit to save your work 2. git status to see what’s happening 3. git push and git pull to sync with remote\nAs you become comfortable with these basics, you can gradually explore more advanced features. Remember: Git is a safety net for your code—it’s there to help, not to complicate your workflow.",
    "crumbs": [
      "Reference",
      "Introduction to Git"
    ]
  },
  {
    "objectID": "pages/installing_docker.html",
    "href": "pages/installing_docker.html",
    "title": "Installing Docker Desktop",
    "section": "",
    "text": "Docker is a tool that can run a small linux world in your computer. Franklin uses it to make sure Jupyter runs your exercise in exactly the same way, no matter which kind of computer you have. You do not need to known anything about Docker. Franklin will take care of the whole thing for you. If you are interested, though, you can have a look at this brief introduction to Docker.\nBefore you to download docker, make sure the operating system on your computer has been updated. For docker to run on your device you will have to have Windows newer than Windows 10 or newer than macOS11 (Big Sur) on mac. If you are downloading docker on a AU computer remember to activate admin privileges by activating Heimdal.\nIf you are unsure of how to activate Heimdal, follow the instructions given on this page\nGo to this page and press on “Download Docker Desktop”. When you have done that you will be presented with different options which depends on which chip your computer has. On a Mac, you can find the name of your chip by clicking the apple icon in the upper left corner and choose “about this mac” in the dropdown menu. Apple silicon chips include M1, M2 and M3. Apple intel chips are named intel.\n\n\n\nalt text\n\n\nOn Windows, you can find the name of your chip by right clicking on the start button and click system. Under device specifications look for processor. This will tell you the chip name and whether it is a AMD chip or an ARM chip.\nDownload the version of Docker Desktop that matches your operating system and computer chip. Once downloaded, follow the installation instructions for your device. You have to click accept when your computer asks you if you trust the provider. When docker desktop opens, a window pops up and asks if you want to sign in or create and account. An account is not necessary for using docker with franklin, so you can just click “skip” when prompted.\nWhen the installation procedure is complete and Docker is done starting up, you must it down. Just closing the blue Docker Dashboard window does not shut down Docker. You need to explicitly quit the program. To make sure it has quit, you can look for the little docker whale icon. In Mac is it in the menu bar. On Windows it is in the small popup menu at the right end of you task bar. If you see a small whale, Docker is still running. Click the whale icon and quit Docker.\n\n\n\nalt text\n\n\n\n\n\n\n\n\nWSL\n\n\n\nOn Windows, Docker Desktop may give you an error message saying “WSL 2 is required”. In that case, install WSL by running the following command into your terminal:\n\n\nTerminal\n\nwsl --install\n\n\n\nBack to @installing.",
    "crumbs": [
      "Setup",
      "Installing Docker Desktop"
    ]
  },
  {
    "objectID": "pages/overview.html",
    "href": "pages/overview.html",
    "title": "Outline and infrastructure",
    "section": "",
    "text": "Under development\n\n\n\nThe content of this page is being developed.\nGitLab hosting: of repositories for exercises grouped by course, allowing for nested authentication privileges.\nDocker Integration: Franklin automates the process of launching Docker containers configured with JupyterLab, simplifying environment setup for users.\nConda and Pixi package Management: The tool supports building and publishing Conda packages, enabling automatic management of dependencies.\nContinuous integration: Franklin uses GitLab pipelines for continuous integration automating workflows for building, testing, and publishing docker images.\nNested plugin APIs: The project supports extensibility through plugins, such as the franklin-educator plugin, which adds Git and GitLab integration.\nAuto update: Once installed Franklin updates automatically through either conda or pixi. This ensures that any update or bugfix is automatically available to students.\nAutomated workflows: To accommodate educators with different computational skill levels, franklin supports three levels of automation to support exercise development.\nUser management: The admin API allow easy management of users and assigning rules as either guest, teaching assistant, professor, or administrator.",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#click",
    "href": "pages/overview.html#click",
    "title": "Outline and infrastructure",
    "section": "Click",
    "text": "Click",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#docker",
    "href": "pages/overview.html#docker",
    "title": "Outline and infrastructure",
    "section": "Docker",
    "text": "Docker",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#pixi",
    "href": "pages/overview.html#pixi",
    "title": "Outline and infrastructure",
    "section": "Pixi",
    "text": "Pixi",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#purpose",
    "href": "pages/overview.html#purpose",
    "title": "Outline and infrastructure",
    "section": "Purpose",
    "text": "Purpose",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#git",
    "href": "pages/overview.html#git",
    "title": "Outline and infrastructure",
    "section": "Git",
    "text": "Git",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#gitlab",
    "href": "pages/overview.html#gitlab",
    "title": "Outline and infrastructure",
    "section": "GitLab",
    "text": "GitLab",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#groupsubgroup-layout",
    "href": "pages/overview.html#groupsubgroup-layout",
    "title": "Outline and infrastructure",
    "section": "Group/Subgroup layout",
    "text": "Group/Subgroup layout",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#users-permissions-authentication",
    "href": "pages/overview.html#users-permissions-authentication",
    "title": "Outline and infrastructure",
    "section": "Users / Permissions / Authentication",
    "text": "Users / Permissions / Authentication\n\nThe franklin-admin plugin\nInstall the franklin-admin to administer users and course infrastructure.\nTODO",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#tokens",
    "href": "pages/overview.html#tokens",
    "title": "Outline and infrastructure",
    "section": "Tokens",
    "text": "Tokens",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#pipelines",
    "href": "pages/overview.html#pipelines",
    "title": "Outline and infrastructure",
    "section": "Pipelines",
    "text": "Pipelines\n\nAU hosting\n\n\nGitLab Franklin group\n\n\nGitLab Course subgroups\n\n\nGitLab exercise repositories",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#authentication",
    "href": "pages/overview.html#authentication",
    "title": "Outline and infrastructure",
    "section": "Authentication",
    "text": "Authentication\nWeb GUI: UNI-AD login\n\nAdmin\nKasper (and someone else for backup)\nssh keys\n\n\nVIP\nssh keys\n\n\nStudents\nRead-only token distributed with franklin.",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#docker-1",
    "href": "pages/overview.html#docker-1",
    "title": "Outline and infrastructure",
    "section": "Docker",
    "text": "Docker\n\nImage hierarchy\n\nBase images maintained in the Base\nCourse base images only refer to a versioned base image\n\n\n\nTemplates\n\nEvery course has a repo template with a docker file that that refers to the course base image\nThese templates are forked from franklin/base-templates/base-template\n\n\n\nTag policy\n\nFranklin base images are versioned and must referred to with their version tag\nCourse base images are tagged latest so that courses always pulls updated version.\nExercise images are always tagged latest, which is the tag franklin pulls",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/overview.html#container-registry",
    "href": "pages/overview.html#container-registry",
    "title": "Outline and infrastructure",
    "section": "Container registry",
    "text": "Container registry\n\nimport os\n\ndef print_tree(dir_path, prefix=''):\n    entries = sorted(\n        [e for e in os.listdir(dir_path) if not e.startswith('.')]\n    )\n    last_index = len(entries) - 1\n\n    for i, entry in enumerate(entries):\n        path = os.path.join(dir_path, entry)\n        is_last = (i == last_index)\n        connector = '└── ' if is_last else '├── '\n        print(f\"{prefix}{connector}{entry}\")\n\n        if os.path.isdir(path):\n            extension = '    ' if is_last else '│   '\n            print_tree(path, prefix + extension)\n\n# Example usage:\nprint_tree(\".\")\n\n├── admin_quick_reference.html\n├── admin_quick_reference.qmd\n├── automatic_updates.html\n├── automatic_updates.qmd\n├── commands_admin.html\n├── commands_admin.qmd\n├── commands_core.html\n├── commands_core.qmd\n├── commands_edu.html\n├── commands_edu.qmd\n├── devel_quick_reference.html\n├── devel_quick_reference.qmd\n├── developer_guide.html\n├── developer_guide.qmd\n├── developing.html\n├── developing.qmd\n├── docker.html\n├── docker.qmd\n├── edu_quick_reference.html\n├── edu_quick_reference.qmd\n├── exercise_workflow.html\n├── exercise_workflow.qmd\n├── faq.html\n├── faq.qmd\n├── full_commands_admin.html\n├── full_commands_admin.qmd\n├── full_commands_core.html\n├── full_commands_core.qmd\n├── full_commands_edu.html\n├── full_commands_edu.qmd\n├── getting_started.html\n├── getting_started.qmd\n├── git.html\n├── git.qmd\n├── gitlab.html\n├── gitlab.qmd\n├── images\n│   ├── Screenshot 2025-05-31 at 11.05.53.png\n│   ├── Skærmbillede 2025-04-01 kl. 17.51.22.png\n│   ├── Skærmbillede 2025-05-22 kl. 16.44.43.png\n│   ├── Skærmbillede 2025-05-22 kl. 16.45.05.png\n│   ├── Skærmbillede 2025-05-27 kl. 13.39.22.png\n│   ├── Skærmbillede 2025-05-27 kl. 13.40.10.png\n│   ├── Skærmbillede 2025-05-27 kl. 13.42.11.png\n│   ├── Skærmbillede 2025-05-28 kl. 14.37.28.png\n│   ├── Skærmbillede 2025-05-28 kl. 14.52.02.png\n│   ├── Skærmbillede 2025-05-28 kl. 15.22.07.png\n│   ├── Skærmbillede 2025-05-28 kl. 15.32.16.png\n│   ├── Skærmbillede 2025-05-29 kl. 16.19.09.png\n│   ├── Skærmbillede 2025-06-03 kl. 13.28.40.png\n│   ├── Skærmbillede 2025-06-03 kl. 14.25.30.png\n│   ├── Skærmbillede 2025-06-03 kl. 14.27.12.png\n│   ├── elephant.png\n│   ├── pipeline_example.png\n│   ├── pipeline_example_nomenu.png\n│   ├── powershellprompt.png\n│   ├── shell-command.png\n│   └── terminal.png\n├── installing_docker.html\n├── installing_docker.qmd\n├── installing_python.html\n├── installing_python.qmd\n├── jupyterlab.ipynb\n├── jupyterlab_complete.ipynb\n├── numpy_and_pandas.ipynb\n├── numpy_pandas_comprehensive.ipynb\n├── overview.qmd\n├── overview.quarto_ipynb\n├── pixi_and_conda.qmd\n├── plotting.ipynb\n├── plotting_expanded.ipynb\n├── python_r_julia.qmd\n├── python_r_julia_expanded.qmd\n├── python_users_guide.qmd\n├── sandbox.qmd\n├── ssh.qmd\n├── student\n│   ├── _quarto.yml\n│   ├── au_fonts\n│   │   ├── AULogoBold.ttf\n│   │   ├── AULogoReg.ttf\n│   │   ├── AUPassata_Bold.ttf\n│   │   ├── AUPassata_Light.ttf\n│   │   ├── AUPassata_Rg.ttf\n│   │   └── AU_Peto.ttf\n│   ├── custom.scss\n│   ├── header_extra.tex\n│   ├── headers.lua\n│   └── index.qmd\n├── terminal.qmd\n├── test_minimal.ipynb\n├── test_simple.ipynb\n├── troubleshooting.qmd\n├── widgets.ipynb\n└── widgets_expanded.ipynb\n\n\nsrc/franklin\nfranklin\n|-- __init__.py\n|-- config.py\n|-- crash.py\n|-- cutie.py\n|-- data\n|-- desktop.py\n|-- docker.py\n|-- gitlab.py\n|-- jupyter.py\n|-- logger.py\n|-- options.py\n|-- system.py\n|-- terminal.py\n|-- update.py\n`-- utils.py\n-- data\n   |-- default_user_settings.json\n   |-- gitui\n   |   |-- key_bindings.ron\n   |   |-- key_symbols.ron\n   |   `-- theme.ron\n   |-- README.md\n   `-- template\n       |-- base\n       |   |-- Dockerfile\n       |   |-- entrypoint.sh\n       |   |-- README.md\n       |   `-- tagged-release.sh\n       `-- exercise\n           |-- Dockerfile\n           |-- exercise.ipynb\n           |-- franklin.log\n           |-- pixi.toml\n           `-- README.md",
    "crumbs": [
      "Developer Resources",
      "Outline and infrastructure"
    ]
  },
  {
    "objectID": "pages/python_r_julia.html",
    "href": "pages/python_r_julia.html",
    "title": "Python, R, and Julia for Data Science",
    "section": "",
    "text": "This guide provides a comprehensive comparison of Python, R, and Julia for data science tasks. Whether you’re transitioning between languages or choosing which to learn, this reference shows how to accomplish common data operations in all three languages.\n\n\n\n\n\n\n\n\n\n\n\nFeature\nPython\nR\nJulia\n\n\n\n\nPrimary Use\nGeneral purpose, Data Science, ML\nStatistics, Data Analysis\nScientific Computing, Performance\n\n\nLearning Curve\nModerate\nSteep initially\nModerate to Steep\n\n\nPerformance\nGood with NumPy\nModerate\nExcellent\n\n\nEcosystem\nVast\nStatistical focus\nGrowing rapidly\n\n\nSyntax\nClean, readable\nFunctional, vectorized\nMathematical, fast"
  },
  {
    "objectID": "pages/python_r_julia.html#introduction",
    "href": "pages/python_r_julia.html#introduction",
    "title": "Python, R, and Julia for Data Science",
    "section": "",
    "text": "This guide provides a comprehensive comparison of Python, R, and Julia for data science tasks. Whether you’re transitioning between languages or choosing which to learn, this reference shows how to accomplish common data operations in all three languages.\n\n\n\n\n\n\n\n\n\n\n\nFeature\nPython\nR\nJulia\n\n\n\n\nPrimary Use\nGeneral purpose, Data Science, ML\nStatistics, Data Analysis\nScientific Computing, Performance\n\n\nLearning Curve\nModerate\nSteep initially\nModerate to Steep\n\n\nPerformance\nGood with NumPy\nModerate\nExcellent\n\n\nEcosystem\nVast\nStatistical focus\nGrowing rapidly\n\n\nSyntax\nClean, readable\nFunctional, vectorized\nMathematical, fast"
  },
  {
    "objectID": "pages/python_r_julia.html#setup-and-libraries",
    "href": "pages/python_r_julia.html#setup-and-libraries",
    "title": "Python, R, and Julia for Data Science",
    "section": "Setup and Libraries",
    "text": "Setup and Libraries\n\nPythonRJulia\n\n\n# Core data science libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import preprocessing, model_selection\n\n# Set display options\npd.set_option('display.max_columns', 10)\npd.set_option('display.precision', 3)\n\n\n# Core tidyverse and data science packages\nlibrary(tidyverse)  # dplyr, ggplot2, tidyr, etc.\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(forcats)\nlibrary(stringr)\n\n# Set options\noptions(scipen = 999)\noptions(digits = 3)\n\n\n# Core data science packages\nusing DataFrames\nusing CSV\nusing Statistics\nusing StatsBase\nusing Plots\nusing Random\n\n# Set random seed\nRandom.seed!(42)"
  },
  {
    "objectID": "pages/python_r_julia.html#creating-data-structures",
    "href": "pages/python_r_julia.html#creating-data-structures",
    "title": "Python, R, and Julia for Data Science",
    "section": "Creating Data Structures",
    "text": "Creating Data Structures\n\nPythonRJulia\n\n\n# Lists and arrays\nlst = [1, 2, 3, 4, 5]\narr = np.array([1, 2, 3, 4, 5])\n\n# Dictionary\ndict_data = {'name': ['Alice', 'Bob'], \n             'age': [25, 30]}\n\n# DataFrame\ndf = pd.DataFrame({\n    'id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'age': [25, 30, 35, 28],\n    'salary': [50000, 60000, 75000, 55000]\n})\n\n# Series\nseries = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n\n\n# Vectors\nvec &lt;- c(1, 2, 3, 4, 5)\n\n# List\nlst &lt;- list(name = c(\"Alice\", \"Bob\"), \n            age = c(25, 30))\n\n# Data frame (base R)\ndf &lt;- data.frame(\n  id = 1:4,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 28),\n  salary = c(50000, 60000, 75000, 55000)\n)\n\n# Tibble (tidyverse)\ntbl &lt;- tibble(\n  id = 1:4,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 28),\n  salary = c(50000, 60000, 75000, 55000)\n)\n\n\n# Arrays\narr = [1, 2, 3, 4, 5]\n\n# Dictionary\ndict_data = Dict(\"name\" =&gt; [\"Alice\", \"Bob\"],\n                 \"age\" =&gt; [25, 30])\n\n# DataFrame\ndf = DataFrame(\n    id = 1:4,\n    name = [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n    age = [25, 30, 35, 28],\n    salary = [50000, 60000, 75000, 55000]\n)\n\n# Named tuple\nnt = (name=\"Alice\", age=25)"
  },
  {
    "objectID": "pages/python_r_julia.html#data-importexport",
    "href": "pages/python_r_julia.html#data-importexport",
    "title": "Python, R, and Julia for Data Science",
    "section": "Data Import/Export",
    "text": "Data Import/Export\n\nPythonRJulia\n\n\n# CSV\ndf = pd.read_csv('data.csv')\ndf.to_csv('output.csv', index=False)\n\n# Excel\ndf = pd.read_excel('data.xlsx', sheet_name='Sheet1')\ndf.to_excel('output.xlsx', index=False)\n\n# JSON\ndf = pd.read_json('data.json')\ndf.to_json('output.json', orient='records')\n\n# Parquet (efficient storage)\ndf = pd.read_parquet('data.parquet')\ndf.to_parquet('output.parquet')\n\n\n# CSV\ndf &lt;- read_csv(\"data.csv\")  # readr package\nwrite_csv(df, \"output.csv\")\n\n# Excel\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\", sheet = \"Sheet1\")\nlibrary(writexl)\nwrite_xlsx(df, \"output.xlsx\")\n\n# JSON\nlibrary(jsonlite)\ndf &lt;- fromJSON(\"data.json\")\nwrite_json(df, \"output.json\")\n\n# RDS (R's native format)\nsaveRDS(df, \"data.rds\")\ndf &lt;- readRDS(\"data.rds\")\n\n\nusing CSV, XLSX, JSON, Parquet\n\n# CSV\ndf = CSV.read(\"data.csv\", DataFrame)\nCSV.write(\"output.csv\", df)\n\n# Excel\ndf = DataFrame(XLSX.readtable(\"data.xlsx\", \"Sheet1\"))\nXLSX.writetable(\"output.xlsx\", df)\n\n# JSON\nusing JSON3\ndf = JSON3.read(read(\"data.json\", String))\nwrite(\"output.json\", JSON3.write(df))\n\n# Parquet\ndf = read_parquet(\"data.parquet\")\nwrite_parquet(\"output.parquet\", df)"
  },
  {
    "objectID": "pages/python_r_julia.html#basic-data-inspection",
    "href": "pages/python_r_julia.html#basic-data-inspection",
    "title": "Python, R, and Julia for Data Science",
    "section": "Basic Data Inspection",
    "text": "Basic Data Inspection\n\nPythonRJulia\n\n\n# Basic info\nprint(df.shape)          # (rows, columns)\nprint(df.dtypes)         # Data types\nprint(df.info())         # Summary info\nprint(df.describe())     # Statistical summary\n\n# First/last rows\nprint(df.head())         # First 5 rows\nprint(df.tail())         # Last 5 rows\n\n# Unique values\nprint(df['name'].nunique())\nprint(df['name'].unique())\nprint(df['name'].value_counts())\n\n# Missing values\nprint(df.isnull().sum())\n\n\n# Basic info\ndim(df)                  # Dimensions\nstr(df)                  # Structure\nglimpse(df)              # dplyr version\nsummary(df)              # Statistical summary\n\n# First/last rows\nhead(df)                 # First 6 rows\ntail(df)                 # Last 6 rows\n\n# Unique values\nn_distinct(df$name)\nunique(df$name)\ntable(df$name)\n\n# Missing values\nsum(is.na(df))\ncolSums(is.na(df))\n\n\n# Basic info\nsize(df)                 # (rows, columns)\ndescribe(df)             # Statistical summary\nnames(df)                # Column names\neltype.(eachcol(df))     # Column types\n\n# First/last rows\nfirst(df, 5)             # First 5 rows\nlast(df, 5)              # Last 5 rows\n\n# Unique values\nlength(unique(df.name))\nunique(df.name)\ncountmap(df.name)        # Using StatsBase\n\n# Missing values\nsum(ismissing.(df.name))"
  },
  {
    "objectID": "pages/python_r_julia.html#selecting-data",
    "href": "pages/python_r_julia.html#selecting-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Selecting Data",
    "text": "Selecting Data\n\nPythonRJulia\n\n\n# Select columns\ndf['name']                    # Single column (Series)\ndf[['name', 'age']]          # Multiple columns\n\n# Select rows by position\ndf.iloc[0]                    # First row\ndf.iloc[0:3]                  # First 3 rows\ndf.iloc[[0, 2, 4]]           # Specific rows\n\n# Select rows by label\ndf.loc[0]                     # Row with index 0\ndf.loc[0:2, ['name', 'age']] # Rows and columns\n\n# Select by condition\ndf[df['age'] &gt; 30]\ndf[(df['age'] &gt; 25) & (df['salary'] &gt; 55000)]\ndf.query('age &gt; 25 and salary &gt; 55000')\n\n\n# Select columns\ndf$name                       # Single column\ndf[, c(\"name\", \"age\")]       # Multiple columns\nselect(df, name, age)         # dplyr\n\n# Select rows by position\ndf[1, ]                       # First row\ndf[1:3, ]                     # First 3 rows\nslice(df, 1:3)                # dplyr\n\n# Select by condition\ndf[df$age &gt; 30, ]\nfilter(df, age &gt; 30)          # dplyr\nfilter(df, age &gt; 25, salary &gt; 55000)\n\n# Combined selection\ndf %&gt;%\n  filter(age &gt; 25) %&gt;%\n  select(name, salary)\n\n\n# Select columns\ndf.name                       # Single column\ndf[:, [:name, :age]]         # Multiple columns\nselect(df, :name, :age)\n\n# Select rows by position\ndf[1, :]                      # First row\ndf[1:3, :]                    # First 3 rows\n\n# Select by condition\ndf[df.age .&gt; 30, :]\nfilter(row -&gt; row.age &gt; 30, df)\nfilter(row -&gt; row.age &gt; 25 && row.salary &gt; 55000, df)\n\n# Combined selection\ndf |&gt; \n  x -&gt; filter(row -&gt; row.age &gt; 25, x) |&gt;\n  x -&gt; select(x, :name, :salary)"
  },
  {
    "objectID": "pages/python_r_julia.html#data-manipulation",
    "href": "pages/python_r_julia.html#data-manipulation",
    "title": "Python, R, and Julia for Data Science",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n\nPythonRJulia\n\n\n# Add new column\ndf['bonus'] = df['salary'] * 0.1\ndf = df.assign(total_comp=df['salary'] + df['bonus'])\n\n# Modify existing column\ndf['age'] = df['age'] + 1\n\n# Drop columns\ndf = df.drop(['bonus'], axis=1)\n\n# Rename columns\ndf = df.rename(columns={'name': 'employee_name'})\n\n# Replace values\ndf['name'] = df['name'].replace('Alice', 'Alicia')\n\n# Apply function\ndf['age_group'] = df['age'].apply(lambda x: 'Young' if x &lt; 30 else 'Adult')\n\n\n# Add new column\ndf$bonus &lt;- df$salary * 0.1\ndf &lt;- df %&gt;% mutate(total_comp = salary + bonus)\n\n# Modify existing column\ndf$age &lt;- df$age + 1\ndf &lt;- df %&gt;% mutate(age = age + 1)\n\n# Drop columns\ndf &lt;- df %&gt;% select(-bonus)\n\n# Rename columns\ndf &lt;- df %&gt;% rename(employee_name = name)\n\n# Replace values\ndf$name[df$name == \"Alice\"] &lt;- \"Alicia\"\ndf &lt;- df %&gt;% mutate(name = if_else(name == \"Alice\", \"Alicia\", name))\n\n# Apply function\ndf &lt;- df %&gt;% \n  mutate(age_group = if_else(age &lt; 30, \"Young\", \"Adult\"))\n\n\n# Add new column\ndf.bonus = df.salary .* 0.1\ntransform!(df, :salary =&gt; (x -&gt; x .* 0.1) =&gt; :bonus)\n\n# Modify existing column\ndf.age = df.age .+ 1\ntransform!(df, :age =&gt; (x -&gt; x .+ 1) =&gt; :age)\n\n# Drop columns\nselect!(df, Not(:bonus))\n\n# Rename columns\nrename!(df, :name =&gt; :employee_name)\n\n# Replace values\ndf.name = replace(df.name, \"Alice\" =&gt; \"Alicia\")\n\n# Apply function\ndf.age_group = [x &lt; 30 ? \"Young\" : \"Adult\" for x in df.age]"
  },
  {
    "objectID": "pages/python_r_julia.html#grouping-and-aggregation",
    "href": "pages/python_r_julia.html#grouping-and-aggregation",
    "title": "Python, R, and Julia for Data Science",
    "section": "Grouping and Aggregation",
    "text": "Grouping and Aggregation\n\nPythonRJulia\n\n\n# Simple aggregation\ndf.groupby('age_group')['salary'].mean()\n\n# Multiple aggregations\nagg_df = df.groupby('age_group').agg({\n    'salary': ['mean', 'std', 'count'],\n    'age': ['min', 'max']\n}).reset_index()\n\n# Custom aggregation\ndef custom_agg(x):\n    return pd.Series({\n        'mean_salary': x['salary'].mean(),\n        'total_comp': x['salary'].sum(),\n        'employee_count': len(x)\n    })\n\nresult = df.groupby('age_group').apply(custom_agg)\n\n# Transform (same size output)\ndf['salary_zscore'] = df.groupby('age_group')['salary'].transform(\n    lambda x: (x - x.mean()) / x.std()\n)\n\n\n# Simple aggregation\ndf %&gt;% \n  group_by(age_group) %&gt;% \n  summarise(mean_salary = mean(salary))\n\n# Multiple aggregations\nagg_df &lt;- df %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(\n    mean_salary = mean(salary),\n    std_salary = sd(salary),\n    count = n(),\n    min_age = min(age),\n    max_age = max(age)\n  )\n\n# Custom aggregation\ndf %&gt;%\n  group_by(age_group) %&gt;%\n  summarise(\n    mean_salary = mean(salary),\n    total_comp = sum(salary),\n    employee_count = n(),\n    .groups = 'drop'\n  )\n\n# Transform (same size output)\ndf &lt;- df %&gt;%\n  group_by(age_group) %&gt;%\n  mutate(salary_zscore = (salary - mean(salary)) / sd(salary))\n\n\nusing Statistics\n\n# Simple aggregation\ncombine(groupby(df, :age_group), :salary =&gt; mean)\n\n# Multiple aggregations\nagg_df = combine(groupby(df, :age_group),\n    :salary =&gt; mean =&gt; :mean_salary,\n    :salary =&gt; std =&gt; :std_salary,\n    nrow =&gt; :count,\n    :age =&gt; minimum =&gt; :min_age,\n    :age =&gt; maximum =&gt; :max_age\n)\n\n# Custom aggregation\ncombine(groupby(df, :age_group)) do sdf\n    DataFrame(\n        mean_salary = mean(sdf.salary),\n        total_comp = sum(sdf.salary),\n        employee_count = nrow(sdf)\n    )\nend\n\n# Transform (same size output)\ntransform!(groupby(df, :age_group),\n    :salary =&gt; (x -&gt; (x .- mean(x)) ./ std(x)) =&gt; :salary_zscore\n)"
  },
  {
    "objectID": "pages/python_r_julia.html#joiningmerging-data",
    "href": "pages/python_r_julia.html#joiningmerging-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Joining/Merging Data",
    "text": "Joining/Merging Data\n\nPythonRJulia\n\n\n# Sample DataFrames\ndf1 = pd.DataFrame({'id': [1, 2, 3], 'name': ['A', 'B', 'C']})\ndf2 = pd.DataFrame({'id': [2, 3, 4], 'value': [10, 20, 30]})\n\n# Inner join\ninner = pd.merge(df1, df2, on='id', how='inner')\n\n# Left join\nleft = pd.merge(df1, df2, on='id', how='left')\n\n# Right join\nright = pd.merge(df1, df2, on='id', how='right')\n\n# Outer join\nouter = pd.merge(df1, df2, on='id', how='outer')\n\n# Join on multiple columns\nmerged = pd.merge(df1, df2, on=['id', 'date'], how='inner')\n\n# Join with different column names\nmerged = pd.merge(df1, df2, left_on='id1', right_on='id2')\n\n\n# Sample data frames\ndf1 &lt;- tibble(id = c(1, 2, 3), name = c(\"A\", \"B\", \"C\"))\ndf2 &lt;- tibble(id = c(2, 3, 4), value = c(10, 20, 30))\n\n# Inner join\ninner &lt;- inner_join(df1, df2, by = \"id\")\n\n# Left join\nleft &lt;- left_join(df1, df2, by = \"id\")\n\n# Right join\nright &lt;- right_join(df1, df2, by = \"id\")\n\n# Full outer join\nouter &lt;- full_join(df1, df2, by = \"id\")\n\n# Join on multiple columns\nmerged &lt;- inner_join(df1, df2, by = c(\"id\", \"date\"))\n\n# Join with different column names\nmerged &lt;- left_join(df1, df2, by = c(\"id1\" = \"id2\"))\n\n\n# Sample DataFrames\ndf1 = DataFrame(id = [1, 2, 3], name = [\"A\", \"B\", \"C\"])\ndf2 = DataFrame(id = [2, 3, 4], value = [10, 20, 30])\n\n# Inner join\ninner = innerjoin(df1, df2, on = :id)\n\n# Left join\nleft = leftjoin(df1, df2, on = :id)\n\n# Right join\nright = rightjoin(df1, df2, on = :id)\n\n# Outer join\nouter = outerjoin(df1, df2, on = :id)\n\n# Join on multiple columns\nmerged = innerjoin(df1, df2, on = [:id, :date])\n\n# Join with different column names\nmerged = leftjoin(df1, df2, on = :id1 =&gt; :id2)"
  },
  {
    "objectID": "pages/python_r_julia.html#reshaping-data",
    "href": "pages/python_r_julia.html#reshaping-data",
    "title": "Python, R, and Julia for Data Science",
    "section": "Reshaping Data",
    "text": "Reshaping Data\n\nPythonRJulia\n\n\n# Wide to long (melt)\nlong_df = pd.melt(df, \n                  id_vars=['id', 'name'],\n                  value_vars=['value1', 'value2'],\n                  var_name='variable',\n                  value_name='value')\n\n# Long to wide (pivot)\nwide_df = long_df.pivot(index='id',\n                        columns='variable',\n                        values='value')\n\n# Pivot table with aggregation\npivot_table = pd.pivot_table(df,\n                             values='value',\n                             index='category',\n                             columns='year',\n                             aggfunc='mean')\n\n# Stack/unstack\nstacked = df.set_index(['id', 'name']).stack()\nunstacked = stacked.unstack()\n\n\nlibrary(tidyr)\n\n# Wide to long\nlong_df &lt;- df %&gt;%\n  pivot_longer(cols = c(value1, value2),\n               names_to = \"variable\",\n               values_to = \"value\")\n\n# Long to wide\nwide_df &lt;- long_df %&gt;%\n  pivot_wider(names_from = variable,\n              values_from = value)\n\n# With aggregation\nwide_df &lt;- long_df %&gt;%\n  pivot_wider(names_from = variable,\n              values_from = value,\n              values_fn = mean)\n\n# Separate and unite columns\ndf %&gt;%\n  separate(full_name, into = c(\"first\", \"last\"), sep = \" \") %&gt;%\n  unite(full_name, first, last, sep = \"_\")\n\n\n# Wide to long (stack)\nlong_df = stack(df, [:value1, :value2],\n                variable_name = :variable,\n                value_name = :value)\n\n# Long to wide (unstack)\nwide_df = unstack(long_df, :id, :variable, :value)\n\n# With aggregation\nwide_df = unstack(long_df, :id, :variable, :value, \n                  combine = mean)\n\n# Custom reshaping\nwide_df = combine(groupby(long_df, [:id, :variable])) do sdf\n    DataFrame(value = mean(sdf.value))\nend |&gt; \nx -&gt; unstack(x, :id, :variable, :value)"
  },
  {
    "objectID": "pages/python_r_julia.html#missing-data-handling",
    "href": "pages/python_r_julia.html#missing-data-handling",
    "title": "Python, R, and Julia for Data Science",
    "section": "Missing Data Handling",
    "text": "Missing Data Handling\n\nPythonRJulia\n\n\n# Check for missing\ndf.isnull().sum()\ndf.isna().any()\n\n# Drop missing\ndf.dropna()                     # Drop rows with any NaN\ndf.dropna(subset=['col1'])     # Drop rows where col1 is NaN\ndf.dropna(axis=1)              # Drop columns with any NaN\n\n# Fill missing\ndf.fillna(0)                   # Fill with constant\ndf.fillna(method='ffill')      # Forward fill\ndf.fillna(method='bfill')      # Backward fill\ndf.fillna(df.mean())           # Fill with mean\n\n# Interpolate\ndf.interpolate(method='linear')\n\n\n# Check for missing\nsum(is.na(df))\ncolSums(is.na(df))\ncomplete.cases(df)\n\n# Drop missing\nna.omit(df)                    # Drop rows with any NA\ndrop_na(df)                    # tidyr version\ndrop_na(df, col1)              # Drop rows where col1 is NA\n\n# Fill missing\nreplace_na(df, list(col1 = 0, col2 = \"Unknown\"))\nfill(df, col1, .direction = \"down\")  # Fill down\nfill(df, col1, .direction = \"up\")    # Fill up\n\n# Replace with mean\ndf %&gt;%\n  mutate(col1 = if_else(is.na(col1), mean(col1, na.rm = TRUE), col1))\n\n\n# Check for missing\nsum(ismissing.(df.col1))\nany(ismissing.(df.col1))\n\n# Drop missing\ndropmissing(df)                # Drop rows with any missing\ndropmissing(df, :col1)         # Drop rows where col1 is missing\n\n# Fill missing\ncoalesce.(df.col1, 0)          # Replace missing with 0\ndf.col1 = coalesce.(df.col1, mean(skipmissing(df.col1)))\n\n# Forward/backward fill\nfunction ffill!(v)\n    for i in 2:length(v)\n        if ismissing(v[i])\n            v[i] = v[i-1]\n        end\n    end\nend"
  },
  {
    "objectID": "pages/python_r_julia.html#string-operations",
    "href": "pages/python_r_julia.html#string-operations",
    "title": "Python, R, and Julia for Data Science",
    "section": "String Operations",
    "text": "String Operations\n\nPythonRJulia\n\n\n# String methods\ndf['name'].str.lower()          # Lowercase\ndf['name'].str.upper()          # Uppercase\ndf['name'].str.title()          # Title case\ndf['name'].str.strip()          # Remove whitespace\ndf['name'].str.len()            # String length\n\n# Pattern matching\ndf['name'].str.contains('pattern')\ndf['name'].str.startswith('A')\ndf['name'].str.endswith('z')\n\n# Extraction and replacement\ndf['name'].str.extract(r'(\\d+)')       # Extract numbers\ndf['name'].str.replace('old', 'new')   # Replace\ndf['name'].str.split('_', expand=True) # Split into columns\n\n# Concatenation\ndf['full_name'] = df['first'] + ' ' + df['last']\n\n\nlibrary(stringr)\n\n# String functions\nstr_to_lower(df$name)           # Lowercase\nstr_to_upper(df$name)           # Uppercase\nstr_to_title(df$name)           # Title case\nstr_trim(df$name)               # Remove whitespace\nstr_length(df$name)             # String length\n\n# Pattern matching\nstr_detect(df$name, \"pattern\")\nstr_starts(df$name, \"A\")\nstr_ends(df$name, \"z\")\n\n# Extraction and replacement\nstr_extract(df$name, \"\\\\d+\")    # Extract numbers\nstr_replace(df$name, \"old\", \"new\")\nstr_split(df$name, \"_\")         # Split\n\n# Concatenation\nstr_c(df$first, df$last, sep = \" \")\npaste(df$first, df$last)\n\n\n# String functions\nlowercase.(df.name)              # Lowercase\nuppercase.(df.name)              # Uppercase\ntitlecase.(df.name)              # Title case\nstrip.(df.name)                  # Remove whitespace\nlength.(df.name)                 # String length\n\n# Pattern matching\noccursin.(\"pattern\", df.name)\nstartswith.(df.name, \"A\")\nendswith.(df.name, \"z\")\n\n# Extraction and replacement\nmatch.(r\"\\d+\", df.name)          # Extract numbers\nreplace.(df.name, \"old\" =&gt; \"new\")\nsplit.(df.name, \"_\")             # Split\n\n# Concatenation\ndf.full_name = df.first .* \" \" .* df.last"
  },
  {
    "objectID": "pages/python_r_julia.html#date-and-time",
    "href": "pages/python_r_julia.html#date-and-time",
    "title": "Python, R, and Julia for Data Science",
    "section": "Date and Time",
    "text": "Date and Time\n\nPythonRJulia\n\n\n# Parse dates\ndf['date'] = pd.to_datetime(df['date_string'])\ndf['date'] = pd.to_datetime(df['date_string'], format='%Y-%m-%d')\n\n# Extract components\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\ndf['weekday'] = df['date'].dt.dayofweek\ndf['quarter'] = df['date'].dt.quarter\n\n# Date arithmetic\ndf['next_month'] = df['date'] + pd.DateOffset(months=1)\ndf['days_diff'] = (df['end_date'] - df['start_date']).dt.days\n\n# Date ranges\ndates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\nbusiness_days = pd.bdate_range('2023-01-01', '2023-12-31')\n\n\nlibrary(lubridate)\n\n# Parse dates\ndf$date &lt;- ymd(df$date_string)\ndf$date &lt;- as.Date(df$date_string, format = \"%Y-%m-%d\")\n\n# Extract components\ndf$year &lt;- year(df$date)\ndf$month &lt;- month(df$date)\ndf$day &lt;- day(df$date)\ndf$weekday &lt;- wday(df$date)\ndf$quarter &lt;- quarter(df$date)\n\n# Date arithmetic\ndf$next_month &lt;- df$date %m+% months(1)\ndf$days_diff &lt;- as.numeric(df$end_date - df$start_date)\n\n# Date sequences\ndates &lt;- seq(ymd(\"2023-01-01\"), ymd(\"2023-12-31\"), by = \"day\")\n\n\nusing Dates\n\n# Parse dates\ndf.date = Date.(df.date_string, \"yyyy-mm-dd\")\n\n# Extract components\ndf.year = year.(df.date)\ndf.month = month.(df.date)\ndf.day = day.(df.date)\ndf.weekday = dayofweek.(df.date)\ndf.quarter = quarterofyear.(df.date)\n\n# Date arithmetic\ndf.next_month = df.date .+ Month(1)\ndf.days_diff = df.end_date .- df.start_date\n\n# Date ranges\ndates = Date(2023,1,1):Day(1):Date(2023,12,31)"
  },
  {
    "objectID": "pages/python_r_julia.html#statistical-operations",
    "href": "pages/python_r_julia.html#statistical-operations",
    "title": "Python, R, and Julia for Data Science",
    "section": "Statistical Operations",
    "text": "Statistical Operations\n\nPythonRJulia\n\n\n# Descriptive statistics\ndf.mean()\ndf.median()\ndf.std()\ndf.var()\ndf.quantile([0.25, 0.75])\ndf.corr()                       # Correlation matrix\n\n# Rolling statistics\ndf['rolling_mean'] = df['value'].rolling(window=7).mean()\ndf['rolling_std'] = df['value'].rolling(window=7).std()\n\n# Ranking\ndf['rank'] = df['value'].rank()\ndf['pct_rank'] = df['value'].rank(pct=True)\n\n# Statistical tests\nfrom scipy import stats\nt_stat, p_value = stats.ttest_ind(group1, group2)\ncorrelation, p_value = stats.pearsonr(x, y)\n\n\n# Descriptive statistics\nmean(df$value)\nmedian(df$value)\nsd(df$value)\nvar(df$value)\nquantile(df$value, c(0.25, 0.75))\ncor(df[, numeric_cols])        # Correlation matrix\n\n# Rolling statistics (using zoo or slider)\nlibrary(zoo)\ndf$rolling_mean &lt;- rollmean(df$value, 7, fill = NA)\n\n# Ranking\ndf$rank &lt;- rank(df$value)\ndf$pct_rank &lt;- percent_rank(df$value)\n\n# Statistical tests\nt.test(group1, group2)\ncor.test(x, y)\n\n\nusing Statistics\n\n# Descriptive statistics\nmean(df.value)\nmedian(df.value)\nstd(df.value)\nvar(df.value)\nquantile(df.value, [0.25, 0.75])\ncor(Matrix(df[:, numeric_cols]))  # Correlation matrix\n\n# Rolling statistics\nusing RollingFunctions\ndf.rolling_mean = rollmean(df.value, 7)\ndf.rolling_std = rollstd(df.value, 7)\n\n# Ranking\nusing StatsBase\ndf.rank = ordinalrank(df.value)\ndf.pct_rank = percentrank(df.value)\n\n# Statistical tests\nusing HypothesisTests\nOneSampleTTest(group1, group2)\nCorrelationTest(x, y)"
  },
  {
    "objectID": "pages/python_r_julia.html#visualization-basics",
    "href": "pages/python_r_julia.html#visualization-basics",
    "title": "Python, R, and Julia for Data Science",
    "section": "Visualization Basics",
    "text": "Visualization Basics\n\nPythonRJulia\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Basic plots\nplt.plot(x, y)                 # Line plot\nplt.scatter(x, y)              # Scatter plot\nplt.hist(data, bins=30)        # Histogram\nplt.bar(categories, values)    # Bar plot\n\n# Seaborn plots\nsns.scatterplot(data=df, x='x', y='y', hue='category')\nsns.boxplot(data=df, x='category', y='value')\nsns.heatmap(df.corr(), annot=True)\n\n# Pandas plotting\ndf.plot(kind='line')\ndf.plot(kind='scatter', x='col1', y='col2')\ndf['value'].hist()\n\n\nlibrary(ggplot2)\n\n# Basic ggplot\nggplot(df, aes(x = x, y = y)) + \n  geom_point()                  # Scatter plot\n\nggplot(df, aes(x = x, y = y)) + \n  geom_line()                   # Line plot\n\nggplot(df, aes(x = value)) + \n  geom_histogram(bins = 30)    # Histogram\n\nggplot(df, aes(x = category, y = value)) + \n  geom_boxplot()                # Boxplot\n\n# Faceting\nggplot(df, aes(x = x, y = y)) + \n  geom_point() + \n  facet_wrap(~ category)\n\n\nusing Plots\n\n# Basic plots\nplot(x, y)                      # Line plot\nscatter(x, y)                   # Scatter plot\nhistogram(data, bins=30)        # Histogram\nbar(categories, values)         # Bar plot\n\n# StatsPlots for DataFrames\nusing StatsPlots\n@df df scatter(:x, :y, group=:category)\n@df df boxplot(:category, :value)\n\n# Multiple series\nplot(x, [y1 y2 y3], label=[\"Series 1\" \"Series 2\" \"Series 3\"])"
  },
  {
    "objectID": "pages/python_r_julia.html#performance-optimization",
    "href": "pages/python_r_julia.html#performance-optimization",
    "title": "Python, R, and Julia for Data Science",
    "section": "Performance Optimization",
    "text": "Performance Optimization\n\nPythonRJulia\n\n\n# Vectorization\n# Bad: Loop\nresult = []\nfor i in range(len(df)):\n    result.append(df.iloc[i]['col1'] * 2)\n\n# Good: Vectorized\nresult = df['col1'] * 2\n\n# Use NumPy for numerical operations\nnp_array = df['col1'].values\nresult = np_array * 2\n\n# Categorical data for memory efficiency\ndf['category'] = df['category'].astype('category')\n\n# Parallel processing\nfrom multiprocessing import Pool\nwith Pool(4) as p:\n    results = p.map(process_function, data_chunks)\n\n\n# Vectorization\n# Bad: Loop\nresult &lt;- c()\nfor(i in 1:nrow(df)) {\n  result[i] &lt;- df$col1[i] * 2\n}\n\n# Good: Vectorized\nresult &lt;- df$col1 * 2\n\n# Use data.table for speed\nlibrary(data.table)\ndt &lt;- as.data.table(df)\ndt[, new_col := col1 * 2]\n\n# Parallel processing\nlibrary(parallel)\ncl &lt;- makeCluster(4)\nresults &lt;- parLapply(cl, data_chunks, process_function)\nstopCluster(cl)\n\n\n# Julia is fast by default!\n# Type stability\nfunction process_data(x::Vector{Float64})\n    return x .* 2\nend\n\n# Broadcasting\nresult = df.col1 .* 2\n\n# Parallel processing\nusing Distributed\naddprocs(4)\n@distributed for i in 1:n\n    process_chunk(data[i])\nend\n\n# Threads\nThreads.@threads for i in 1:n\n    process_chunk(data[i])\nend"
  },
  {
    "objectID": "pages/python_r_julia.html#machine-learning-basics",
    "href": "pages/python_r_julia.html#machine-learning-basics",
    "title": "Python, R, and Julia for Data Science",
    "section": "Machine Learning Basics",
    "text": "Machine Learning Basics\n\nPythonRJulia\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\n\n\n# Split data\nlibrary(caret)\ntrain_idx &lt;- createDataPartition(y, p = 0.8, list = FALSE)\nX_train &lt;- X[train_idx, ]\nX_test &lt;- X[-train_idx, ]\ny_train &lt;- y[train_idx]\ny_test &lt;- y[-train_idx]\n\n# Train model\nmodel &lt;- lm(y ~ ., data = train_data)\n\n# Predict\ny_pred &lt;- predict(model, newdata = test_data)\n\n# Evaluate\nmse &lt;- mean((y_test - y_pred)^2)\n\n\nusing MLJ\n\n# Split data\ntrain, test = partition(eachindex(y), 0.8, shuffle=true)\nX_train, X_test = X[train, :], X[test, :]\ny_train, y_test = y[train], y[test]\n\n# Train model\nLinearRegressor = @load LinearRegressor pkg=MLJLinearModels\nmodel = LinearRegressor()\nmach = machine(model, X_train, y_train)\nfit!(mach)\n\n# Predict\ny_pred = predict(mach, X_test)\n\n# Evaluate\nmse = mean((y_test .- y_pred).^2)"
  },
  {
    "objectID": "pages/python_r_julia.html#best-practices-and-tips",
    "href": "pages/python_r_julia.html#best-practices-and-tips",
    "title": "Python, R, and Julia for Data Science",
    "section": "Best Practices and Tips",
    "text": "Best Practices and Tips\n\nWhen to Use Each Language\nPython - General-purpose programming - Machine learning and deep learning - Web applications with data backends - Large ecosystem of libraries - Franklin ecosystem integration\nR - Statistical analysis and modeling - Academic research - Data visualization (ggplot2) - Statistical reporting (R Markdown)\nJulia - High-performance computing - Scientific simulations - Numerical optimization - When Python is too slow but C is too complex\n\n\nCommon Pitfalls and Solutions\n\n\n\nIssue\nPython\nR\nJulia\n\n\n\n\nMemory\nUse chunks, dask\nUse data.table\nBuilt-in efficiency\n\n\nSpeed\nUse NumPy, Numba\nUse Rcpp\nAlready fast\n\n\nType Issues\nCheck dtypes\nUse typeof()\nType annotations\n\n\nMissing Data\nUse pd.NA\nUse NA\nUse missing\n\n\n\n\n\nPackage Ecosystems\n\n\n\n\n\n\n\n\n\nDomain\nPython\nR\nJulia\n\n\n\n\nData Manipulation\npandas\ndplyr, data.table\nDataFrames.jl\n\n\nVisualization\nmatplotlib, seaborn\nggplot2\nPlots.jl\n\n\nMachine Learning\nscikit-learn\ncaret, mlr3\nMLJ.jl\n\n\nDeep Learning\nTensorFlow, PyTorch\nkeras, torch\nFlux.jl\n\n\nStatistics\nscipy, statsmodels\nBuilt-in, many packages\nStatsBase.jl"
  },
  {
    "objectID": "pages/python_r_julia.html#franklin-integration",
    "href": "pages/python_r_julia.html#franklin-integration",
    "title": "Python, R, and Julia for Data Science",
    "section": "Franklin Integration",
    "text": "Franklin Integration\n\nUsing These Languages in Franklin\nFranklin exercises support all three languages through Docker containers:\n# Python in Franklin\nimport pandas as pd\nimport numpy as np\n# Franklin automatically installs required packages\n# R in Franklin\nlibrary(tidyverse)\n# Use pixi.toml for R package management\n# Julia in Franklin\nusing DataFrames\n# Julia packages managed through Project.toml\n\n\nBest Practices for Franklin Exercises\n\nPython (Recommended): Default choice for Franklin exercises\nR: Use for statistics-focused courses\nJulia: Use for high-performance computing courses"
  },
  {
    "objectID": "pages/python_r_julia.html#conclusion",
    "href": "pages/python_r_julia.html#conclusion",
    "title": "Python, R, and Julia for Data Science",
    "section": "Conclusion",
    "text": "Conclusion\nEach language has its strengths: - Python: Versatility and ecosystem - R: Statistical depth and visualization - Julia: Performance and mathematical elegance\nChoose based on your specific needs, team expertise, and project requirements. Many data scientists use multiple languages, leveraging each for its strengths.\n\nFurther Resources\nPython - Pandas Documentation - Python Data Science Handbook\nR - R for Data Science - Advanced R\nJulia - Julia Documentation - Julia Data Science\nHappy coding in your language of choice!"
  },
  {
    "objectID": "pages/python_users_guide.html",
    "href": "pages/python_users_guide.html",
    "title": "Franklin for Python & Jupyter Users",
    "section": "",
    "text": "If you’re already familiar with Python and Jupyter, Franklin streamlines your workflow by handling environment management, dependency resolution, and exercise distribution. This guide covers advanced features and best practices for experienced users.",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#overview",
    "href": "pages/python_users_guide.html#overview",
    "title": "Franklin for Python & Jupyter Users",
    "section": "",
    "text": "If you’re already familiar with Python and Jupyter, Franklin streamlines your workflow by handling environment management, dependency resolution, and exercise distribution. This guide covers advanced features and best practices for experienced users.",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#quick-start",
    "href": "pages/python_users_guide.html#quick-start",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Quick Start",
    "text": "Quick Start\n# Install Franklin with educator tools using Pixi\npixi global install franklin franklin-educator --channel conda-forge --channel munch-group\n\n# Alternative: Using conda\n# conda install -c conda-forge -c munch-group franklin franklin-educator\n\n# Download and work on exercises\nfranklin download              # Interactive exercise selection\nfranklin jupyter               # Launch in containerized environment\n\n# Create and manage exercises (educators)\nfranklin exercise new          # Create new exercise\nfranklin exercise edit         # Edit existing exercise",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#understanding-franklins-architecture",
    "href": "pages/python_users_guide.html#understanding-franklins-architecture",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Understanding Franklin’s Architecture",
    "text": "Understanding Franklin’s Architecture\n\nEnvironment Management\nFranklin uses Docker containers to ensure reproducibility:\n\nEach exercise runs in an isolated container\nDependencies are managed via Pixi (modern conda replacement)\nAutomatic dependency detection from notebook imports\nZero conflicts between different exercises or courses\n\n\n\nThe Franklin Magic\nInside Jupyter notebooks, Franklin provides magic commands for package management:\n# Load the Franklin magic\n%load_ext magic\n\n# Install packages on-the-fly\n%franklin numpy pandas scikit-learn\n\n# Alternative syntax\n%pixi_install matplotlib seaborn\nThese commands: - Install packages in the current container - Update the pixi.toml manifest - Persist across notebook sessions - Work identically on all platforms",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#advanced-workflows",
    "href": "pages/python_users_guide.html#advanced-workflows",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Advanced Workflows",
    "text": "Advanced Workflows\n\n\nWorking with Custom Environments\nFranklin exercises use pixi.toml for dependency management:\n[project]\nname = \"data-science-exercise\"\nplatforms = [\"linux-64\", \"osx-arm64\", \"win-64\"]\n\n[dependencies]\npython = \"3.11.*\"\njupyter = \"*\"\nnumpy = \"&gt;=1.24\"\npandas = \"&gt;=2.0\"\n\n[feature.exercise.dependencies]\nscikit-learn = \"*\"\nmatplotlib = \"*\"\nTo add dependencies programmatically:\nimport subprocess\n\ndef add_package(package_name):\n    \"\"\"Add a package to the exercise environment\"\"\"\n    subprocess.run([\n        \"pixi\", \"add\", \n        \"--feature\", \"exercise\", \n        \"--platform\", \"linux-64\",\n        package_name\n    ])\n\nadd_package(\"tensorflow\")\n\n\nCustomizing Docker Containers\nEach exercise includes a Dockerfile you can customize:\n# Use course-specific base image\nFROM registry.gitlab.com/franklin/courses/data-science:latest\n\n# Add system dependencies\nRUN apt-get update && apt-get install -y \\\n    graphviz \\\n    ffmpeg\n\n# Install additional Python packages\nRUN pixi add --feature exercise \\\n    pytorch \\\n    transformers\n\n# Copy exercise files\nCOPY . /workspace\nWORKDIR /workspace\n\n\nGit Integration for Version Control\nFranklin exercises are Git repositories by default:\n# After downloading an exercise\ncd \"Exercise Name\"\n\n# Track your changes\ngit add -A\ngit commit -m \"Completed data analysis section\"\n\n# Create your own remote\ngit remote add personal https://github.com/you/solutions\ngit push personal main\n\n\nBatch Processing Multiple Exercises\nProcess multiple exercises programmatically:\nimport subprocess\nimport json\nfrom pathlib import Path\n\ndef get_exercises(course_name):\n    \"\"\"Get all exercises for a course\"\"\"\n    result = subprocess.run(\n        [\"franklin\", \"list\", \"--json\"],\n        capture_output=True,\n        text=True\n    )\n    exercises = json.loads(result.stdout)\n    return exercises.get(course_name, [])\n\ndef batch_download(course_name):\n    \"\"\"Download all exercises for a course\"\"\"\n    exercises = get_exercises(course_name)\n    for exercise in exercises:\n        subprocess.run([\n            \"franklin\", \"download\",\n            \"--course\", course_name,\n            \"--exercise\", exercise\n        ])\n\n# Download all exercises\nbatch_download(\"Advanced Python\")",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#creating-exercises-educators",
    "href": "pages/python_users_guide.html#creating-exercises-educators",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Creating Exercises (Educators)",
    "text": "Creating Exercises (Educators)\n\nExercise Structure\nA typical Franklin exercise contains:\nexercise-name/\n├── Dockerfile           # Container configuration\n├── pixi.toml           # Dependency specification\n├── exercise.ipynb      # Main notebook\n├── README.md           # Instructions\n├── tests/              # Automated tests\n│   └── test_solution.py\n├── data/               # Dataset files\n│   └── sample.csv\n└── solutions/          # Hidden from students\n    └── solution.ipynb\n\n\nAutomated Testing\nImplement automated testing for exercises:\n# tests/test_solution.py\nimport pytest\nimport pandas as pd\nfrom pathlib import Path\n\ndef test_data_loading():\n    \"\"\"Test that students load data correctly\"\"\"\n    # Import student's notebook\n    import import_ipynb\n    import exercise\n    \n    # Check that dataframe was created\n    assert hasattr(exercise, 'df')\n    assert isinstance(exercise.df, pd.DataFrame)\n    assert len(exercise.df) &gt; 0\n\ndef test_analysis_complete():\n    \"\"\"Test that analysis was performed\"\"\"\n    import exercise\n    \n    # Check for expected variables\n    assert hasattr(exercise, 'mean_value')\n    assert hasattr(exercise, 'correlation_matrix')\n    \n    # Validate results\n    assert 0 &lt;= exercise.correlation_matrix.max().max() &lt;= 1\n\n# Run tests automatically\nif __name__ == \"__main__\":\n    pytest.main([__file__])\n\n\nDependency Detection\nFranklin automatically detects dependencies from imports:\n# Franklin detects these and adds to pixi.toml\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Custom modules need explicit installation\n%franklin scikit-image opencv-python\n\n\nPublishing Exercises\n# Create new exercise\nfranklin exercise new\n\n# Follow prompts:\n# - Course: Machine Learning\n# - Exercise: Neural Networks Lab\n# - Template: default\n\n# Edit the exercise\ncd \"Neural Networks Lab\"\njupyter lab exercise.ipynb\n\n# Test locally\npixi run test-notebook\n\n# Publish for students\nfranklin exercise publish",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#performance-optimization",
    "href": "pages/python_users_guide.html#performance-optimization",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Performance Optimization",
    "text": "Performance Optimization\n\nContainer Management\n# List Franklin containers\ndocker ps -a | grep franklin\n\n# Clean up old containers\nfranklin cleanup --days 7\n\n# Prune Docker resources\ndocker system prune -a\n\n# Limit container resources\nfranklin jupyter --memory 4g --cpus 2\n\n\nCaching and Persistence\nFranklin caches: - Docker images per exercise - Pixi environments - Downloaded exercises\nTo manage cache:\n# Clear Franklin cache\nfranklin cache clear\n\n# Keep specific courses\nfranklin cache clear --keep-course \"Data Science\"\n\n# Export environment for offline use\nfranklin export --course \"ML\" --exercise \"Lab1\" --output lab1.tar",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#integration-with-external-tools",
    "href": "pages/python_users_guide.html#integration-with-external-tools",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Integration with External Tools",
    "text": "Integration with External Tools\n\nVS Code Integration\n// .vscode/settings.json\n{\n    \"python.defaultInterpreterPath\": \"/opt/conda/bin/python\",\n    \"jupyter.jupyterServerType\": \"remote\",\n    \"docker.containers.label\": \"franklin\",\n    \"python.linting.enabled\": true,\n    \"python.formatting.provider\": \"black\"\n}\n\n\nCI/CD Pipeline Integration\n# .gitlab-ci.yml\ntest-exercise:\n  image: registry.gitlab.com/franklin/base:latest\n  script:\n    - pixi install\n    - pixi run test-notebook\n    - pixi run pytest tests/\n  artifacts:\n    reports:\n      junit: test-results.xml\n\n\nCustom Extensions\nCreate JupyterLab extensions for Franklin:\n// franklin-extension/src/index.ts\nimport { JupyterFrontEndPlugin } from '@jupyterlab/application';\n\nconst plugin: JupyterFrontEndPlugin&lt;void&gt; = {\n  id: 'franklin-tools',\n  autoStart: true,\n  activate: (app) =&gt; {\n    console.log('Franklin Tools activated');\n    // Add custom toolbar buttons, menu items, etc.\n  }\n};\n\nexport default plugin;",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#debugging-and-profiling",
    "href": "pages/python_users_guide.html#debugging-and-profiling",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Debugging and Profiling",
    "text": "Debugging and Profiling\n\nDebug Mode\n# Enable verbose output\nFRANKLIN_DEBUG=1 franklin jupyter\n\n# View container logs\nfranklin logs --tail 50\n\n# Access container shell\nfranklin shell\n\n\nPerformance Profiling\n# Profile notebook execution\nimport cProfile\nimport pstats\n\ndef profile_notebook():\n    profiler = cProfile.Profile()\n    profiler.enable()\n    \n    # Run your notebook code\n    exec(open('exercise.ipynb').read())\n    \n    profiler.disable()\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(20)\n\nprofile_notebook()",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#best-practices",
    "href": "pages/python_users_guide.html#best-practices",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Best Practices",
    "text": "Best Practices\n\nFor Students\n\nVersion Control: Commit your work frequently\nDocumentation: Add markdown cells explaining your approach\nTesting: Run all cells before submission\nResources: Monitor memory usage in resource-intensive exercises\n\n\n\nFor Educators\n\nReproducibility: Test exercises on both Mac and Windows\nDependencies: Minimize dependencies, pin critical versions\nData: Include sample data, provide download scripts for large datasets\nSolutions: Maintain separate solution branches\nFeedback: Use automated testing for instant feedback\n\n\n\nSecurity Considerations\n\nExercises run in isolated containers\nNetwork access can be restricted\nFile system access is sandboxed\nSensitive data should use environment variables:\n\nimport os\n\n# Access secure credentials\napi_key = os.environ.get('API_KEY')\ndb_password = os.environ.get('DB_PASSWORD')",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#advanced-configuration",
    "href": "pages/python_users_guide.html#advanced-configuration",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Advanced Configuration",
    "text": "Advanced Configuration\n\nFranklin Settings\n// ~/.franklin/settings.json\n{\n    \"default_course\": \"Advanced Python\",\n    \"jupyter_port\": 8888,\n    \"container_prefix\": \"franklin\",\n    \"auto_update\": true,\n    \"telemetry\": false,\n    \"max_containers\": 5,\n    \"default_memory\": \"4g\",\n    \"default_cpus\": 2\n}\n\n\nCustom Base Images\nCreate specialized base images for your courses:\n# Dockerfile.base\nFROM continuumio/miniconda3:latest\n\n# Install system dependencies\nRUN apt-get update && \\\n    apt-get install -y build-essential\n\n# Install Pixi\nRUN curl -fsSL https://pixi.sh/install.sh | bash\n\n# Pre-install common packages\nRUN pixi global install \\\n    jupyter \\\n    numpy \\\n    pandas \\\n    matplotlib\n\n# Set up workspace\nWORKDIR /workspace",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#troubleshooting",
    "href": "pages/python_users_guide.html#troubleshooting",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nCommon Issues\nImport errors after package installation\n# Restart kernel after installing packages\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(True)\nMemory errors with large datasets\n# Use chunked processing\nimport pandas as pd\n\nfor chunk in pd.read_csv('large_file.csv', chunksize=10000):\n    process(chunk)\nSlow container startup\n# Pre-pull base images\ndocker pull registry.gitlab.com/franklin/base:latest\n\n# Increase Docker resources\n# Docker Desktop → Preferences → Resources",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#contributing-to-franklin",
    "href": "pages/python_users_guide.html#contributing-to-franklin",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Contributing to Franklin",
    "text": "Contributing to Franklin\nInterested in contributing? See our Developer Guide for information on:\n\nSetting up a development environment\nFranklin’s plugin architecture\nCreating custom templates\nContributing to core functionality",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/python_users_guide.html#resources",
    "href": "pages/python_users_guide.html#resources",
    "title": "Franklin for Python & Jupyter Users",
    "section": "Resources",
    "text": "Resources\n\nFranklin GitHub Repository\nPixi Documentation\nDocker Best Practices\nJupyterLab Extensions Guide",
    "crumbs": [
      "Developer Resources",
      "Franklin for Python & Jupyter Users"
    ]
  },
  {
    "objectID": "pages/ssh.html",
    "href": "pages/ssh.html",
    "title": "Introduction to SSH",
    "section": "",
    "text": "SSH (Secure Shell) is a protocol that allows you to securely connect to remote computers over a network. Think of it as a secure telephone line between your computer and another computer—you can run commands, transfer files, and work on the remote machine as if you were sitting right in front of it.\n\n\n\nSecurity: All communication is encrypted\nRemote Work: Access servers and clusters from anywhere\nFile Transfer: Securely copy files between machines\nAutomation: Run scripts on remote servers\nGit Integration: Push/pull to GitHub/GitLab without passwords",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#what-is-ssh",
    "href": "pages/ssh.html#what-is-ssh",
    "title": "Introduction to SSH",
    "section": "",
    "text": "SSH (Secure Shell) is a protocol that allows you to securely connect to remote computers over a network. Think of it as a secure telephone line between your computer and another computer—you can run commands, transfer files, and work on the remote machine as if you were sitting right in front of it.\n\n\n\nSecurity: All communication is encrypted\nRemote Work: Access servers and clusters from anywhere\nFile Transfer: Securely copy files between machines\nAutomation: Run scripts on remote servers\nGit Integration: Push/pull to GitHub/GitLab without passwords",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#how-ssh-works",
    "href": "pages/ssh.html#how-ssh-works",
    "title": "Introduction to SSH",
    "section": "How SSH Works",
    "text": "How SSH Works\nSSH uses a pair of cryptographic keys for authentication:\ngraph LR\n    A[Your Computer&lt;br/&gt;Private Key 🔑] --&gt;|Encrypted Connection| B[Remote Server&lt;br/&gt;Public Key 🔓]\n    B --&gt;|Challenge| A\n    A --&gt;|Response| B\n\nPrivate Key: Secret key that never leaves your computer\nPublic Key: Can be shared freely, stored on servers\nAuthentication: Server verifies you have the matching private key",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#setting-up-ssh-keys",
    "href": "pages/ssh.html#setting-up-ssh-keys",
    "title": "Introduction to SSH",
    "section": "Setting Up SSH Keys",
    "text": "Setting Up SSH Keys\n\nStep 1: Check for Existing Keys\nFirst, check if you already have SSH keys:\nls -la ~/.ssh\nLook for files like: - id_rsa (private key) - id_rsa.pub (public key) - id_ed25519 (newer algorithm private key) - id_ed25519.pub (newer algorithm public key)\n\n\nStep 2: Generate SSH Keys\nIf you don’t have keys, generate them:\n# Generate RSA key (traditional)\nssh-keygen -t rsa -b 4096 -C \"your.email@example.com\"\n\n# Or generate Ed25519 key (recommended, more secure)\nssh-keygen -t ed25519 -C \"your.email@example.com\"\nWhen prompted: 1. File location: Press Enter for default 2. Passphrase: Optional but recommended for extra security 3. Confirm passphrase: Re-enter if you set one\n\n\nStep 3: View Your Public Key\n# Display your public key\ncat ~/.ssh/id_rsa.pub\n# or\ncat ~/.ssh/id_ed25519.pub\nThis is the key you’ll share with servers and services.",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#using-ssh",
    "href": "pages/ssh.html#using-ssh",
    "title": "Introduction to SSH",
    "section": "Using SSH",
    "text": "Using SSH\n\nBasic Connection\n# Connect to a remote server\nssh username@hostname\n\n# Examples\nssh john@192.168.1.100\nssh student@server.university.edu\nssh admin@myserver.com\n\n# Connect with specific port\nssh -p 2222 username@hostname\n\n\nFirst Connection\nWhen connecting to a new server:\nThe authenticity of host 'server.com (192.168.1.1)' can't be established.\nRSA key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxx.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? \nType yes if you trust the server.\n\n\nSSH with Password\nIf you haven’t set up key authentication:\nssh username@hostname\n# Enter password when prompted\n\n\nSSH with Key\nOnce your public key is on the server:\nssh username@hostname\n# No password needed!",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#setting-up-password-less-access",
    "href": "pages/ssh.html#setting-up-password-less-access",
    "title": "Introduction to SSH",
    "section": "Setting Up Password-less Access",
    "text": "Setting Up Password-less Access\n\nMethod 1: ssh-copy-id (Easiest)\n# Copy your public key to the server\nssh-copy-id username@hostname\n\n# Enter your password one last time\n# Future connections won't need a password\n\n\nMethod 2: Manual Setup\n# 1. Copy your public key\ncat ~/.ssh/id_rsa.pub\n\n# 2. Connect to server\nssh username@hostname\n\n# 3. Add key to authorized_keys\nmkdir -p ~/.ssh\necho \"YOUR_PUBLIC_KEY_HERE\" &gt;&gt; ~/.ssh/authorized_keys\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/authorized_keys",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#ssh-config-file",
    "href": "pages/ssh.html#ssh-config-file",
    "title": "Introduction to SSH",
    "section": "SSH Config File",
    "text": "SSH Config File\nSimplify connections with SSH config:\n\nCreate/Edit Config\nnano ~/.ssh/config\n\n\nAdd Server Configurations\n# ~/.ssh/config\n\nHost myserver\n    HostName server.example.com\n    User john\n    Port 22\n    IdentityFile ~/.ssh/id_rsa\n\nHost university\n    HostName cluster.uni.edu\n    User student123\n    Port 2222\n\nHost gitlab\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/id_ed25519\n\n\nUse Simplified Names\n# Instead of:\nssh john@server.example.com\n\n# Just use:\nssh myserver",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#file-transfer-with-ssh",
    "href": "pages/ssh.html#file-transfer-with-ssh",
    "title": "Introduction to SSH",
    "section": "File Transfer with SSH",
    "text": "File Transfer with SSH\n\nSCP (Secure Copy)\n# Copy file to remote\nscp localfile.txt username@hostname:/path/to/destination/\n\n# Copy file from remote\nscp username@hostname:/path/to/file.txt ./\n\n# Copy entire directory\nscp -r local_directory/ username@hostname:/path/to/destination/\n\n# Using SSH config alias\nscp file.txt myserver:~/documents/\n\n\nSFTP (Secure FTP)\n# Start SFTP session\nsftp username@hostname\n\n# SFTP commands\nsftp&gt; ls                    # List remote files\nsftp&gt; pwd                   # Show remote directory\nsftp&gt; cd /path/to/dir       # Change remote directory\nsftp&gt; get remote_file.txt   # Download file\nsftp&gt; put local_file.txt    # Upload file\nsftp&gt; exit                  # Close connection",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#ssh-with-git",
    "href": "pages/ssh.html#ssh-with-git",
    "title": "Introduction to SSH",
    "section": "SSH with Git",
    "text": "SSH with Git\n\nGitHub SSH Setup\n\nAdd SSH key to GitHub:\n\nGo to GitHub → Settings → SSH and GPG keys\nClick “New SSH key”\nPaste your public key\n\nTest connection:\nssh -T git@github.com\nClone with SSH:\ngit clone git@github.com:username/repository.git\n\n\n\nGitLab SSH Setup\n\nAdd SSH key to GitLab:\n\nGo to GitLab → Settings → SSH Keys\nPaste your public key\n\nTest connection:\nssh -T git@gitlab.com\nUse SSH for Git:\ngit remote set-url origin git@gitlab.com:username/project.git",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#ssh-tunneling",
    "href": "pages/ssh.html#ssh-tunneling",
    "title": "Introduction to SSH",
    "section": "SSH Tunneling",
    "text": "SSH Tunneling\nCreate secure tunnels for accessing remote services:\n\nLocal Port Forwarding\nAccess remote service through local port:\n# Access remote database locally\nssh -L 3306:localhost:3306 username@hostname\n\n# Access remote Jupyter notebook\nssh -L 8888:localhost:8888 username@hostname\n\n\nExample: Remote Jupyter\n# 1. On remote server, start Jupyter\njupyter notebook --no-browser --port=8888\n\n# 2. On local machine, create tunnel\nssh -L 8888:localhost:8888 username@hostname\n\n# 3. Open browser to http://localhost:8888",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#ssh-agent",
    "href": "pages/ssh.html#ssh-agent",
    "title": "Introduction to SSH",
    "section": "SSH Agent",
    "text": "SSH Agent\nManage keys and passphrases efficiently:\n\nStart SSH Agent\n# Start agent\neval \"$(ssh-agent -s)\"\n\n# Add key to agent\nssh-add ~/.ssh/id_rsa\n\n# Add with passphrase caching\nssh-add -t 3600 ~/.ssh/id_rsa  # Cache for 1 hour\n\n\nList Loaded Keys\nssh-add -l",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#common-ssh-commands",
    "href": "pages/ssh.html#common-ssh-commands",
    "title": "Introduction to SSH",
    "section": "Common SSH Commands",
    "text": "Common SSH Commands\n\n\n\nCommand\nPurpose\n\n\n\n\nssh user@host\nConnect to remote host\n\n\nssh -p 2222 user@host\nConnect on specific port\n\n\nssh-keygen\nGenerate SSH keys\n\n\nssh-copy-id user@host\nCopy public key to server\n\n\nscp file user@host:~/\nCopy file to remote\n\n\nsftp user@host\nStart SFTP session\n\n\nssh -L 8080:localhost:80 user@host\nCreate tunnel\n\n\nssh-add\nAdd key to SSH agent\n\n\nssh -X user@host\nEnable X11 forwarding",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#troubleshooting",
    "href": "pages/ssh.html#troubleshooting",
    "title": "Introduction to SSH",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nPermission Denied\n# Check key permissions\nls -la ~/.ssh/\n\n# Fix permissions\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/id_rsa\nchmod 644 ~/.ssh/id_rsa.pub\nchmod 600 ~/.ssh/config\n\n\nConnection Refused\n# Check if SSH service is running on server\nssh -v username@hostname  # Verbose mode\n\n# Common issues:\n# - Wrong port\n# - Firewall blocking connection\n# - SSH service not running\n\n\nKey Not Working\n# Debug authentication\nssh -vv username@hostname\n\n# Check authorized_keys on server\ncat ~/.ssh/authorized_keys\n\n# Ensure correct permissions on server\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/authorized_keys",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#security-best-practices",
    "href": "pages/ssh.html#security-best-practices",
    "title": "Introduction to SSH",
    "section": "Security Best Practices",
    "text": "Security Best Practices\n\nDo’s\n\n✅ Use strong passphrases for keys\n✅ Use Ed25519 keys (more secure than RSA)\n✅ Keep private keys private\n✅ Use different keys for different services\n✅ Regularly rotate keys\n✅ Use SSH config for organization\n\n\n\nDon’ts\n\n❌ Share private keys\n❌ Use password authentication when keys are available\n❌ Ignore host key warnings\n❌ Use weak or no passphrases\n❌ Store private keys in insecure locations",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#ssh-with-franklin",
    "href": "pages/ssh.html#ssh-with-franklin",
    "title": "Introduction to SSH",
    "section": "SSH with Franklin",
    "text": "SSH with Franklin\nFranklin exercises often involve SSH for:\n\nAccessing Remote Clusters\n# SSH to university cluster\nssh student@cluster.university.edu\n\n# Run Franklin on remote server\nfranklin jupyter --remote\n\n\nGit Operations\n# Configure SSH for GitLab\nssh-keygen -t ed25519 -C \"student@university.edu\"\n\n# Add to GitLab\ncat ~/.ssh/id_ed25519.pub\n# Copy and paste to GitLab → Settings → SSH Keys\n\n# Clone with SSH\ngit clone git@gitlab.university.edu:course/exercise.git",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#quick-setup-guide",
    "href": "pages/ssh.html#quick-setup-guide",
    "title": "Introduction to SSH",
    "section": "Quick Setup Guide",
    "text": "Quick Setup Guide\nFor Franklin users, here’s a quick SSH setup:\n# 1. Generate key\nssh-keygen -t ed25519 -C \"your.email@university.edu\"\n\n# 2. Start SSH agent\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n\n# 3. Copy public key\ncat ~/.ssh/id_ed25519.pub\n\n# 4. Add to GitHub/GitLab\n# Paste the key in settings\n\n# 5. Test connection\nssh -T git@github.com\nssh -T git@gitlab.com\n\n# 6. Configure Git to use SSH\ngit config --global url.\"git@github.com:\".insteadOf \"https://github.com/\"\ngit config --global url.\"git@gitlab.com:\".insteadOf \"https://gitlab.com/\"",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/ssh.html#summary",
    "href": "pages/ssh.html#summary",
    "title": "Introduction to SSH",
    "section": "Summary",
    "text": "Summary\nSSH is essential for: - Secure remote access to servers - Password-less Git operations - Secure file transfers - Running remote commands\nStart with basic key generation and connections, then explore advanced features like tunneling and agent forwarding as needed. Remember: your private key is like your password—keep it safe and never share it!",
    "crumbs": [
      "Reference",
      "Introduction to SSH"
    ]
  },
  {
    "objectID": "pages/terminal.html",
    "href": "pages/terminal.html",
    "title": "The Terminal",
    "section": "",
    "text": "A terminal (also called command line, shell, or console) is a text-based interface for interacting with your computer. Instead of clicking buttons and icons, you type commands to tell the computer what to do. While it might seem intimidating at first, the terminal is an incredibly powerful tool that gives you precise control over your system.\nWhat is Powershell and this Terminal thing? Both programs are what we call terminal emulators. They are used to run other programs, like the ones you will write yourself. We informally refer to both Terminal and Powershell as “the terminal or”the shell”. So if you read something like “open the terminal,” you should open Powershell if you are running Windows and the Terminal application if you are running OS X.\nTo use the terminal, you need to know a few basics. First of all, a terminal lets you execute commands on your computer. You type the command you want and then hit enter. The place where you type is called a prompt (or command prompt), and it may look a little different depending on which terminal emulator you use. In this book, we represent the prompt with the character $. So, a command in the examples below is the line of text to the left of the $. When you open the terminal, you’ll be redirected to a folder. You can see which folder you are in by typing pwd, and then press Enter on the keyboard. When you press Enter, you tell the terminal to execute your written command. In this case, the command you typed tells you the path to the folder we are in. If I do it, I get:\nIf I had been on a Windows machine, it would have looked something like this:",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#what-is-a-terminal",
    "href": "pages/terminal.html#what-is-a-terminal",
    "title": "The Terminal",
    "section": "",
    "text": "A terminal (also called command line, shell, or console) is a text-based interface for interacting with your computer. Instead of clicking buttons and icons, you type commands to tell the computer what to do. While it might seem intimidating at first, the terminal is an incredibly powerful tool that gives you precise control over your system.",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#mac",
    "href": "pages/terminal.html#mac",
    "title": "The Terminal",
    "section": "Mac",
    "text": "Mac\nOn Mac, it is called Terminal. You can find it by typing “Terminal” in Spotlight Search. When you start, you will see something like Figure 1. You may be presented with the following text:\nThe default interactive shell is now zsh.\nTo update your account to use zsh, please run `chsh -s /bin/zsh`.\nFor more details, please visit https://support.apple.com/kb/HT208050.\nDo not update your account to zsh! (If you did so by mistake, you change back using this command: chsh -s /bin/bash).\n\n\n\n\n\n\nFigure 1: The Terminal app on Mac",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#windows",
    "href": "pages/terminal.html#windows",
    "title": "The Terminal",
    "section": "Windows",
    "text": "Windows\nOn Windows, the tool you need is called the Anaconda Powershell Prompt, which was installed along with Anaconda Python. You should be able to find it from the Start menu. If you open Powershell, you should see something like Figure 2.\n\n\n\n\n\n\nFigure 2: Anaconda Powershell Prompt app on Windows",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#navigating-folders",
    "href": "pages/terminal.html#navigating-folders",
    "title": "The Terminal",
    "section": "Navigating folders",
    "text": "Navigating folders\nSo, right now, I am in the programming folder. /Users/kasper/programming is the folder’s path or “full address” with dashes (or backslashes on Windows) separating nested folders. So programming is a subfolder of kasper, a subfolder of Users. That way, you know which folder you are in and where that folder is. Let us see what is in this folder. You can use the ls command (l as in Lima and s as in Sierra). When I do that and press Enter I get the following:\n$ ls\nnotes projects\nThere seem to be two other folders, one called notes and another called projects. If you are curious about what is inside the notes folder, you can “walk” into the folder with the cd command. To use this command, you must specify which folder you want to walk into (in this case, notes). We do this by typing cd, then a space, and then the folder’s name. When I press Enter I get the following:\n$ cd notes\n$\nIt seems that nothing really happened, but if I run the pwd command now to see which folder I am in, I get the following:\n$ pwd\n/Users/kasper/programming/notes\nJust to keep track of what is happening: before we ran the cd command, we were in the directory /Users/kasper/programming folder, and now we’re in /Users/kasper/programming/notes. This means that we can now use the ls command to see what is in the notes folder:\n$ ls\n$\nAgain, it seems like nothing happened. Well, ls and dir do not show anything if the folder we are in is empty. So notes must be empty. Let us go back to where we came from. To walk “back” or “up” to /Users/kasper/programming, we again use the cd command, but we do not need to name a folder this time. Instead, we use the special name .. to say that we wish to go to the parent folder called programming, i.e., the folder we just came from:\n$ cd ..\n$ pwd\n/Users/kasper/programming\nWhen we run the pwd command, we see that we are back where we started. Let us see if the two folders are still there:\n$ ls\nnotes projects\nThey are!",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#working-with-files-and-folders",
    "href": "pages/terminal.html#working-with-files-and-folders",
    "title": "The Terminal",
    "section": "Working with Files and Folders",
    "text": "Working with Files and Folders\nCreate a new folder:\nmkdir my_project\nView entire file:\ncat filename.txt\nCopy file:\ncp source.txt destination.txt\nCopy folder recursively:\ncp -r source_folder destination_folder\nMove/rename file or folder:\nmv old_name.txt new_name.txt\nmv file.txt /path/to/destination/\nDelete file:\nrm file.txt\nDelete with confirmation:\nrm -i file.txt\nDelete empty folder:\nrmdir empty_folder\nDelete folder and all of its content:\nrm -r folder_name\n\nCareful with this command! if you delete some important folder, like your user folder, the command will delete it along with everything inside it - without asking for confirmation!",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#tips-and-tricks",
    "href": "pages/terminal.html#tips-and-tricks",
    "title": "The Terminal",
    "section": "Tips and Tricks",
    "text": "Tips and Tricks\n\nKeyboard Shortcuts\n\n\n\nShortcut\nAction\n\n\n\n\nTab\nAuto-complete file/folder names\n\n\n↑ / ↓\nNavigate command history\n\n\nCtrl + C\nCancel current command\n\n\nCtrl + A\nGo to beginning of line\n\n\nCtrl + E\nGo to end of line\n\n\nCtrl + L\nClear screen (or use clear)\n\n\nCtrl + R\nSearch command history\n\n\nCtrl + D\nExit terminal\n\n\n\n\n\nStuck Terminal\n\nCtrl + C: Stop current command\nCtrl + D: Exit/logout\n\n\n\nSafety First\n\nUse ls before rm to verify what you’re deleting\nUse -i flag with rm for confirmation\nMake backups before major operations\nTest commands on sample data first\n\n\n\nEfficiency\n\nUse Tab completion extensively\nCreate aliases for repetitive commands\nLearn keyboard shortcuts\nUse command history\n\n\n\nOrganization\n\nUse descriptive file and folder names\nOrganize projects in dedicated directories\nKeep your home directory clean",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "pages/terminal.html#resources-for-learning-more",
    "href": "pages/terminal.html#resources-for-learning-more",
    "title": "The Terminal",
    "section": "Resources for Learning More",
    "text": "Resources for Learning More\n\nCommand Line Tutorial\nLearn Shell\nBash Guide",
    "crumbs": [
      "Reference",
      "The Terminal"
    ]
  },
  {
    "objectID": "notebooks/example.html",
    "href": "notebooks/example.html",
    "title": "Workplace interaction",
    "section": "",
    "text": "Import some plotting libraries and set some defaults:\n\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, Markdown\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "pages/jupyterlab.html",
    "href": "pages/jupyterlab.html",
    "title": "JupyterLab Tutorial",
    "section": "",
    "text": "—title: “JupyterLab Tutorial”subtitle: “Interactive Computing with Notebooks”—"
  },
  {
    "objectID": "pages/jupyterlab.html#what-is-jupyterlabjupyterlab-is-a-powerful-web-based-interactive-development-environment-for-working-with-notebooks-code-and-data.-its-the-next-generation-interface-for-project-jupyter-offering-a-flexible-and-extensible-environment-for-computational-work.-key-features--notebooks-interactive-documents-combining-code-text-and-outputs--multiple-languages-support-for-python-r-julia-and-100-other-languages--rich-outputs-display-plots-tables-images-videos-and-interactive-widgets--flexible-interface-arrange-multiple-documents-and-activities-side-by-side--extensions-customize-with-a-growing-ecosystem-of-extensions-jupyterlab-vs-jupyter-notebook-feature-jupyterlab-classic-notebook-interface-multi-document-ide-like-single-document-file-browser-built-in-limited-terminal-integrated-separate-text-editor-full-featured-basic-extensions-modern-system-legacy-layout-flexible-draggable-fixed-franklin-uses-jupyterlab-by-default-because-it-provides-the-most-comprehensive-environment-for-learning-and-research.",
    "href": "pages/jupyterlab.html#what-is-jupyterlabjupyterlab-is-a-powerful-web-based-interactive-development-environment-for-working-with-notebooks-code-and-data.-its-the-next-generation-interface-for-project-jupyter-offering-a-flexible-and-extensible-environment-for-computational-work.-key-features--notebooks-interactive-documents-combining-code-text-and-outputs--multiple-languages-support-for-python-r-julia-and-100-other-languages--rich-outputs-display-plots-tables-images-videos-and-interactive-widgets--flexible-interface-arrange-multiple-documents-and-activities-side-by-side--extensions-customize-with-a-growing-ecosystem-of-extensions-jupyterlab-vs-jupyter-notebook-feature-jupyterlab-classic-notebook-interface-multi-document-ide-like-single-document-file-browser-built-in-limited-terminal-integrated-separate-text-editor-full-featured-basic-extensions-modern-system-legacy-layout-flexible-draggable-fixed-franklin-uses-jupyterlab-by-default-because-it-provides-the-most-comprehensive-environment-for-learning-and-research.",
    "title": "JupyterLab Tutorial",
    "section": "What is JupyterLab?JupyterLab is a powerful web-based interactive development environment for working with notebooks, code, and data. It’s the next-generation interface for Project Jupyter, offering a flexible and extensible environment for computational work.### Key Features- Notebooks: Interactive documents combining code, text, and outputs- Multiple Languages: Support for Python, R, Julia, and 100+ other languages- Rich Outputs: Display plots, tables, images, videos, and interactive widgets- Flexible Interface: Arrange multiple documents and activities side by side- Extensions: Customize with a growing ecosystem of extensions### JupyterLab vs Jupyter Notebook| Feature | JupyterLab | Classic Notebook ||———|————|——————|| Interface | Multi-document, IDE-like | Single document || File Browser | Built-in | Limited || Terminal | Integrated | Separate || Text Editor | Full-featured | Basic || Extensions | Modern system | Legacy || Layout | Flexible, draggable | Fixed |Franklin uses JupyterLab by default because it provides the most comprehensive environment for learning and research.",
    "text": "What is JupyterLab?JupyterLab is a powerful web-based interactive development environment for working with notebooks, code, and data. It’s the next-generation interface for Project Jupyter, offering a flexible and extensible environment for computational work.### Key Features- Notebooks: Interactive documents combining code, text, and outputs- Multiple Languages: Support for Python, R, Julia, and 100+ other languages- Rich Outputs: Display plots, tables, images, videos, and interactive widgets- Flexible Interface: Arrange multiple documents and activities side by side- Extensions: Customize with a growing ecosystem of extensions### JupyterLab vs Jupyter Notebook| Feature | JupyterLab | Classic Notebook ||———|————|——————|| Interface | Multi-document, IDE-like | Single document || File Browser | Built-in | Limited || Terminal | Integrated | Separate || Text Editor | Full-featured | Basic || Extensions | Modern system | Legacy || Layout | Flexible, draggable | Fixed |Franklin uses JupyterLab by default because it provides the most comprehensive environment for learning and research."
  },
  {
    "objectID": "pages/jupyterlab.html#starting-jupyterlabthere-are-several-ways-to-start-jupyterlab",
    "href": "pages/jupyterlab.html#starting-jupyterlabthere-are-several-ways-to-start-jupyterlab",
    "title": "JupyterLab Tutorial",
    "section": "Starting JupyterLabThere are several ways to start JupyterLab:",
    "text": "Starting JupyterLabThere are several ways to start JupyterLab:\n\nWith Franklin (Recommended)The easiest way for Franklin users:\n\n# Navigate to your exercise foldercd \"My Exercise\"# Start JupyterLab through Franklinfranklin jupyter"
  },
  {
    "objectID": "pages/jupyterlab.html#keyboard-shortcuts",
    "href": "pages/jupyterlab.html#keyboard-shortcuts",
    "title": "JupyterLab Tutorial",
    "section": "Keyboard shortcuts",
    "text": "Keyboard shortcuts\n\nCommand Mode in Jupyter Notebooks\nIn Jupyter Notebooks, Command Mode is one of the two main interaction modes—the other being Edit Mode. Command Mode is active when the cell border is blue, indicating that keyboard commands will be interpreted as notebook-level operations rather than editing the cell’s content.\nCommand Mode allows users to manage cells and perform structural modifications without using the mouse. This enhances efficiency, especially when working with large notebooks. Pressing Esc while in a cell activates Command Mode.\n\nCommon Keyboard Shortcuts in Command Mode\n\n\n\n\n\n\n\nShortcut\nDescription\n\n\n\n\nEnter\nSwitch to Edit Mode in the selected cell\n\n\nA\nInsert a new cell above the current cell\n\n\nB\nInsert a new cell below the current cell\n\n\nD, D\nDelete the selected cell (press D twice quickly)\n\n\nZ\nUndo the last cell deletion\n\n\nY\nChange cell type to code\n\n\nM\nChange cell type to Markdown\n\n\nC\nCopy the selected cell\n\n\nX\nCut the selected cell\n\n\nV\nPaste cell below\n\n\nShift + V\nPaste cell above\n\n\nShift + Up/Down\nExtend selection to multiple cells\n\n\nCtrl + S (or Cmd + S on macOS)\nSave the notebook\n\n\nH\nShow all keyboard shortcuts\n\n\n0, 0\nRestart the kernel (press 0 twice quickly)\n\n\nShift + M (in Command Mode)\nMerge selected cells\n\n\n\nThese shortcuts make navigation and cell management significantly faster, enabling an efficient coding and documentation workflow within Jupyter Notebooks.\n\n\n\nEdit Mode in Jupyter Notebooks\nEdit Mode is activated when a cell’s border turns green, allowing the user to directly modify the contents of the cell. You can enter Edit Mode by pressing Enter while a cell is selected in Command Mode. This mode is primarily used for writing and editing code or Markdown content within cells.\n\nCommon Keyboard Shortcuts in Edit Mode\n\n\n\n\n\n\n\nShortcut\nDescription\n\n\n\n\nCtrl + Enter\nRun the current cell and remain in Edit Mode\n\n\nShift + Enter\nRun the current cell and move to the next cell\n\n\nAlt + Enter\nRun the current cell and insert a new cell below\n\n\nEsc\nSwitch to Command Mode\n\n\nCtrl + /\nToggle comment on selected lines (code cells only)\n\n\nTab\nCode completion or indent\n\n\nShift + Tab\nShow tooltip/help for the object under cursor\n\n\nCtrl + ]\nIndent the current line or selection\n\n\nCtrl + [\nDedent the current line or selection\n\n\nCtrl + A\nSelect all content in the cell\n\n\nCtrl + Z\nUndo the last change\n\n\nCtrl + Y\nRedo the last undone change\n\n\nCtrl + Shift + -\nSplit the current cell at cursor position into two cells\n\n\nCtrl + S (or Cmd + S)\nSave the notebook\n\n\nCtrl + Shift + -\nSplit the cell at the current cursor position\n\n\n\nThese shortcuts are optimized for efficient coding and content editing, significantly reducing reliance on the mouse and improving productivity within Jupyter Notebooks."
  },
  {
    "objectID": "pages/jupyterlab.html#menu-toolbar-context-menu",
    "href": "pages/jupyterlab.html#menu-toolbar-context-menu",
    "title": "JupyterLab Tutorial",
    "section": "Menu, Toolbar, Context menu",
    "text": "Menu, Toolbar, Context menu"
  },
  {
    "objectID": "pages/jupyterlab.html#command-palette-commandctrl-shift-c",
    "href": "pages/jupyterlab.html#command-palette-commandctrl-shift-c",
    "title": "JupyterLab Tutorial",
    "section": "Command palette: Command/Ctrl Shift C",
    "text": "Command palette: Command/Ctrl Shift C"
  },
  {
    "objectID": "pages/jupyterlab.html#keyboard-short-cuts-commandctrl-shift-h",
    "href": "pages/jupyterlab.html#keyboard-short-cuts-commandctrl-shift-h",
    "title": "JupyterLab Tutorial",
    "section": "Keyboard short-cuts: Command/Ctrl Shift H",
    "text": "Keyboard short-cuts: Command/Ctrl Shift H"
  },
  {
    "objectID": "pages/jupyterlab.html#code-blocks",
    "href": "pages/jupyterlab.html#code-blocks",
    "title": "JupyterLab Tutorial",
    "section": "Code blocks",
    "text": "Code blocks\n\nx = 0"
  },
  {
    "objectID": "pages/jupyterlab.html#last-value-is-displayed",
    "href": "pages/jupyterlab.html#last-value-is-displayed",
    "title": "JupyterLab Tutorial",
    "section": "Last value is displayed",
    "text": "Last value is displayed\n\nx = 1\nx"
  },
  {
    "objectID": "pages/jupyterlab.html#everything-is-one-python-process",
    "href": "pages/jupyterlab.html#everything-is-one-python-process",
    "title": "JupyterLab Tutorial",
    "section": "Everything is one Python process",
    "text": "Everything is one Python process\n\nx += 1\nx"
  },
  {
    "objectID": "pages/jupyterlab.html#restarting-the-kernel",
    "href": "pages/jupyterlab.html#restarting-the-kernel",
    "title": "JupyterLab Tutorial",
    "section": "Restarting the kernel",
    "text": "Restarting the kernel"
  },
  {
    "objectID": "pages/jupyterlab.html#lists",
    "href": "pages/jupyterlab.html#lists",
    "title": "JupyterLab Tutorial",
    "section": "Lists",
    "text": "Lists\n\nfoo\nbar\nbaz"
  },
  {
    "objectID": "pages/jupyterlab.html#numbered-lists",
    "href": "pages/jupyterlab.html#numbered-lists",
    "title": "JupyterLab Tutorial",
    "section": "Numbered lists",
    "text": "Numbered lists\n\nfoo\nbar\nbaz"
  },
  {
    "objectID": "pages/jupyterlab.html#quotes",
    "href": "pages/jupyterlab.html#quotes",
    "title": "JupyterLab Tutorial",
    "section": "Quotes",
    "text": "Quotes\n\nThis is a quote"
  },
  {
    "objectID": "pages/jupyterlab.html#formulas",
    "href": "pages/jupyterlab.html#formulas",
    "title": "JupyterLab Tutorial",
    "section": "Formulas",
    "text": "Formulas\n\\(\\sum_{i=0}^n i\\)\n\nHTML"
  },
  {
    "objectID": "pages/jupyterlab.html#header-2",
    "href": "pages/jupyterlab.html#header-2",
    "title": "JupyterLab Tutorial",
    "section": "Header 2",
    "text": "Header 2\n\nHeader 3\n\nHeader 4"
  },
  {
    "objectID": "pages/jupyterlab.html#formulas-1",
    "href": "pages/jupyterlab.html#formulas-1",
    "title": "JupyterLab Tutorial",
    "section": "Formulas",
    "text": "Formulas\n\\(\\sum_{i=0}^n i\\)"
  },
  {
    "objectID": "pages/jupyterlab.html#tables",
    "href": "pages/jupyterlab.html#tables",
    "title": "JupyterLab Tutorial",
    "section": "Tables",
    "text": "Tables\n\n\n\nName\nValue\n\n\n\n\nfoo\n2\n\n\nbar\n3"
  },
  {
    "objectID": "pages/numpy_and_pandas.html",
    "href": "pages/numpy_and_pandas.html",
    "title": "NumPy and Pandas",
    "section": "",
    "text": "Fast computation using vectors and matrices\n\nlist1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nlist2 = [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nsummed = []\nfor i in range(len(list1)):\n    summed.append(list1[i] + list2[i])\nsummed\n\n\n\n\nimport numpy as np\n\n\na = np.array(list1)\nb = np.array(list2)\na, b\n\n\n\n\n\na + b\n\n\na * b\n\n\na - 10\n\n\na.sum()\n\n\na.mean()\n\n\n\n\n\nlist_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nlist_of_lists\n\n\nlist_of_lists[1][1]\n\n\nmatrix = np.array(list_of_lists)\nmatrix\n\n\nmatrix[1][1] # not efficient\n\n\nmatrix[1, 1] # efficient\n\n\nmatrix - 10\n\n\nmatrix.sum()\n\n\nlist_of_lists_of_lists = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\nlist_of_lists_of_lists\n\n\ntensor = np.array(list_of_lists_of_lists)\ntensor\n\n\ntensor[1, 1, 1]"
  },
  {
    "objectID": "pages/numpy_and_pandas.html#numpy",
    "href": "pages/numpy_and_pandas.html#numpy",
    "title": "NumPy and Pandas",
    "section": "",
    "text": "Fast computation using vectors and matrices\n\nlist1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nlist2 = [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nsummed = []\nfor i in range(len(list1)):\n    summed.append(list1[i] + list2[i])\nsummed\n\n\n\n\nimport numpy as np\n\n\na = np.array(list1)\nb = np.array(list2)\na, b\n\n\n\n\n\na + b\n\n\na * b\n\n\na - 10\n\n\na.sum()\n\n\na.mean()\n\n\n\n\n\nlist_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nlist_of_lists\n\n\nlist_of_lists[1][1]\n\n\nmatrix = np.array(list_of_lists)\nmatrix\n\n\nmatrix[1][1] # not efficient\n\n\nmatrix[1, 1] # efficient\n\n\nmatrix - 10\n\n\nmatrix.sum()\n\n\nlist_of_lists_of_lists = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\nlist_of_lists_of_lists\n\n\ntensor = np.array(list_of_lists_of_lists)\ntensor\n\n\ntensor[1, 1, 1]"
  },
  {
    "objectID": "pages/numpy_and_pandas.html#pandas",
    "href": "pages/numpy_and_pandas.html#pandas",
    "title": "NumPy and Pandas",
    "section": "Pandas",
    "text": "Pandas\nFast computations on data tables (on top of Numpy).\n\nimport pandas as pd\n\n\nDataFrame\n\ndf = pd.DataFrame({'name': ['Mike', 'Mia', 'Jake'], 'weight': [82, 62, 75]})\ndf\n\n\ntype(df)\n\n\ndf = pd.DataFrame(dict(name=['Mike', 'Mia', 'Jake'], weight=[82, 62, 75]))\ndf\n\n\nrecords = [('Mike', 82), ('Mia', 62), ('Jake', 75)]\n\ndf = pd.DataFrame().from_records(records, columns=['age', 'weight'])\ndf\n\n\ndf.index\n\n\ndf.index.values\n\n\ndf.columns\n\n\ndf.dtypes\n\nAdd a column to an existing dataframe:\n\ndf['height'] = [182.5, 173.0, 192.5]\ndf\n\nAdd another, categorical, column:\n\ndf['sex'] = pd.Categorical(['male', 'female', 'male'], categories=['female', 'male'], ordered=True)\ndf\n\n\ndf.dtypes\n\nA Series just wraps an array:\n\ndf.height.to_numpy()\n\n\n\nExample penguin data set\n\nimport seaborn as sns\n\npenguins = sns.load_dataset('penguins')\n\n\npenguins\n\n\npenguins.dtypes\n\n\npenguins.head()\n\n\npenguins.tail()\n\n\n\nSeries\n\npenguins['flipper_length_mm']\n\n\npenguins.flipper_length_mm\n\n\ntype(penguins.flipper_length_mm)\n\n\n\nBroadcasting\n\npenguins.bill_depth_mm - 1000\n\n\npenguins.bill_depth_mm * penguins.flipper_length_mm\n\n\n\nIndexing\n\nGet a cell\n\npenguins.loc[4, 'island']\n\n\n\nGet a row\n\npenguins.loc[4]\n\n\n\nGet a column\n\npenguins['bill_depth_mm']\n\n\npenguins.bill_depth_mm\n\n\n\nGet a range of rows and multiple columns\n\npenguins.loc[40:45, ['island', 'body_mass_g']]\n\n\n\nUse boolean series as index to subset data\n\nidx = penguins.bill_length_mm &gt; 55\nidx\n\n\npenguins.loc[idx]\n\n\npenguins.loc[(penguins.bill_length_mm &gt; 55) & (penguins.sex == 'Female')]\n\n\n\nSetting and resetting the index\n\npenguins\n\n\ndf = penguins.set_index(['species', 'sex', 'island'])\ndf.head(10)\n\n\ndf.reset_index()\n\n\n\n\nSorting rows\n\nsorted_df = penguins.sort_values(by=\"bill_length_mm\")\nsorted_df.head()\n\n\nsorted_df.index.values\n\nClick to the left of an output cell to enable/disable scrolling of the output (usefull for large amounts of output).\n\nsorted_df.loc[0]\n\n\nsorted_df.flipper_length_mm[0]\n\n\nsorted_df.iloc[0] # iloc !!!\n\n\nsorted_df.flipper_length_mm.iloc[0]\n\n\n\nSummary stats\n\npenguins.describe()\n\n\npenguins.bill_length_mm.mean()\n\n\npenguins.bill_length_mm.count()\n\n\n\nGroup\n\npenguins.groupby('island')\n\n\n\nAggregate\nAggregating produces a single value for each variable in each group:\nMeans for all numeric variables for each island:\n\npenguins.groupby('island').aggregate(\"mean\", numeric_only=True)\n\n\npenguins.groupby('island').mean(numeric_only=True)\n\nMeans for bill_length_mm and flipper_length_mm:\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].mean()\n\nJust for flipper_length_mm:\n\npenguins.groupby('island').flipper_length_mm.mean()\n\n\n\nTransform\nTransforming produces new colums with the same length as the input:\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].transform(\"mean\")\n\n\ndef z_value(sr):\n    return (sr - sr.mean()) / sr.std()\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].transform(z_value)\n\n\n\nApply\nFlexible method allowing any operation on grouped data.\nReturn a single value:\n\ndef fun(df):\n    return df.bill_length_mm + df.flipper_length_mm.mean() / df.body_mass_g\n\npenguins.groupby('island').apply(fun)#.to_frame('my_stat')\n\nReturn a dataframe:\n\ndef fun(df):\n    return pd.DataFrame({'sqrt_bill': np.sqrt(df.bill_length_mm),\n                         'bill_squared': df.bill_length_mm**2})\n\npenguins.groupby('island').apply(fun)"
  },
  {
    "objectID": "pages/plotting.html",
    "href": "pages/plotting.html",
    "title": "Plotting with Python",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nsns.set_style(\"darkgrid\")\n\n# make graphics sharper on a good screen\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nset_matplotlib_formats('retina', 'png')\npenguins = sns.load_dataset(\"penguins\")\npenguins.head()\nplt.scatter(penguins.bill_length_mm, penguins.flipper_length_mm) ;  # semi colon makes last value None\nsns.set_style(\"ticks\")\n# sns.set_style(\"darkgrid\")\n# sns.set_style(\"whitegrid\")\n# sns.set_style(\"white\")\n# sns.set_style(\"dark\")\n\nplt.scatter(penguins.bill_length_mm, penguins.flipper_length_mm)\nsns.despine()\nplt.hist(penguins.bill_length_mm) ;"
  },
  {
    "objectID": "pages/plotting.html#facetgrid.map-vs.-facetgrid.map_dataframe",
    "href": "pages/plotting.html#facetgrid.map-vs.-facetgrid.map_dataframe",
    "title": "Plotting with Python",
    "section": "FacetGrid.map vs. FacetGrid.map_dataframe",
    "text": "FacetGrid.map vs. FacetGrid.map_dataframe\nWhen you use FacetGrid.map(func, \"col1\", \"col2\", ...), the function func is passed the values of the columns \"col1\" and \"col2\" (and more if needed) as parameters 1 and 2 (args[0], args[1], …). In addition, the function always receives a keyword argument named color=.\n\ndef scatter(*args, **kwargs):\n    return plt.scatter(args[0], args[1], **kwargs)\n    \ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(scatter, \"bill_length_mm\", \"flipper_length_mm\") ;\n\nWhen you use FacetGrid.map_dataframe(func, \"col1\", \"col2\", ...), the function func is passed the names \"col1\" and \"col2\" (and more if needed) as parameters 1 and 2 (args[0], args[1], …), and the filtered dataframe as keyword argument data=. In addition, the function always receives a keyword argument named color=.\n\ndef scatterplot(*args, **kwargs):\n    return sns.scatterplot(x=args[0], y=args[1], **kwargs)\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map_dataframe(scatterplot, \"bill_length_mm\", \"flipper_length_mm\") ;\n\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.histplot, \"bill_length_mm\") ;\n\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.kdeplot, \"bill_length_mm\") ;\n\n\nsns.pairplot(penguins, hue=\"species\") ;\n\n\nsns.pairplot(penguins, hue=\"sex\") ;"
  },
  {
    "objectID": "pages/test_minimal.html",
    "href": "pages/test_minimal.html",
    "title": "Test Notebook",
    "section": "",
    "text": "This is a minimal test notebook.\n\nprint('Hello World')"
  },
  {
    "objectID": "pages/widgets.html",
    "href": "pages/widgets.html",
    "title": "Showcase",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nfrom widgetplots import menu_plot\n%config InlineBackend.figure_format = 'retina'\n\n#wp.set_options(max_figure_width=4)\n#wp.set_options(x=None, y=None, col=None, graphics=[sns.scatterplot, sns.boxplot], theme={'style': 'darkgrid', 'palette': 'colorblind'})"
  },
  {
    "objectID": "pages/widgets.html#penguin-data",
    "href": "pages/widgets.html#penguin-data",
    "title": "Showcase",
    "section": "Penguin data",
    "text": "Penguin data\n\ndata = sns.load_dataset('penguins')\ndata\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the init_notebook_mode cell...\n    (need help?)"
  },
  {
    "objectID": "pages/widgets.html#the-plot-widget",
    "href": "pages/widgets.html#the-plot-widget",
    "title": "Showcase",
    "section": "The plot widget",
    "text": "The plot widget\n\nmenu_plot(data, x='species', y='body_mass_g', hue='sex', plot='boxplot',\n          palette=\"tab10\", )\n\n\n\n\n\n\n\n\nimport seaborn as sns\nsns.set_style({'style': 'darkgrid', 'palette': 'viridis'})                             \ng = sns.relplot(data, x='species', y='island', col='island', row='species', height=2, kind='scatter', \n                facet_kws=dict(margin_titles=True))\ng.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\ng.tight_layout() ;\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\nsns.set_style({'style': 'darkgrid', 'palette': 'viridis'})                             \nsns.relplot(data, x='bill_length_mm', y='bill_depth_mm', hue='flipper_length_mm', \n            row='island', col='species', \n            palette='viridis', kind='scatter', height=2) ;\n\n\n\n\n\n\n\n\n\nmenu_plot(data, x='bill_length_mm', y='body_mass_g', hue='body_mass_g', #plot='boxplot',\n           col='species'\n          )\n\n\n\n\n\n\n\n\n\n\nmenu_plot(data, #plot='scatterplot', \n           x='bill_length_mm', y='body_mass_g', hue='body_mass_g', col='species')\n\n\n\n\n\n\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', hue='sex', #plot='scatterplot', \n          # palette='colorblind'\n          )\n\n\n\n\n\n\n\n\nsns.scatterplot(data, x='bill_length_mm', y='bill_depth_mm', hue='sex', \n              #  palette='colorblind'\n               )\n\n\n\n\n\n\n\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', hue='body_mass_g', \n           # style='sex', \n           # size='body_mass_g', \n           col='species', row='island',\n          wrap=3, theme={'palette': 'Set1'})\n\n\n\n\n\n\n\n\nmenu_plot(data, plot='boxplot', x='species', y='bill_depth_mm')\n\n\nmenu_plot(data, plot='histplot', x='bill_depth_mm', hue='sex', row='species', col='island')\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', row='species', col='island')\n\n\nmenu_plot(data=data, x='bill_length_mm', y='bill_depth_mm')\n\n\nmenu_plot(data=data, x='bill_length_mm', y='bill_depth_mm', graphics=[sns.lmplot])\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', hue='species', graphics=[sns.lmplot])\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', graphics=[sns.scatterplot])\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', hue='species', graphics=[sns.kdeplot])\n\n\nmenu_plot(data, x='bill_length_mm', y='bill_depth_mm', hue='sex', plot='scatterplot', palette='colorblind')\n\n\ng = sns.FacetGrid(data, row='species', col='island', hue='sex')\ng.map_dataframe(sns.regplot, x='bill_depth_mm', y='bill_length_mm')\n\n\n\n\n\n\n\n\n# pixi add ipydatagrid itables\n\n\n## Read in an Excel file\nimport pandas as pd\ndata = pd.read_excel('~/Desktop/tester.xlsx')  \n\n\nfrom ipydatagrid import DataGrid\nimport pandas as pd\n\n# Create interactive data grid\ngrid = DataGrid(data, editable=True, layout={'height': '400px', 'width': '100%'})\ngrid\n\n\n\n\n\nimport pandas as pd\nimport ipydatagrid as dg\nimport ipywidgets as ipw\n\n## Callbacks ##\ndef add_row(e):\n    current_grid_df = grid.get_visible_data()\n    additional_row = pd.DataFrame(\n        columns = current_grid_df.columns, \n        index = [current_grid_df.index[-1] + 1],\n        data = \"\" * len(current_grid_df.columns)\n    )\n    grid.data = pd.concat([current_grid_df, additional_row], ignore_index=True)\n\ndef remove_row(e):\n    current_grid_df = grid.get_visible_data()\n    grid.data = current_grid_df.drop(current_grid_df.tail(1).index)\n\n## Data ##\ndf = pd.DataFrame(data={\"Col1\":range(1,11), \"Col2\":range(11,21)})\n\n## Widgets ##\ngrid = dg.DataGrid(df, selection_mode='cell', editable=True, layout={\"height\":\"350px\"})\nbutton_add_row = ipw.Button(description=\"Add Row\", \n                               layout=ipw.Layout(width='100px', height='25px')                            \n                            # style=ipw.ButtonStyle(button_color='darkgreen')\n                            )\nbutton_remove_row = ipw.Button(description=\"Remove Row\", \n                               layout=ipw.Layout(width='100px', height='25px')\n                            #    style=ipw.ButtonStyle(button_color='darkred')\n                               )\n\n## Handlers ##\nbutton_add_row.on_click(add_row)\nbutton_remove_row.on_click(remove_row)\n\n## Layout ##\nipw.VBox([\n    ipw.HBox([button_add_row, button_remove_row]),\n    grid\n])\n\n\n\n\n\ngrid.set_cell_value('Col1', 4, 99999)\n\nTrue\n\n\n\nimport numpy as np\npd.DataFrame(np.array(grid.selected_cell_values).reshape(-1, 2), columns=['Col1', 'Col2'])\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the init_notebook_mode cell...\n    (need help?)"
  },
  {
    "objectID": "pages/widgets.html#table-widget",
    "href": "pages/widgets.html#table-widget",
    "title": "Showcase",
    "section": "Table widget",
    "text": "Table widget\nYou can use the itables package to display interactive tables in Jupyter notebooks:\n\nimport itables\nitables.init_notebook_mode()\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nThis is the init_notebook_mode cell from ITables v2.4.4\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\nitables.show(data, buttons=[\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"])\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.4.4 from the init_notebook_mode cell...\n    (need help?)\n    \n\n\n\n\nimport seaborn as sns\nsns.regplot(data, x='X', y='Y')"
  }
]