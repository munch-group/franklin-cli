{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"NumPy and Pandas Mastery\"\n",
    "subtitle: \"Essential Data Analysis Libraries for Python\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "NumPy and Pandas are the foundation of data science in Python:\n",
    "\n",
    "- **NumPy**: Efficient numerical computing with arrays\n",
    "- **Pandas**: Data manipulation and analysis with DataFrames\n",
    "\n",
    "This comprehensive tutorial will take you from basics to advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.precision', 3)\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: NumPy - Numerical Python\n",
    "\n",
    "## Why NumPy?\n",
    "\n",
    "NumPy provides:\n",
    "- Fast operations on arrays (10-100x faster than lists)\n",
    "- Broadcasting for element-wise operations\n",
    "- Mathematical functions\n",
    "- Linear algebra operations\n",
    "- Random number generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From lists\n",
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"1D array:\", arr1)\n",
    "print(\"2D array:\\n\", arr2)\n",
    "print(f\"Shape: {arr2.shape}, Dimensions: {arr2.ndim}, Size: {arr2.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special arrays\n",
    "zeros = np.zeros((3, 4))           # 3x4 matrix of zeros\n",
    "ones = np.ones((2, 3, 4))          # 2x3x4 tensor of ones\n",
    "identity = np.eye(4)               # 4x4 identity matrix\n",
    "random = np.random.rand(3, 3)      # 3x3 random values [0,1)\n",
    "\n",
    "# Sequences\n",
    "sequence = np.arange(0, 10, 2)     # [0, 2, 4, 6, 8]\n",
    "linspace = np.linspace(0, 1, 5)    # 5 points from 0 to 1\n",
    "\n",
    "print(\"Zeros:\\n\", zeros)\n",
    "print(\"\\nIdentity:\\n\", identity)\n",
    "print(\"\\nSequence:\", sequence)\n",
    "print(\"Linspace:\", linspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "\n",
    "print(\"Addition:\", a + b)\n",
    "print(\"Multiplication:\", a * b)\n",
    "print(\"Power:\", a ** 2)\n",
    "print(\"Boolean:\", a > 2)\n",
    "\n",
    "# Mathematical functions\n",
    "print(\"\\nSqrt:\", np.sqrt(a))\n",
    "print(\"Exp:\", np.exp(a))\n",
    "print(\"Log:\", np.log(a + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "NumPy's powerful feature for operations on arrays of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting examples\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Add scalar to matrix\n",
    "print(\"Matrix + 10:\")\n",
    "print(matrix + 10)\n",
    "\n",
    "# Add vector to each row\n",
    "row_vector = np.array([1, 0, -1])\n",
    "print(\"\\nMatrix + row vector:\")\n",
    "print(matrix + row_vector)\n",
    "\n",
    "# Add vector to each column\n",
    "col_vector = np.array([[10], [20], [30]])\n",
    "print(\"\\nMatrix + column vector:\")\n",
    "print(matrix + col_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D array indexing\n",
    "arr = np.array([[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8],\n",
    "                [9, 10, 11, 12]])\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(arr)\n",
    "\n",
    "# Access elements\n",
    "print(\"\\nElement [1,2]:\", arr[1, 2])  # Row 1, Column 2\n",
    "print(\"First row:\", arr[0, :])         # or arr[0]\n",
    "print(\"Last column:\", arr[:, -1])\n",
    "\n",
    "# Slicing\n",
    "print(\"\\nSubmatrix [0:2, 1:3]:\")\n",
    "print(arr[0:2, 1:3])\n",
    "\n",
    "# Boolean indexing\n",
    "mask = arr > 5\n",
    "print(\"\\nElements > 5:\", arr[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "a = np.arange(12)\n",
    "print(\"Original:\", a)\n",
    "print(\"Reshaped to 3x4:\")\n",
    "print(a.reshape(3, 4))\n",
    "print(\"Reshaped to 2x2x3:\")\n",
    "print(a.reshape(2, 2, 3))\n",
    "\n",
    "# Stacking\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "print(\"\\nVertical stack:\")\n",
    "print(np.vstack([a, b]))\n",
    "print(\"Horizontal stack:\")\n",
    "print(np.hstack([a, b]))\n",
    "\n",
    "# Splitting\n",
    "arr = np.arange(9).reshape(3, 3)\n",
    "print(\"\\nOriginal:\")\n",
    "print(arr)\n",
    "print(\"Split horizontally:\", np.hsplit(arr, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "data = np.random.randn(1000)  # Normal distribution\n",
    "\n",
    "print(f\"Mean: {np.mean(data):.3f}\")\n",
    "print(f\"Median: {np.median(data):.3f}\")\n",
    "print(f\"Std Dev: {np.std(data):.3f}\")\n",
    "print(f\"Variance: {np.var(data):.3f}\")\n",
    "print(f\"Min: {np.min(data):.3f}\")\n",
    "print(f\"Max: {np.max(data):.3f}\")\n",
    "print(f\"25th percentile: {np.percentile(data, 25):.3f}\")\n",
    "print(f\"75th percentile: {np.percentile(data, 75):.3f}\")\n",
    "\n",
    "# Axis operations\n",
    "matrix = np.random.randn(3, 4)\n",
    "print(\"\\nMatrix:\")\n",
    "print(matrix)\n",
    "print(\"Column means:\", np.mean(matrix, axis=0))\n",
    "print(\"Row means:\", np.mean(matrix, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B:\")\n",
    "print(B)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"\\nA @ B (matrix product):\")\n",
    "print(A @ B)  # or np.dot(A, B)\n",
    "\n",
    "# Other operations\n",
    "print(\"\\nTranspose of A:\")\n",
    "print(A.T)\n",
    "print(\"\\nDeterminant of A:\", np.linalg.det(A))\n",
    "print(\"\\nInverse of A:\")\n",
    "print(np.linalg.inv(A))\n",
    "\n",
    "# Eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "print(\"\\nEigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pandas - Data Analysis\n",
    "\n",
    "## Why Pandas?\n",
    "\n",
    "Pandas provides:\n",
    "- DataFrames for tabular data\n",
    "- Missing data handling\n",
    "- Data alignment and merging\n",
    "- Time series functionality\n",
    "- Input/Output tools for various formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dictionary\n",
    "df1 = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 28],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Houston'],\n",
    "    'salary': [70000, 80000, 75000, 65000]\n",
    "})\n",
    "\n",
    "# From lists\n",
    "df2 = pd.DataFrame(\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    columns=['A', 'B', 'C'],\n",
    "    index=['row1', 'row2', 'row3']\n",
    ")\n",
    "\n",
    "# From NumPy array\n",
    "df3 = pd.DataFrame(\n",
    "    np.random.randn(5, 3),\n",
    "    columns=['X', 'Y', 'Z']\n",
    ")\n",
    "\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame with custom index:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Basic information\n",
    "print(\"Shape:\", tips.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(tips.head())\n",
    "print(\"\\nData types:\")\n",
    "print(tips.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(tips.describe())\n",
    "print(\"\\nInfo:\")\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection\n",
    "print(\"Single column (Series):\")\n",
    "print(tips['total_bill'].head())\n",
    "\n",
    "print(\"\\nMultiple columns (DataFrame):\")\n",
    "print(tips[['total_bill', 'tip', 'day']].head())\n",
    "\n",
    "# Row selection with loc (label-based)\n",
    "print(\"\\nRows 10-12, specific columns:\")\n",
    "print(tips.loc[10:12, ['total_bill', 'tip', 'day']])\n",
    "\n",
    "# Row selection with iloc (position-based)\n",
    "print(\"\\nRows 0-2, columns 0-2:\")\n",
    "print(tips.iloc[0:3, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean filtering\n",
    "# Simple condition\n",
    "high_bills = tips[tips['total_bill'] > 30]\n",
    "print(f\"High bills (>30): {len(high_bills)} rows\")\n",
    "print(high_bills.head())\n",
    "\n",
    "# Multiple conditions\n",
    "dinner_high_tip = tips[(tips['time'] == 'Dinner') & (tips['tip'] > 5)]\n",
    "print(f\"\\nDinner with high tip: {len(dinner_high_tip)} rows\")\n",
    "\n",
    "# Using isin\n",
    "weekend = tips[tips['day'].isin(['Sat', 'Sun'])]\n",
    "print(f\"\\nWeekend data: {len(weekend)} rows\")\n",
    "\n",
    "# Using query\n",
    "result = tips.query('total_bill > 30 and tip > 5')\n",
    "print(f\"\\nQuery result: {len(result)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns\n",
    "tips_copy = tips.copy()\n",
    "tips_copy['tip_percentage'] = tips_copy['tip'] / tips_copy['total_bill'] * 100\n",
    "tips_copy['bill_per_person'] = tips_copy['total_bill'] / tips_copy['size']\n",
    "\n",
    "print(\"New columns added:\")\n",
    "print(tips_copy[['total_bill', 'tip', 'tip_percentage', 'bill_per_person']].head())\n",
    "\n",
    "# Modifying columns\n",
    "tips_copy['day_type'] = tips_copy['day'].apply(\n",
    "    lambda x: 'Weekend' if x in ['Sat', 'Sun'] else 'Weekday'\n",
    ")\n",
    "\n",
    "# Dropping columns\n",
    "tips_copy = tips_copy.drop(['bill_per_person'], axis=1)\n",
    "\n",
    "# Renaming columns\n",
    "tips_copy = tips_copy.rename(columns={'size': 'party_size'})\n",
    "\n",
    "print(\"\\nModified DataFrame:\")\n",
    "print(tips_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with missing values\n",
    "df_missing = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, 2, 3, 4, 5],\n",
    "    'D': [np.nan, np.nan, np.nan, np.nan, 5]\n",
    "})\n",
    "\n",
    "print(\"Data with missing values:\")\n",
    "print(df_missing)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_missing.isnull().sum())\n",
    "\n",
    "# Drop missing values\n",
    "print(\"\\nDrop rows with any NaN:\")\n",
    "print(df_missing.dropna())\n",
    "\n",
    "print(\"\\nDrop columns with any NaN:\")\n",
    "print(df_missing.dropna(axis=1))\n",
    "\n",
    "# Fill missing values\n",
    "print(\"\\nFill with constant:\")\n",
    "print(df_missing.fillna(0))\n",
    "\n",
    "print(\"\\nForward fill:\")\n",
    "print(df_missing.fillna(method='ffill'))\n",
    "\n",
    "print(\"\\nFill with mean:\")\n",
    "print(df_missing.fillna(df_missing.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple groupby\n",
    "grouped = tips.groupby('day')\n",
    "print(\"Mean by day:\")\n",
    "print(grouped[['total_bill', 'tip']].mean())\n",
    "\n",
    "# Multiple grouping\n",
    "print(\"\\nMean by day and time:\")\n",
    "print(tips.groupby(['day', 'time'])['total_bill'].mean().unstack())\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"\\nMultiple statistics:\")\n",
    "agg_result = tips.groupby('day').agg({\n",
    "    'total_bill': ['mean', 'std', 'count'],\n",
    "    'tip': ['mean', 'max']\n",
    "})\n",
    "print(agg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform - returns same-sized result\n",
    "tips['bill_zscore'] = tips.groupby('day')['total_bill'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "print(\"Z-scores by day:\")\n",
    "print(tips[['day', 'total_bill', 'bill_zscore']].head(10))\n",
    "\n",
    "# Apply - flexible operation\n",
    "def top_tips(df, n=3):\n",
    "    return df.nlargest(n, 'tip')[['total_bill', 'tip']]\n",
    "\n",
    "print(\"\\nTop 3 tips per day:\")\n",
    "print(tips.groupby('day').apply(top_tips))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'city': ['NYC', 'LA', 'Chicago', 'Houston']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 2, 1, 3, 5],\n",
    "    'amount': [250, 150, 300, 200, 175]\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)\n",
    "\n",
    "# Different join types\n",
    "print(\"\\nInner join:\")\n",
    "print(pd.merge(customers, orders, on='customer_id', how='inner'))\n",
    "\n",
    "print(\"\\nLeft join:\")\n",
    "print(pd.merge(customers, orders, on='customer_id', how='left'))\n",
    "\n",
    "print(\"\\nOuter join:\")\n",
    "print(pd.merge(customers, orders, on='customer_id', how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "pivot = tips.pivot_table(\n",
    "    values='total_bill',\n",
    "    index='day',\n",
    "    columns='time',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"Pivot table - mean bill by day and time:\")\n",
    "print(pivot)\n",
    "\n",
    "# Melt (unpivot)\n",
    "melted = pivot.reset_index().melt(\n",
    "    id_vars='day',\n",
    "    var_name='time',\n",
    "    value_name='avg_bill'\n",
    ")\n",
    "print(\"\\nMelted data:\")\n",
    "print(melted)\n",
    "\n",
    "# Stack and unstack\n",
    "stacked = tips.groupby(['day', 'time'])['total_bill'].mean()\n",
    "print(\"\\nStacked:\")\n",
    "print(stacked)\n",
    "print(\"\\nUnstacked:\")\n",
    "print(stacked.unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data\n",
    "dates = pd.date_range('2023-01-01', periods=365, freq='D')\n",
    "ts = pd.Series(np.random.randn(365).cumsum() + 100, index=dates)\n",
    "\n",
    "print(\"Time series data:\")\n",
    "print(ts.head())\n",
    "\n",
    "# Resampling\n",
    "monthly = ts.resample('M').mean()\n",
    "print(\"\\nMonthly average:\")\n",
    "print(monthly)\n",
    "\n",
    "# Rolling operations\n",
    "rolling_mean = ts.rolling(window=30).mean()\n",
    "rolling_std = ts.rolling(window=30).std()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ts.plot(ax=ax, label='Daily', alpha=0.5)\n",
    "rolling_mean.plot(ax=ax, label='30-day MA', linewidth=2)\n",
    "ax.fill_between(rolling_mean.index, \n",
    "                rolling_mean - 2*rolling_std,\n",
    "                rolling_mean + 2*rolling_std,\n",
    "                alpha=0.2, label='\u00b12 STD')\n",
    "ax.legend()\n",
    "ax.set_title('Time Series with Moving Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String data\n",
    "df = pd.DataFrame({\n",
    "    'name': ['John Smith', 'jane doe', 'Bob JONES', 'alice wonderland'],\n",
    "    'email': ['john@email.com', 'JANE@GMAIL.COM', 'bob@yahoo.com', 'alice@outlook.com']\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df)\n",
    "\n",
    "# String methods\n",
    "df['name_upper'] = df['name'].str.upper()\n",
    "df['name_title'] = df['name'].str.title()\n",
    "df['first_name'] = df['name'].str.split().str[0]\n",
    "df['email_domain'] = df['email'].str.split('@').str[1].str.lower()\n",
    "df['name_length'] = df['name'].str.len()\n",
    "\n",
    "print(\"\\nProcessed:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical data\n",
    "df = pd.DataFrame({\n",
    "    'grade': ['A', 'B', 'A', 'C', 'B', 'A', 'D', 'C'],\n",
    "    'score': [95, 85, 92, 75, 88, 96, 65, 78]\n",
    "})\n",
    "\n",
    "# Convert to categorical\n",
    "df['grade'] = pd.Categorical(\n",
    "    df['grade'],\n",
    "    categories=['D', 'C', 'B', 'A'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(\"Categorical data:\")\n",
    "print(df)\n",
    "print(\"\\nCategories:\", df['grade'].cat.categories)\n",
    "print(\"Ordered:\", df['grade'].cat.ordered)\n",
    "\n",
    "# Sort by categorical order\n",
    "print(\"\\nSorted by grade:\")\n",
    "print(df.sort_values('grade'))\n",
    "\n",
    "# Filter using categorical order\n",
    "print(\"\\nGrades better than C:\")\n",
    "print(df[df['grade'] > 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Real-World Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Data Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create messy data\n",
    "messy_data = pd.DataFrame({\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023/01/03', '01-04-2023', None],\n",
    "    'Amount': ['$1,234.56', '2345.67', '$3,456.78', 'N/A', '4567.89'],\n",
    "    'Category': ['Food', 'food', 'FOOD', 'Transport', None],\n",
    "    'Status': ['Complete', 'complete', 'PENDING', 'pending', 'Complete']\n",
    "})\n",
    "\n",
    "print(\"Messy data:\")\n",
    "print(messy_data)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean and standardize the data\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Clean dates\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    \n",
    "    # Clean amounts\n",
    "    df['Amount'] = (df['Amount']\n",
    "                   .str.replace('$', '', regex=False)\n",
    "                   .str.replace(',', '', regex=False)\n",
    "                   .replace('N/A', np.nan))\n",
    "    df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "    \n",
    "    # Standardize categories\n",
    "    df['Category'] = df['Category'].str.title()\n",
    "    df['Category'] = df['Category'].fillna('Unknown')\n",
    "    \n",
    "    # Standardize status\n",
    "    df['Status'] = df['Status'].str.title()\n",
    "    \n",
    "    # Remove rows with critical missing data\n",
    "    df = df.dropna(subset=['Date', 'Amount'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "clean = clean_data(messy_data)\n",
    "print(\"\\nCleaned data:\")\n",
    "print(clean)\n",
    "print(\"\\nData types:\")\n",
    "print(clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sales data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "sales = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=n_records, freq='H'),\n",
    "    'product': np.random.choice(['A', 'B', 'C', 'D'], n_records),\n",
    "    'quantity': np.random.poisson(10, n_records),\n",
    "    'price': np.random.uniform(10, 100, n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records)\n",
    "})\n",
    "\n",
    "sales['revenue'] = sales['quantity'] * sales['price']\n",
    "\n",
    "# Analysis\n",
    "print(\"Sales Summary:\")\n",
    "print(sales.describe())\n",
    "\n",
    "# Daily aggregation\n",
    "daily_sales = sales.set_index('date').resample('D').agg({\n",
    "    'quantity': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    'price': 'mean'\n",
    "})\n",
    "\n",
    "print(\"\\nDaily sales (first week):\")\n",
    "print(daily_sales.head(7))\n",
    "\n",
    "# Product performance\n",
    "product_performance = sales.groupby('product').agg({\n",
    "    'quantity': 'sum',\n",
    "    'revenue': ['sum', 'mean'],\n",
    "    'price': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nProduct Performance:\")\n",
    "print(product_performance)\n",
    "\n",
    "# Regional analysis\n",
    "regional = sales.pivot_table(\n",
    "    values='revenue',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum'\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nRevenue by Product and Region:\")\n",
    "print(regional)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Daily revenue trend\n",
    "daily_sales['revenue'].plot(ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Daily Revenue Trend')\n",
    "axes[0, 0].set_ylabel('Revenue ($)')\n",
    "\n",
    "# Product distribution\n",
    "sales.groupby('product')['revenue'].sum().plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Total Revenue by Product')\n",
    "axes[0, 1].set_ylabel('Revenue ($)')\n",
    "\n",
    "# Regional distribution\n",
    "sales.groupby('region')['revenue'].sum().plot(kind='pie', ax=axes[1, 0], autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('Revenue Distribution by Region')\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(regional, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Revenue Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "### NumPy Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Vectorization vs loops\n",
    "size = 1000000\n",
    "a = np.random.randn(size)\n",
    "b = np.random.randn(size)\n",
    "\n",
    "# Loop method\n",
    "start = time.time()\n",
    "result_loop = []\n",
    "for i in range(size):\n",
    "    result_loop.append(a[i] + b[i])\n",
    "loop_time = time.time() - start\n",
    "\n",
    "# Vectorized method\n",
    "start = time.time()\n",
    "result_vector = a + b\n",
    "vector_time = time.time() - start\n",
    "\n",
    "print(f\"Loop time: {loop_time:.4f} seconds\")\n",
    "print(f\"Vectorized time: {vector_time:.4f} seconds\")\n",
    "print(f\"Speedup: {loop_time/vector_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient data types\n",
    "df = pd.DataFrame({\n",
    "    'int_col': np.random.randint(0, 100, 10000),\n",
    "    'float_col': np.random.randn(10000),\n",
    "    'category_col': np.random.choice(['A', 'B', 'C'], 10000)\n",
    "})\n",
    "\n",
    "print(\"Original memory usage:\")\n",
    "print(df.memory_usage(deep=True))\n",
    "\n",
    "# Optimize data types\n",
    "df['int_col'] = df['int_col'].astype('int8')  # Smaller int\n",
    "df['float_col'] = df['float_col'].astype('float32')  # Smaller float\n",
    "df['category_col'] = df['category_col'].astype('category')  # Categorical\n",
    "\n",
    "print(\"\\nOptimized memory usage:\")\n",
    "print(df.memory_usage(deep=True))\n",
    "\n",
    "# Use vectorized string operations\n",
    "# Bad: df['new'] = df['category_col'].apply(lambda x: x.lower())\n",
    "# Good: df['new'] = df['category_col'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### NumPy Best Practices\n",
    "1. **Use vectorization** instead of loops\n",
    "2. **Preallocate arrays** when size is known\n",
    "3. **Use appropriate data types** (float32 vs float64)\n",
    "4. **Leverage broadcasting** for operations\n",
    "5. **Use views instead of copies** when possible\n",
    "\n",
    "### Pandas Best Practices\n",
    "1. **Use vectorized operations** (.str, .dt methods)\n",
    "2. **Optimize data types** (categories, smaller ints)\n",
    "3. **Use .loc/.iloc** for explicit indexing\n",
    "4. **Chain operations** for readability\n",
    "5. **Profile memory usage** for large datasets\n",
    "\n",
    "### When to Use What?\n",
    "- **NumPy**: Numerical computations, linear algebra, image processing\n",
    "- **Pandas**: Tabular data, time series, data cleaning, analysis\n",
    "\n",
    "### Resources\n",
    "- [NumPy Documentation](https://numpy.org/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [NumPy Tutorial](https://numpy.org/doc/stable/user/quickstart.html)\n",
    "- [Pandas Tutorial](https://pandas.pydata.org/docs/getting_started/tutorials.html)\n",
    "\n",
    "Master these libraries and you'll be equipped for any data analysis task! \ud83d\ude80\ud83d\udcca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}